{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqGs0nK9M8Kq",
        "outputId": "b99aeb85-098b-4fe0-cc0e-40f0c8a94691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.11/dist-packages (12.0.1)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gurobipy\n",
        "!pip install torch_geometric\n",
        "!pip install sortedcontainers\n",
        "\n",
        "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "!pip install scikit-optimize\n",
        "\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import pairwise_distances as sklearn_pairwise_distances\n",
        "import networkx as nx\n",
        " # Use \"cosine\" for cosine similarity\n",
        "import heapq\n",
        "\n",
        "\n",
        "os.environ[\"GRB_LICENSE_FILE\"] = \"gurobi (3).lic\"\n",
        "os.environ[\"GRB_WLSACCESSID\"] = \"f218200d-1f8d-4342-83f5-b7b2d9263751\"  # Replace with your actual WLSACCESSID\n",
        "os.environ[\"GRB_WLSSECRET\"] = \"528d596b-babc-4a1e-bda2-693c44f4f006\"  # Replace with your actual WLSSECRET\n",
        "os.environ[\"GRB_LICENSEID\"] = \"840285\"  # Replace with your actual LICENSEID\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from torch_geometric.datasets import WebKB, WikipediaNetwork, Actor\n",
        "\n",
        "from torch_geometric.datasets import FacebookPagePage\n",
        "\n",
        "from torch_geometric.datasets import SNAPDataset\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import networkx as nx\n",
        "from torch_geometric.datasets import WebKB\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sortedcontainers import SortedSet  # Ordered set\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "from torch_geometric.datasets import WikipediaNetwork\n",
        "from torch_geometric.datasets import Actor\n",
        "\n",
        "# Load the Film dataset (also known as Actor dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD28jxmhNmm5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZChMrfbyNoOn",
        "outputId": "a14e0eab-11dc-415c-92c1-90ff2b35cecf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_9.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Loaded  dataset with 251 nodes, 916 edges\n",
            "   - Features: 1703\n",
            "   - Number of Classes: 5\n",
            "   - Number of Components: 1\n",
            "1 -23.756143024989537\n",
            "2 -20.922897429693315\n",
            "0 -21.817668823968795\n",
            "3 -26.011760711669922\n",
            "4 -23.030241557529994\n",
            "\n",
            "🔹 Labelling Node 4 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -23.285575321742467\n",
            "2 -19.63846978687105\n",
            "0 -22.273834137689498\n",
            "3 -26.416616439819336\n",
            "4 -29.90858895438058\n",
            "\n",
            "🔹 Labelling Node 9 \n",
            "   -> Predicted Label: 2 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.38633864266532\n",
            "2 -16.57874497913179\n",
            "0 -20.13071432567778\n",
            "3 -25.432994842529297\n",
            "4 -22.203480311802455\n",
            "\n",
            "🔹 Labelling Node 16 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -30.015649250575475\n",
            "2 -27.09831628345308\n",
            "0 -27.387588410150435\n",
            "3 -28.99302101135254\n",
            "4 -29.677912303379603\n",
            "\n",
            "🔹 Labelling Node 27 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -20.444894245692662\n",
            "2 -14.741014571416946\n",
            "0 -18.072687058221724\n",
            "3 -23.560592651367188\n",
            "4 -26.62401635306222\n",
            "\n",
            "🔹 Labelling Node 39 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -24.018416813441686\n",
            "2 -22.822059722173783\n",
            "0 -23.60590162731352\n",
            "3 -29.410226821899414\n",
            "4 -25.924223491123744\n",
            "\n",
            "🔹 Labelling Node 46 \n",
            "   -> Predicted Label: 2 | True Label: 4 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.74572890145438\n",
            "2 -30.871120543706986\n",
            "0 -27.040115265619185\n",
            "3 -30.16864585876465\n",
            "4 -28.227772303989955\n",
            "\n",
            "🔹 Labelling Node 48 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.98805754525321\n",
            "2 -17.215953917730424\n",
            "0 -20.95921316600981\n",
            "3 -25.499439239501953\n",
            "4 -22.879944392613\n",
            "\n",
            "🔹 Labelling Node 55 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -28.17013304574149\n",
            "2 -17.734401793706986\n",
            "0 -20.69073286510649\n",
            "3 -25.55100440979004\n",
            "4 -23.000767299107142\n",
            "\n",
            "🔹 Labelling Node 56 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -20.683312824794225\n",
            "2 -14.755705924261184\n",
            "0 -18.335000900995162\n",
            "3 -29.86019515991211\n",
            "4 -20.803257533482142\n",
            "\n",
            "🔹 Labelling Node 65 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.99851553780692\n",
            "2 -15.470487685430617\n",
            "0 -19.01408949352446\n",
            "3 -24.28838539123535\n",
            "4 -21.39365632193429\n",
            "\n",
            "🔹 Labelling Node 76 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.633527210780553\n",
            "2 -16.48357018970308\n",
            "0 -20.023527054559615\n",
            "3 -24.90620994567871\n",
            "4 -21.716408320835658\n",
            "\n",
            "🔹 Labelling Node 88 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -23.27585928780692\n",
            "2 -26.64046372913179\n",
            "0 -24.65889921642485\n",
            "3 -29.390454483032226\n",
            "4 -25.735075541904994\n",
            "\n",
            "🔹 Labelling Node 89 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 4 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -32.06636984688895\n",
            "2 -29.35095071338472\n",
            "0 -28.944866089593795\n",
            "3 -30.057281494140625\n",
            "4 -30.227847834995814\n",
            "\n",
            "🔹 Labelling Node 93 \n",
            "   -> Predicted Label: 0 | True Label: 3 ❌\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -25.977752140590123\n",
            "2 -14.448367209661575\n",
            "0 -19.26486959911528\n",
            "3 -23.850475311279297\n",
            "4 -20.788096019199916\n",
            "\n",
            "🔹 Labelling Node 99 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -29.619546345302037\n",
            "2 -19.190305800664994\n",
            "0 -22.73459616161528\n",
            "3 -26.71734046936035\n",
            "4 -24.24594361441476\n",
            "\n",
            "🔹 Labelling Node 109 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.05673735482352\n",
            "2 -19.96498879932222\n",
            "0 -24.162305741083053\n",
            "3 -27.360431671142578\n",
            "4 -24.45473725455148\n",
            "\n",
            "🔹 Labelling Node 116 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -30.70261137826102\n",
            "2 -27.372793288457963\n",
            "0 -28.081508545648482\n",
            "3 -28.967477798461914\n",
            "4 -29.965336390904017\n",
            "\n",
            "🔹 Labelling Node 121 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -22.480555943080358\n",
            "2 -18.415519042242142\n",
            "0 -21.180515198480514\n",
            "3 -28.55003128051758\n",
            "4 -23.826358577183314\n",
            "\n",
            "🔹 Labelling Node 122 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 3: 3 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -24.881648472377233\n",
            "2 -16.856905074346635\n",
            "0 -20.824510483514693\n",
            "3 -27.13998794555664\n",
            "4 -21.93519456045968\n",
            "\n",
            "🔹 Labelling Node 125 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.935943058558873\n",
            "2 -21.368303389776322\n",
            "0 -24.261312393915084\n",
            "3 -27.559856414794922\n",
            "4 -27.929495402744838\n",
            "\n",
            "🔹 Labelling Node 131 \n",
            "   -> Predicted Label: 2 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -29.994571140834264\n",
            "2 -25.0373345329648\n",
            "0 -26.182125000726607\n",
            "3 -28.66668128967285\n",
            "4 -28.58146721976144\n",
            "\n",
            "🔹 Labelling Node 132 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -32.050122669764924\n",
            "2 -22.756631942022416\n",
            "0 -25.885736374627974\n",
            "3 -29.13791275024414\n",
            "4 -26.923538752964564\n",
            "\n",
            "🔹 Labelling Node 133 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.104457310267858\n",
            "2 -14.918518157232375\n",
            "0 -19.636060623895553\n",
            "3 -24.050922393798828\n",
            "4 -20.908272334507533\n",
            "\n",
            "🔹 Labelling Node 134 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -21.478499821254186\n",
            "2 -17.861354918706986\n",
            "0 -21.965421585809615\n",
            "3 -32.08018112182617\n",
            "4 -22.623322078159877\n",
            "\n",
            "🔹 Labelling Node 136 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -25.035838535853795\n",
            "2 -14.676901908147903\n",
            "0 -19.50134077526274\n",
            "3 -24.167150497436523\n",
            "4 -19.608130046299525\n",
            "\n",
            "🔹 Labelling Node 141 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -24.233746937343053\n",
            "2 -20.67975625537691\n",
            "0 -22.859022049676803\n",
            "3 -26.54056739807129\n",
            "4 -23.40366608755929\n",
            "\n",
            "🔹 Labelling Node 149 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -22.67653410775321\n",
            "2 -21.061853499639604\n",
            "0 -22.82805624462309\n",
            "3 -28.26277732849121\n",
            "4 -24.841963359287806\n",
            "\n",
            "🔹 Labelling Node 159 \n",
            "   -> Predicted Label: 2 | True Label: 4 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -25.90941756112235\n",
            "2 -15.807640166509719\n",
            "0 -20.528119950067428\n",
            "3 -24.885095596313477\n",
            "4 -20.89745957510812\n",
            "\n",
            "🔹 Labelling Node 194 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -22.424537113734655\n",
            "2 -17.273986907232377\n",
            "0 -21.720874695550826\n",
            "3 -29.286609649658203\n",
            "4 -21.90793854849679\n",
            "\n",
            "🔹 Labelling Node 208 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.446931294032506\n",
            "2 -25.459873290289018\n",
            "0 -25.53680220104399\n",
            "3 -29.39719009399414\n",
            "4 -26.349754878452845\n",
            "\n",
            "🔹 Labelling Node 209 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 2: 2 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -25.29412978036063\n",
            "2 -24.56084832691011\n",
            "0 -27.457141785394576\n",
            "3 -25.951984405517578\n",
            "4 -25.05850464957101\n",
            "\n",
            "🔹 Labelling Node 210 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.06010573250907\n",
            "2 -18.501834960210893\n",
            "0 -22.107156662713912\n",
            "3 -25.45062828063965\n",
            "4 -26.186714717320033\n",
            "\n",
            "🔹 Labelling Node 213 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.468518665858678\n",
            "2 -20.29847726367769\n",
            "0 -24.17782774425688\n",
            "3 -27.451663970947266\n",
            "4 -24.7106328691755\n",
            "\n",
            "🔹 Labelling Node 222 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -29.286984852382115\n",
            "2 -18.834497542608354\n",
            "0 -22.616207031976607\n",
            "3 -26.179988861083984\n",
            "4 -23.662830897739955\n",
            "\n",
            "🔹 Labelling Node 227 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -29.656037739345006\n",
            "2 -20.349037261236283\n",
            "0 -24.241279511224654\n",
            "3 -27.908145904541016\n",
            "4 -25.103178569248744\n",
            "\n",
            "🔹 Labelling Node 235 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -25.441173008510045\n",
            "2 -14.767217726934524\n",
            "0 -19.56316938854399\n",
            "3 -24.162378311157227\n",
            "4 -20.06565339224679\n",
            "\n",
            "🔹 Labelling Node 236 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -25.260938099452428\n",
            "2 -14.894634337652297\n",
            "0 -19.94455137706938\n",
            "3 -24.429588317871094\n",
            "4 -20.215340205601283\n",
            "\n",
            "🔹 Labelling Node 246 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -25.220422199794225\n",
            "2 -15.17475041889009\n",
            "0 -20.245504288446334\n",
            "3 -24.251110076904297\n",
            "4 -20.132755824497767\n",
            "\n",
            "🔹 Labelling Node 247 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -30.16148703438895\n",
            "2 -20.950885863531205\n",
            "0 -24.41414823986235\n",
            "3 -28.347061157226562\n",
            "4 -24.99146134512765\n",
            "\n",
            "🔹 Labelling Node 250 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -37.36869321550642\n",
            "2 -36.12579109555199\n",
            "0 -37.76453090849377\n",
            "3 -37.711398533412385\n",
            "4 -37.58009283883231\n",
            "\n",
            "🔹 Labelling Node 147 \n",
            "   -> Predicted Label: 2 | True Label: 4 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 4: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -33.901718684605186\n",
            "2 -27.543434233892533\n",
            "0 -29.37689009166899\n",
            "3 -32.223536900111604\n",
            "4 -30.9925537109375\n",
            "\n",
            "🔹 Labelling Node 170 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 5 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -23.807044437953405\n",
            "2 -21.09778794788179\n",
            "0 -21.75359907604399\n",
            "3 -25.66358757019043\n",
            "4 -23.872303553989955\n",
            "\n",
            "🔹 Labelling Node 29 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 2: 3 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -32.98208830697196\n",
            "2 -25.333326430547807\n",
            "0 -27.832412628900435\n",
            "3 -30.799395751953124\n",
            "4 -28.806717463902064\n",
            "\n",
            "🔹 Labelling Node 104 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 4 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -21.255286625453405\n",
            "2 -20.43053063892183\n",
            "0 -21.366544632684615\n",
            "3 -25.353435516357422\n",
            "4 -24.761530467442103\n",
            "\n",
            "🔹 Labelling Node 241 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 2: 2 neighbors\n",
            "   - Class 4: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -22.456721714564733\n",
            "2 -21.671875090826127\n",
            "0 -22.998800186883834\n",
            "3 -28.437854766845703\n",
            "4 -24.915455409458705\n",
            "\n",
            "🔹 Labelling Node 198 \n",
            "   -> Predicted Label: 2 | True Label: 4 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -33.77781432015555\n",
            "2 -33.15212831043062\n",
            "0 -32.67390242077055\n",
            "3 -35.17346954345703\n",
            "4 -33.66334206717355\n",
            "\n",
            "🔹 Labelling Node 243 \n",
            "   -> Predicted Label: 0 | True Label: 1 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 1: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.72897093636649\n",
            "2 -18.242506118047807\n",
            "0 -22.637620835077193\n",
            "3 -26.9454288482666\n",
            "4 -22.801117488316127\n",
            "\n",
            "🔹 Labelling Node 11 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -28.096818378993444\n",
            "2 -23.42594728015718\n",
            "0 -26.97394361950102\n",
            "3 -28.783849716186523\n",
            "4 -25.728201457432338\n",
            "\n",
            "🔹 Labelling Node 37 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -29.98007529122489\n",
            "2 -20.904220671880815\n",
            "0 -25.12151327587309\n",
            "3 -26.955459594726562\n",
            "4 -24.71036011832101\n",
            "\n",
            "🔹 Labelling Node 155 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -39.49967520577567\n",
            "2 -44.297395797002885\n",
            "0 -40.50810041881743\n",
            "3 -44.08251190185547\n",
            "4 -41.30716759817941\n",
            "\n",
            "🔹 Labelling Node 217 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -28.82411711556571\n",
            "2 -20.292406172979447\n",
            "0 -24.69919577099028\n",
            "3 -27.22238540649414\n",
            "4 -24.279102870396205\n",
            "\n",
            "🔹 Labelling Node 171 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 5 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.01081793648856\n",
            "2 -26.42586526416597\n",
            "0 -25.98175611950102\n",
            "3 -28.124515533447266\n",
            "4 -25.7960820879255\n",
            "\n",
            "🔹 Labelling Node 206 \n",
            "   -> Predicted Label: 4 | True Label: 1 ❌\n",
            "   - Class 2: 2 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -28.01741042694488\n",
            "2 -27.346360557523123\n",
            "0 -26.846124558221724\n",
            "3 -29.646615982055664\n",
            "4 -27.543472834995814\n",
            "\n",
            "🔹 Labelling Node 204 \n",
            "   -> Predicted Label: 0 | True Label: 1 ❌\n",
            "   - Class 1: 5 neighbors\n",
            "   - Class 2: 6 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -23.818717411586217\n",
            "2 -15.671206565130325\n",
            "0 -23.40030088878813\n",
            "3 -24.47614860534668\n",
            "4 -20.66061646597726\n",
            "\n",
            "🔹 Labelling Node 3 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -24.610856464930944\n",
            "2 -15.031549544561477\n",
            "0 -22.405885605585006\n",
            "3 -23.798709869384766\n",
            "4 -20.51165063040597\n",
            "\n",
            "🔹 Labelling Node 114 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -24.76142065865653\n",
            "2 -16.045408339727494\n",
            "0 -23.36044493175688\n",
            "3 -24.483531951904297\n",
            "4 -21.57641465323312\n",
            "\n",
            "🔹 Labelling Node 190 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.141572407313756\n",
            "2 -15.643870444524856\n",
            "0 -21.5269965217227\n",
            "3 -24.76334571838379\n",
            "4 -20.72588402884347\n",
            "\n",
            "🔹 Labelling Node 22 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -30.020829609462194\n",
            "2 -26.918108077276322\n",
            "0 -28.246381668817428\n",
            "3 -30.787357330322266\n",
            "4 -28.313173839024135\n",
            "\n",
            "🔹 Labelling Node 28 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 1: 3 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -28.361703327723912\n",
            "2 -22.373355956304643\n",
            "0 -28.840707688104537\n",
            "3 -29.031566619873047\n",
            "4 -25.942669459751674\n",
            "\n",
            "🔹 Labelling Node 71 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.566911152430944\n",
            "2 -22.123006911504838\n",
            "0 -25.805219559442428\n",
            "3 -27.874523162841797\n",
            "4 -27.82774407523019\n",
            "\n",
            "🔹 Labelling Node 78 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -22.22546332223075\n",
            "2 -25.026336760748002\n",
            "0 -24.639617829095748\n",
            "3 -29.113971710205078\n",
            "4 -24.419714518955775\n",
            "\n",
            "🔹 Labelling Node 87 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 3 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -31.053828648158483\n",
            "2 -33.95873078845796\n",
            "0 -32.77638426281157\n",
            "3 -37.72669219970703\n",
            "4 -33.17045647757394\n",
            "\n",
            "🔹 Labelling Node 112 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -22.13438551766532\n",
            "2 -25.269680114019486\n",
            "0 -23.807647614251998\n",
            "3 -26.380008697509766\n",
            "4 -23.269770213535853\n",
            "\n",
            "🔹 Labelling Node 152 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 4 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -32.66891997201102\n",
            "2 -23.176614852178666\n",
            "0 -26.656453995477584\n",
            "3 -28.689208984375\n",
            "4 -27.07387787955148\n",
            "\n",
            "🔹 Labelling Node 169 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 1: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.856477192470006\n",
            "2 -20.180826277959916\n",
            "0 -26.918416886102584\n",
            "3 -26.805347442626953\n",
            "4 -23.778616496494838\n",
            "\n",
            "🔹 Labelling Node 244 \n",
            "   -> Predicted Label: 2 | True Label: 4 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -32.124532154628206\n",
            "2 -29.145731063116166\n",
            "0 -28.329694657098678\n",
            "3 -30.296127319335938\n",
            "4 -28.911570140293666\n",
            "\n",
            "🔹 Labelling Node 187 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -29.27771246773856\n",
            "2 -26.686862273443314\n",
            "0 -30.91509848095122\n",
            "3 -29.649768829345703\n",
            "4 -28.470023890904017\n",
            "\n",
            "🔹 Labelling Node 156 \n",
            "   -> Predicted Label: 2 | True Label: 4 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -30.954529081072128\n",
            "2 -27.028296970185778\n",
            "0 -29.616774876912434\n",
            "3 -28.908245086669922\n",
            "4 -31.021164757864817\n",
            "\n",
            "🔹 Labelling Node 75 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 4: 3 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -31.867904118129186\n",
            "2 -28.701456160772416\n",
            "0 -28.94638243175688\n",
            "3 -29.25823974609375\n",
            "4 -28.269648143223353\n",
            "\n",
            "🔹 Labelling Node 77 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -24.880870274135045\n",
            "2 -22.34605226062593\n",
            "0 -23.188123612176803\n",
            "3 -25.45400047302246\n",
            "4 -23.032953807285853\n",
            "\n",
            "🔹 Labelling Node 172 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -33.16770117623465\n",
            "2 -24.74844941638765\n",
            "0 -27.758140473138717\n",
            "3 -29.19222068786621\n",
            "4 -27.73425919669015\n",
            "\n",
            "🔹 Labelling Node 25 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 1: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -24.6082090650286\n",
            "2 -22.45232591174898\n",
            "0 -24.051923661004928\n",
            "3 -26.471765518188477\n",
            "4 -23.347813197544642\n",
            "\n",
            "🔹 Labelling Node 82 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -33.03758566720145\n",
            "2 -23.767320723760697\n",
            "0 -27.196954636346724\n",
            "3 -27.473621368408203\n",
            "4 -26.56898934500558\n",
            "\n",
            "🔹 Labelling Node 58 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -33.09660284859793\n",
            "2 -23.685077758062455\n",
            "0 -27.06143370128813\n",
            "3 -26.943716049194336\n",
            "4 -26.600615092686244\n",
            "\n",
            "🔹 Labelling Node 137 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -23.816552570887975\n",
            "2 -28.00657472156343\n",
            "0 -26.27296057201567\n",
            "3 -28.10666275024414\n",
            "4 -25.44265229361398\n",
            "\n",
            "🔹 Labelling Node 158 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -28.206397465297155\n",
            "2 -21.20025071643648\n",
            "0 -25.168626694452193\n",
            "3 -27.81585121154785\n",
            "4 -24.992348262241908\n",
            "\n",
            "🔹 Labelling Node 249 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -26.70865958077567\n",
            "2 -22.51940354846773\n",
            "0 -23.881011872064498\n",
            "3 -25.53554916381836\n",
            "4 -23.66028458731515\n",
            "\n",
            "🔹 Labelling Node 153 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 2: 2 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.814097813197545\n",
            "2 -20.94657525562105\n",
            "0 -23.691528229486373\n",
            "3 -25.811838150024414\n",
            "4 -23.62961823599679\n",
            "\n",
            "🔹 Labelling Node 12 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 3 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -22.321135929652623\n",
            "2 -24.468862624395463\n",
            "0 -23.101406006585982\n",
            "3 -25.124975204467773\n",
            "4 -22.34912736075265\n",
            "\n",
            "🔹 Labelling Node 64 \n",
            "   -> Predicted Label: 1 | True Label: 4 ❌\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -29.952727726527623\n",
            "2 -26.707000823248002\n",
            "0 -27.33125677562895\n",
            "3 -27.48483657836914\n",
            "4 -26.581638881138392\n",
            "\n",
            "🔹 Labelling Node 144 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -25.301265171595983\n",
            "2 -24.166088195074174\n",
            "0 -27.428235916864303\n",
            "3 -29.346826553344727\n",
            "4 -32.75858361380441\n",
            "\n",
            "🔹 Labelling Node 108 \n",
            "   -> Predicted Label: 2 | True Label: 1 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -31.814822605678014\n",
            "2 -22.18694695972261\n",
            "0 -25.921111969720748\n",
            "3 -25.976016998291016\n",
            "4 -25.19352776663644\n",
            "\n",
            "🔹 Labelling Node 179 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -29.407222202845983\n",
            "2 -34.80597123645601\n",
            "0 -31.074653534662154\n",
            "3 -32.898033142089844\n",
            "4 -30.892023631504603\n",
            "\n",
            "🔹 Labelling Node 214 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -21.678702763148717\n",
            "2 -26.461776824224565\n",
            "0 -24.639961151849654\n",
            "3 -26.98391342163086\n",
            "4 -24.20909173148019\n",
            "\n",
            "🔹 Labelling Node 224 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -20.023719242640905\n",
            "2 -22.57290467761812\n",
            "0 -22.014390854608443\n",
            "3 -24.72319793701172\n",
            "4 -20.851540156773158\n",
            "\n",
            "🔹 Labelling Node 228 \n",
            "   -> Predicted Label: 1 | True Label: 1 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -27.613353184291295\n",
            "2 -17.404090972173783\n",
            "0 -22.0614260718936\n",
            "3 -24.608808517456055\n",
            "4 -22.17504174368722\n",
            "\n",
            "🔹 Labelling Node 234 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1 -23.16353361947196\n",
            "2 -25.713276000249955\n",
            "0 -23.56686583019438\n",
            "3 -26.172286987304688\n",
            "4 -24.058676310947963\n",
            "\n",
            "🔹 Labelling Node 117 \n",
            "   -> Predicted Label: 1 | True Label: 2 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "🎯 Label Propagation Accuracy: 0.5909\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "#dataset = Actor(root='data/Film')\n",
        "data = dataset[0]\n",
        "data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "\n",
        "# ✅ Remove duplicate edges\n",
        "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "# ✅ Convert to NetworkX Graph to Find Components\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "components = list(nx.connected_components(G))\n",
        "num_components = len(components)\n",
        "\n",
        "print(f\"\\n✅ Loaded  dataset with {data.num_nodes} nodes, {data.edge_index.shape[1]} edges\")\n",
        "print(f\"   - Features: {data.x.shape[1]}\")\n",
        "print(f\"   - Number of Classes: {len(set(data.y.numpy()))}\")\n",
        "print(f\"   - Number of Components: {num_components}\")\n",
        "\n",
        "# ✅ Set Training Percentage\n",
        "train_percentage = 0.65\n",
        "\n",
        "# ✅ Select Training Nodes\n",
        "train_indices = []\n",
        "for component in components:\n",
        "    component = list(component)\n",
        "    t = max(1, int(train_percentage * len(component)))\n",
        "    sampled_nodes = np.random.choice(component, t, replace=False)\n",
        "    train_indices.extend(sampled_nodes)\n",
        "\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "# ✅ Initialize Prediction Labels\n",
        "y_pred = np.full(data.num_nodes, -1)\n",
        "for idx in train_indices:\n",
        "    y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "# ✅ Compute Label Distribution\n",
        "total_label_counts = Counter(data.y.numpy())\n",
        "num_labels = len(set(data.y.numpy()))\n",
        "alpha = 1  # Laplace smoothing\n",
        "\n",
        "dataset_label_distribution = {\n",
        "    lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "    for lbl in total_label_counts.keys()\n",
        "}\n",
        "\n",
        "train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "train_label_distribution = {\n",
        "    lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "    for lbl in dataset_label_distribution.keys()\n",
        "}\n",
        "\n",
        "# ✅ Precompute Neighbors for Each Node\n",
        "A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "A = A.numpy()\n",
        "neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "# ✅ Track Instances Assigned to Each Label\n",
        "class_instances = defaultdict(set)\n",
        "for idx in train_indices:\n",
        "    class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "# ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "ordered_set = SortedSet()\n",
        "train_labeled_nodes = set(train_indices)\n",
        "\n",
        "for node in range(data.num_nodes):\n",
        "    if y_pred[node] == -1:  # Only process unlabeled nodes\n",
        "        labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "        num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "        total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "        if total_neighbors > 0:\n",
        "            weighted_score = (num_labeled_by_propagation + 3 * num_labeled_by_train) / total_neighbors\n",
        "        else:\n",
        "            weighted_score = 0\n",
        "\n",
        "        ordered_set.add((-weighted_score, node))\n",
        "\n",
        "# ✅ Iteratively Label the Most Constrained Nodes\n",
        "while ordered_set:\n",
        "    _, node = ordered_set.pop(0)\n",
        "\n",
        "    if y_pred[node] != -1:\n",
        "        continue\n",
        "\n",
        "    # Get labeled neighbors\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    # 🚨 If this node has 0 labeled neighbors\n",
        "    if not neighbor_labels:\n",
        "        print(f\"\\n🚨 STRANGE: Node {node} was chosen, but it has 0 labeled neighbors!\")\n",
        "        break\n",
        "\n",
        "    # Compute Neighbor Label Distribution\n",
        "    neighbor_label_counts = Counter(neighbor_labels)\n",
        "    total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "    if total_labeled_neighbors > 0:\n",
        "        neighbor_label_distribution = {\n",
        "            lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "        }\n",
        "    else:\n",
        "        neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # ✅ Compute Feature Distance to Each Class\n",
        "    # feature_diffs = {}\n",
        "    # for lbl in dataset_label_distribution.keys():\n",
        "    #   if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "    #       instance_features = data.x[list(class_instances[lbl])]\n",
        "    #       node_feature = data.x[node].unsqueeze(0)\n",
        "\n",
        "    #       # Compute distances for each instance\n",
        "    #       distances = torch.norm(instance_features - node_feature, dim=1).tolist()\n",
        "\n",
        "    #       # Apply weight based on whether the instance is from training or predicted labels\n",
        "    #       weighted_distances = [\n",
        "    #           (3 * dist) if instance in train_indices else dist  # Give 3x weight if in training set\n",
        "    #           for instance, dist in zip(class_instances[lbl], distances)\n",
        "    #       ]\n",
        "\n",
        "    #       # Compute weighted average distance\n",
        "    #       avg_distance = sum(weighted_distances) / len(weighted_distances)\n",
        "    #       feature_diffs[lbl] = avg_distance\n",
        "    #   else:\n",
        "    #       feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    feature_diffs = {}\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "            instance_features = data.x[list(class_instances[lbl])]\n",
        "            node_feature = data.x[node].unsqueeze(0)\n",
        "           # print(len(instance_features),len(node_feature))\n",
        "            avg_distance = torch.mean(torch.norm(instance_features - node_feature, dim=1)).item()\n",
        "            feature_diffs[lbl] = avg_distance\n",
        "        else:\n",
        "            feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    # ✅ Select the Best Label Based on the Adjusted Score\n",
        "    best_label_candidates = []\n",
        "    max_value = float('-inf')\n",
        "    a1=0.5\n",
        "    a2=-6\n",
        "    a3=-2\n",
        "    a4=1\n",
        "    a5=3\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        score = (\n",
        "            a1*train_label_distribution.get(lbl, 0)\n",
        "            +a2* neighbor_label_distribution.get(lbl, 0)\n",
        "            +a3*feature_diffs[lbl]  # Penalize by average feature distance\n",
        "        )\n",
        "        print(lbl,score,)\n",
        "\n",
        "        if score - max_value > 0.01:\n",
        "            best_label_candidates = [lbl]\n",
        "            max_value = score\n",
        "        elif abs(score - max_value) <= 0.01:\n",
        "            best_label_candidates.append(lbl)\n",
        "\n",
        "\n",
        "    best_label = random.choice(best_label_candidates)\n",
        "    y_pred[node] = best_label\n",
        "    class_instances[best_label].add(node)  # Track newly labeled nodes\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    print(f\"\\n🔹 Labelling Node {node} \")\n",
        "    # ✅ Print Prediction Outcome\n",
        "    true_label = data.y[node].item()\n",
        "    correct = \"✅\" if best_label == true_label else \"❌\"\n",
        "    print(f\"   -> Predicted Label: {best_label} | True Label: {true_label} {correct}\")\n",
        "\n",
        "   # print(f\"   - Total Neighbors: {len(neighbors_dict[node])}\")\n",
        "   # print(f\"   - Labeled Neighbors: {len(neighbor_labels)}\")\n",
        "    for lbl, count in label_counts.items():\n",
        "        print(f\"   - Class {lbl}: {count} neighbors\")\n",
        "        # ✅ Update Labeled Neighbor Score for Unlabeled Neighbors\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                new_weighted_score = (a4*num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "# ✅ Evaluate Accuracy\n",
        "test_indices = [i for i in range(data.num_nodes) if i not in train_indices]\n",
        "y_true = data.y[test_indices]\n",
        "y_pred_test = y_pred[test_indices]\n",
        "\n",
        "valid_idx = [i for i in range(len(y_pred_test)) if y_pred_test[i] != -1]\n",
        "if valid_idx:\n",
        "    final_accuracy = accuracy_score(y_true[valid_idx], y_pred_test[valid_idx])\n",
        "    print(f\"\\n🎯 Label Propagation Accuracy: {final_accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"\\n❌ No valid predictions were made!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru9be0GZSBHA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sortedcontainers import SortedSet\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sortedcontainers import SortedSet\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predictclass(data, train_indices, test_indices, a1, a2, a3, a4, a5, a6, a7):\n",
        "    data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "    train_indices = list(train_indices)\n",
        "    test_indices = list(test_indices)\n",
        "\n",
        "    # ✅ Remove duplicate edges\n",
        "    data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "    # ✅ Initialize Prediction Labels\n",
        "    y_pred = np.full(data.num_nodes, -1, dtype=int)\n",
        "    for idx in train_indices:\n",
        "        y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "    # ✅ Compute Label Distribution\n",
        "    total_label_counts = Counter(data.y.numpy())\n",
        "    num_labels = len(set(data.y.numpy()))\n",
        "    alpha = 1  # Laplace smoothing\n",
        "\n",
        "    dataset_label_distribution = {\n",
        "        lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "        for lbl in total_label_counts.keys()\n",
        "    }\n",
        "\n",
        "    train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "    train_label_distribution = {\n",
        "        lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "        for lbl in dataset_label_distribution.keys()\n",
        "    }\n",
        "\n",
        "    # ✅ Precompute Neighbors for Each Node\n",
        "    A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "    A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "    neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "    # ✅ Track Instances Assigned to Each Label\n",
        "    class_instances = defaultdict(set)\n",
        "    for idx in train_indices:\n",
        "        class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "    # ✅ Initialize D Table (Similarity Table)\n",
        "    D = {i: {lbl: 0.0 for lbl in dataset_label_distribution.keys()} for i in range(data.num_nodes)}\n",
        "    class_counts = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # ✅ Compute Average Feature Vector Once Per Label\n",
        "    avg_features = {}\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if class_instances[lbl]:\n",
        "            instance_list = list(class_instances[lbl])\n",
        "            instance_features = data.x[instance_list]\n",
        "            instance_weights = torch.tensor(\n",
        "                [(1 - a7) if inst in train_indices else a7 for inst in instance_list],\n",
        "                dtype=torch.float,\n",
        "                device=data.x.device\n",
        "            )\n",
        "            instance_weights /= instance_weights.sum()\n",
        "            avg_features[lbl] = torch.sum(instance_features * instance_weights.view(-1, 1), dim=0, keepdim=True)\n",
        "\n",
        "    # ✅ Compute Similarity for Each Unlabeled Node\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if lbl in avg_features:\n",
        "            for i in range(data.num_nodes):\n",
        "                similarity = F.cosine_similarity(data.x[i].unsqueeze(0), avg_features[lbl]).item()\n",
        "                D[i][lbl] = (similarity + 1) / 2\n",
        "\n",
        "    # ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "    ordered_set = SortedSet()\n",
        "    train_labeled_nodes = set(train_indices)\n",
        "    labeled_nodes_count = 0\n",
        "\n",
        "    for node in range(data.num_nodes):\n",
        "        if y_pred[node] == -1:\n",
        "            labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "            num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "            num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "            total_neighbors = len(neighbors_dict[node])\n",
        "            weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "            similarity_score = max(D[node].values()) if D[node] else 0\n",
        "            ordered_set.add((-weighted_score - a6 * similarity_score, node))\n",
        "\n",
        "    while ordered_set:\n",
        "        _, node = ordered_set.pop(0)\n",
        "\n",
        "        if y_pred[node] != -1:\n",
        "            continue\n",
        "            print(\"This node is already labeled. Something is wrong.\")\n",
        "\n",
        "        neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "\n",
        "\n",
        "        neighbor_label_counts = Counter(neighbor_labels)\n",
        "        total_labeled_neighbors = len(neighbor_labels)\n",
        "        neighbor_label_distribution = {\n",
        "            lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "        } if total_labeled_neighbors > 0 else {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        label_similarity = {lbl: D[node][lbl] for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        best_label_candidates = []\n",
        "        max_value = float('-inf')\n",
        "\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            score = (\n",
        "                a1 * train_label_distribution.get(lbl, 0)\n",
        "                + a2 * neighbor_label_distribution.get(lbl, 0)\n",
        "                + a3 * label_similarity[lbl]\n",
        "            )\n",
        "\n",
        "            if score - max_value > 0.01:\n",
        "                best_label_candidates = [lbl]\n",
        "                max_value = score\n",
        "            elif abs(score - max_value) <= 0.01:\n",
        "                best_label_candidates.append(lbl)\n",
        "\n",
        "        best_label = random.choice(best_label_candidates)\n",
        "        y_pred[node] = best_label\n",
        "        class_instances[best_label].add(node)\n",
        "        class_counts[best_label] += 1\n",
        "        labeled_nodes_count += 1\n",
        "\n",
        "\n",
        "\n",
        "        if labeled_nodes_count % (data.num_nodes // 5) == 0 == 0:\n",
        "            avg_features = {}\n",
        "            for lbl in dataset_label_distribution.keys():\n",
        "                if class_instances[lbl]:\n",
        "                    instance_list = list(class_instances[lbl])\n",
        "                    instance_features = data.x[instance_list]\n",
        "                    instance_weights = torch.tensor(\n",
        "                        [(1 - a7) if inst in train_indices else a7 for inst in instance_list],\n",
        "                        dtype=torch.float,\n",
        "                        device=data.x.device\n",
        "                    )\n",
        "                    instance_weights /= instance_weights.sum()\n",
        "                    avg_features[lbl] = torch.sum(instance_features * instance_weights.view(-1, 1), dim=0, keepdim=True)\n",
        "\n",
        "            for lbl in dataset_label_distribution.keys():\n",
        "                if lbl in avg_features:\n",
        "                    for i in range(data.num_nodes):\n",
        "                        similarity = F.cosine_similarity(data.x[i].unsqueeze(0), avg_features[lbl]).item()\n",
        "                        D[i][lbl] = (similarity + 1) / 2\n",
        "\n",
        "            # ✅ Update Scores in Ordered Set\n",
        "            new_ordered_set = SortedSet()\n",
        "            for node in range(data.num_nodes):\n",
        "                if y_pred[node] == -1:\n",
        "                    labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "                    num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "                    num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "                    total_neighbors = len(neighbors_dict[node])\n",
        "                    weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "                    similarity_score = max(D[node].values()) if D[node] else 0\n",
        "                    new_ordered_set.add((-weighted_score - a6 * similarity_score, node))\n",
        "            ordered_set = new_ordered_set\n",
        "\n",
        "    return torch.tensor(y_pred[test_indices], dtype=torch.float), accuracy_score(data.y[test_indices], y_pred[test_indices])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqUQNrZolOwy",
        "outputId": "c989c22f-a8c9-42a5-bbcf-1989003c77e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0: 10 elements\n",
            "Class 1: 70 elements\n",
            "Class 2: 118 elements\n",
            "Class 3: 32 elements\n",
            "Class 4: 21 elements\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "\n",
        "# Count occurrences of each class label\n",
        "class_counts = torch.bincount(data.y)\n",
        "\n",
        "# Print the number of elements in each class\n",
        "for class_id, count in enumerate(class_counts):\n",
        "    print(f\"Class {class_id}: {count} elements\")\n",
        "a1=0.5\n",
        "a2=-6\n",
        "a3=-2\n",
        "a4=1\n",
        "a5=3\n",
        "a6=1\n",
        "\n",
        "indices = np.arange(data.num_nodes)  # NumPy array of indices [0, 1, 2, ..., num_nodes-1]\n",
        "np.random.shuffle(indices)\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.6)\n",
        "\n",
        "# Further split train_idx into train and validation sets (e.g., 20% of train goes to validation)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.5)\n",
        "test_indices=test_idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u88m8qZfUdX-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsMOjg0RUedb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88eDCyKNUf57"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWZxuxXlygBh",
        "outputId": "da44a6b4-a608-4d12-86fe-437d4b28fc13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "best validation by random search: 0.6416470588235293\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import KFold\n",
        "import warnings\n",
        "warnings.simplefilter(\"error\", RuntimeWarning)  # Convert warnings to errors\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "\n",
        "\n",
        "\n",
        "def random_search(model, data, num_samples=50, num_splits=5):\n",
        "    \"\"\"\n",
        "    Perform random search for hyperparameter tuning while evaluating each set\n",
        "    of hyperparameters across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function to predict classes.\n",
        "        data: Dataset object.\n",
        "        num_samples: Number of random search samples (default: 120).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best hyperparameters found based on average accuracy.\n",
        "        best_score: The highest average accuracy obtained.\n",
        "    \"\"\"\n",
        "    best_params = None\n",
        "    best_score = float('-inf')\n",
        "    indices = np.arange(data.num_nodes)\n",
        "    maxi=1\n",
        "    for _ in range(num_samples):\n",
        "        print(\"step number \",_)\n",
        "        # Generate random hyperparameters\n",
        "        a1 = random.uniform(0, maxi)     # a1 must be positive\n",
        "        a2 = random.uniform(-maxi, -0.01)  # a2 must be negative\n",
        "        a3 = random.uniform(0, maxi)  # a3 must be negative\n",
        "        a5 = random.uniform(0, maxi)     # a5 must be positive\n",
        "        a4 = random.uniform(0, a5)    # a4 must be positive and a4 <= a5\n",
        "        a6 = random.uniform(0, maxi)\n",
        "        a7 = random.uniform(0, maxi/2)\n",
        "       # a8 = random.uniform(0, a7)\n",
        "        params = [a1, a2, a3, a4, a5, a6,a7]\n",
        "\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, *params)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "\n",
        "        if avg_score > best_score:\n",
        "            best_score = avg_score\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initial guesses for a1, a2, a3, a4, a5\n",
        "#initial_params = [0.5,-5,-2,1,3]\n",
        "\n",
        "# Bounds for parameters\n",
        " # Adjust bounds as needed\n",
        "\n",
        "# Optimize using scipy\n",
        "result,best_val = random_search(predictclass,data,num_samples=15,num_splits=5)\n",
        "#print(result)\n",
        "# Get best parameters\n",
        "best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7 = result[0],result[1],result[2],result[3],result[4],result[5],result[6]\n",
        "\n",
        "# Evaluate on test set\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(\"best validation by random search:\", best_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqOUOkBf6ACE",
        "outputId": "bbc7231e-4487-405e-89a5-f13ddafcd618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial_params= [0.10586410945215707, -0.3230484442645478, 0.48531631726553803, 0.18185173976035238, 0.44006249705484113, 0.5350546526336548, 0.48356491277508173]\n",
            "best_validation by Bayesian= 0.8683137254901961\n",
            "best params found = [0.0, -0.010000000000000009, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
            "\n",
            "🎯 Final Val Set Accuracy: 0.86\n",
            "151 151\n",
            "\n",
            "🎯 Final Test Set Accuracy: 0.847682119205298\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from skopt.space import Real\n",
        "from skopt import gp_minimize\n",
        "def bayesian_optimization(model, data, num_calls=10, num_splits=5, initial_params=None):\n",
        "    \"\"\"\n",
        "    Bayesian Optimization to find best hyperparameters (a1, a2, a3, a4, a5, a6)\n",
        "    that maximize the validation accuracy while evaluating across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function that takes (data, train_idx, val_idx, a1, a2, a3, a4, a5, a6) and returns (loss, accuracy)\n",
        "        data: Dataset object.\n",
        "        num_calls: Number of function evaluations (default: 30).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "        initial_params: Optional initial solution from random search.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best found values for [a1, a2, a3, a4, a5, a6].\n",
        "        best_accuracy: The best validation accuracy found.\n",
        "    \"\"\"\n",
        "    maxi=1\n",
        "    search_space = [\n",
        "        Real(0, maxi, name=\"a1\"),        # a1 must be positive\n",
        "        Real(-maxi, -0.01, name=\"a2\"),   # a2 must be negative\n",
        "        Real(0, maxi, name=\"a3\"),   # a3 must be negative\n",
        "        Real(0, maxi, name=\"a4\"),        # a4 must be positive and a4 ≤ a5\n",
        "        Real(0, maxi, name=\"a5\"),        # a5 must be positive\n",
        "        Real(0, maxi, name=\"a6\"),\n",
        "        Real(0, maxi/2, name=\"a7\") , # a6 must be positive\n",
        "       # Real(0, maxi, name=\"a8\")\n",
        "    ]\n",
        "\n",
        "    indices = np.arange(data.num_nodes)\n",
        "\n",
        "    def objective(params):\n",
        "        a1, a2, a3, a4, a5, a6,a7 = params\n",
        "        a4, a5 = min(a4, a5), max(a4, a5)  # Ensure a4 ≤ a5\n",
        "       # a8, a7 = min(a8, a7), max(a8, a7)\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, a1, a2, a3, a4, a5, a6,a7)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "        return -avg_score  # Since `gp_minimize` minimizes the function, we negate accuracy\n",
        "\n",
        "    if initial_params is not None:\n",
        "        print(\"initial_params=\",initial_params)\n",
        "        initial_params[3], initial_params[4] = min(initial_params[3], initial_params[4]), max(initial_params[3], initial_params[4])\n",
        "\n",
        "        #initial_params[7], initial_params[6] = min(initial_params[7], initial_params[6]), max(initial_params[7], initial_params[6])\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, x0=[initial_params], random_state=None)\n",
        "    else:\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, random_state=None)\n",
        "\n",
        "    best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7 = result.x\n",
        "    best_a4, best_a5 = min(best_a4, best_a5), max(best_a4, best_a5)  # Ensure a4 ≤ a5\n",
        "    #best_a8, best_a7 = min(best_a8, best_a7), max(best_a8, best_a7)\n",
        "    best_accuracy = -result.fun\n",
        "\n",
        "    best_params = [best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7]\n",
        "\n",
        "    return best_params, best_accuracy\n",
        "\n",
        "# Example Usage:\n",
        "best_params, best_validation_score = bayesian_optimization(predictclass, data, num_calls=30, initial_params=result)\n",
        "\n",
        "print(\"best_validation by Bayesian=\",best_validation_score)\n",
        "if best_validation_score<best_val:\n",
        "  print(\"Bayesian made the parameters worse\")\n",
        "  best_params=result\n",
        "else:\n",
        "  best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7 = best_params\n",
        "print(\"best params found =\", best_params)\n",
        "\n",
        "# # # # Step 2: Test the Model Using the Best Parameters\n",
        "y_pred_test, final_test_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7)\n",
        "\n",
        "y_pred_val, final_val_accuracy = predictclass(data, train_idx, val_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7)\n",
        "\n",
        "# # # Step 3: Print the Final Accuracy on the Test Set\n",
        "print(\"\\n🎯 Final Val Set Accuracy:\", final_val_accuracy)\n",
        "\n",
        "\n",
        "print(len(y_pred_test),len(test_idx))\n",
        "\n",
        "print(\"\\n🎯 Final Test Set Accuracy:\", final_test_accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH9DxCcGSpLc",
        "outputId": "6b3822ef-2dc2-4cd6-f617-4665c7fe6777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔄 Iteration 1/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.09229114968873608, -0.17093373371190634, 0.4611500563660065, 0.6822425778238799, 0.7289407921025879, 0.9759890047952606, 0.4826371847802788]\n",
            "🎯 Test Accuracy for iteration 1: 0.8824\n",
            "\n",
            "🔄 Iteration 2/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.08504406208650417, -0.4070233446474596, 0.6416733647023685, 0.15593915845870074, 0.5742085021573553, 0.3514304121138633, 0.3486340840115086]\n",
            "🎯 Test Accuracy for iteration 2: 0.8235\n",
            "\n",
            "🔄 Iteration 3/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.1547072631017744, -0.10858013907611153, 0.7755720245613833, 0.20306603874320286, 0.3047793271003879, 0.7647318692613151, 0.06559406043647781]\n",
            "🎯 Test Accuracy for iteration 3: 0.7647\n",
            "\n",
            "🔄 Iteration 4/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.015344727478149855, -0.30078093720075283, 0.5331171691724839, 0.4920609066631904, 0.8229494194599725, 0.861977425108397, 0.434108169341797]\n",
            "🎯 Test Accuracy for iteration 4: 0.9608\n",
            "\n",
            "🔄 Iteration 5/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.12064919171733912, -0.7417480745257419, 0.8468083268489587, 0.05717055346261439, 0.38085951175772714, 0.15467086368085503, 0.11089331204809244]\n",
            "🎯 Test Accuracy for iteration 5: 0.7647\n",
            "\n",
            "🔄 Iteration 6/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.01869303168388292, -0.20277131991739272, 0.787236948915121, 0.024926220139173654, 0.04819607823858718, 0.42858261570876754, 0.3680748210759279]\n",
            "🎯 Test Accuracy for iteration 6: 0.8824\n",
            "\n",
            "🔄 Iteration 7/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.06897709257627682, -0.4311604990033958, 0.8332620163009695, 0.48152987254348034, 0.504475132664578, 0.2772151738280829, 0.14787692001296865]\n",
            "🎯 Test Accuracy for iteration 7: 0.8431\n",
            "\n",
            "🔄 Iteration 8/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.40102485226564144, -0.14424522730553213, 0.9475764101604585, 0.32102656754149617, 0.49932192339845094, 0.8627266676119428, 0.2225859050587164]\n",
            "🎯 Test Accuracy for iteration 8: 0.9216\n",
            "\n",
            "🔄 Iteration 9/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.0007887712735010766, -0.07142652474058941, 0.48797927714162126, 0.004835923321907964, 0.33156218219149547, 0.2952764774531047, 0.23825969423438143]\n",
            "🎯 Test Accuracy for iteration 9: 0.8627\n",
            "\n",
            "🔄 Iteration 10/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.25798930328082115, -0.3492204534559761, 0.9680387253351234, 0.09665475905076122, 0.41068023705344825, 0.6797618297665349, 0.0446002723832572]\n",
            "🎯 Test Accuracy for iteration 10: 0.9020\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_accuracies = []\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "for run in range(num_iterations):\n",
        "    print(f\"\\n🔄 Iteration {run + 1}/{num_iterations}\")\n",
        "\n",
        "    # Shuffle indices\n",
        "    indices = np.arange(data.num_nodes)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Step 1: Split into 80% train+validation and 20% test\n",
        "    train_val_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=run)\n",
        "\n",
        "    # Step 2: Split train+validation into 75% train and 25% validation\n",
        "    train_idx, val_idx = train_test_split(train_val_idx, test_size=0.25, random_state=run)\n",
        "    # (0.25 * 80%) = 20% of total, so remaining 60% is train\n",
        "\n",
        "    # Now we have:\n",
        "    # - train_idx (60% of total)\n",
        "    # - val_idx (20% of total)\n",
        "    # - test_idx (20% of total)\n",
        "\n",
        "    # Run hyperparameter tuning\n",
        "    best_params_random, best_val_random = random_search(predictclass, data, num_samples=15, num_splits=5)\n",
        "\n",
        "    best_params_bayes, best_val_bayes = bayesian_optimization(predictclass, data, num_calls=30, initial_params=best_params_random)\n",
        "\n",
        "    best_params = best_params_bayes if best_val_bayes >= best_val_random else best_params_random\n",
        "\n",
        "    # Extract optimized hyperparameters\n",
        "    best_a1, best_a2, best_a3, best_a4, best_a5, best_a6, best_a7 = best_params\n",
        "\n",
        "    # Run predictclass with best parameters on test set\n",
        "    _, final_test_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5, best_a6, best_a7)\n",
        "\n",
        "    # Store the result\n",
        "    test_accuracies.append(final_test_accuracy)\n",
        "\n",
        "    print(f\"🎯 Test Accuracy for iteration {run + 1}: {final_test_accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gbhUt_lv1Vh_",
        "outputId": "aaa6f39c-01ef-446d-dce3-ab2c9608fefd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 0.8608, Std: 0.0604\n"
          ]
        }
      ],
      "source": [
        "mean_accuracy = np.mean(test_accuracies)\n",
        "std_accuracy = np.std(test_accuracies)\n",
        "\n",
        "print(f\"Mean: {mean_accuracy:.4f}, Std: {std_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c_sXm_FtUhXF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.nn import Linear, Sequential, ReLU, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class HighPassConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, amp=0.5, **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(**kwargs)\n",
        "        self.amp = amp\n",
        "        self.lin = Linear(in_channels, out_channels)\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.lin(x)\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "        out = self.amp * x - out\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "class Augmenter(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, amp=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = HighPassConv(in_dim, hidden_dim, amp=amp)\n",
        "        self.conv2 = HighPassConv(hidden_dim, hidden_dim, amp=amp)\n",
        "        self.mlp_edge_model = Sequential(\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim, hidden_dim * 2),\n",
        "            ReLU(),\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        src, dst = edge_index[0], edge_index[1]\n",
        "        edge_emb = x[src] + x[dst]\n",
        "        return torch.sigmoid(self.mlp_edge_model(edge_emb))\n",
        "\n",
        "class HeterophilicNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds=None):\n",
        "        super().__init__()\n",
        "        self.augmenter = Augmenter(in_dim, hidden_dim)\n",
        "        self.gnn_high = HighPassConv(in_dim, hidden_dim)\n",
        "        self.offset_mlp = Sequential(\n",
        "            Linear(in_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.final_mlp = Sequential(\n",
        "            Linear(hidden_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self.test_indices = test_indices  # Store test indices\n",
        "\n",
        "        # Store initial predictions but only for test indices (not trained)\n",
        "        if initial_preds is not None:\n",
        "            self.initial_preds = F.one_hot(initial_preds.long(), num_classes=num_classes).float()\n",
        "        else:\n",
        "            self.initial_preds = None\n",
        "\n",
        "    def forward(self, x, edge_index, train_indices):\n",
        "        edge_weights = self.augmenter(x, edge_index)\n",
        "        h = self.gnn_high(x, edge_index, edge_weights)\n",
        "        offset = self.offset_mlp(x)\n",
        "        logits = self.final_mlp(h + offset)\n",
        "\n",
        "        # If initial_preds exists, add it **only for test nodes**\n",
        "        if self.initial_preds is not None:\n",
        "            logits[self.test_indices] = logits[self.test_indices] + self.initial_preds\n",
        "\n",
        "        return F.log_softmax(logits, dim=1)\n",
        "\n",
        "# Training and Evaluation Code\n",
        "def train_and_evaluate(model, data, train_indices, test_indices, initial_preds, epochs=2000, lr=0.01):\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        loss = criterion(logits[train_indices], data.y[train_indices])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        predicted_classes = torch.argmax(logits, dim=1)\n",
        "        test_predictions = predicted_classes[test_indices]\n",
        "        final_accuracy = accuracy_score(data.y[test_indices].cpu().numpy(), test_predictions.cpu().numpy())\n",
        "\n",
        "    return final_accuracy, test_predictions\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TtC0NBH7UhKO",
        "outputId": "33f5deeb-5a77-41c6-915b-653a038cec57"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "predictclass() missing 1 required positional argument: 'a7'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6b35ef64a2e5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute initial test predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minitial_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_a6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Ensure `initial_preds` is a tensor and on the correct device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minitial_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensures a proper detached copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predictclass() missing 1 required positional argument: 'a7'"
          ]
        }
      ],
      "source": [
        "# Compute initial test predictions\n",
        "initial_preds, initial_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6)\n",
        "\n",
        "# Ensure `initial_preds` is a tensor and on the correct device\n",
        "initial_preds = initial_preds.clone().detach()  # Ensures a proper detached copy\n",
        "\n",
        "\n",
        "print(f\"📊 Initial Classification Accuracy: {initial_accuracy:.4f}\")\n",
        "\n",
        "# Create the model\n",
        "model = HeterophilicNodeClassifier(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=len(set(data.y.tolist())),test_indices=test_indices, initial_preds=initial_preds\n",
        ").to(data.x.device)  # Ensure model is on the correct device\n",
        "\n",
        "# 🔄 Train the model before inference\n",
        "final_accuracy_before_djgnn, test_predictions_before_djgnn = train_and_evaluate(\n",
        "    model, data, train_idx, test_idx, initial_preds, epochs=100, lr=0.01\n",
        ")\n",
        "\n",
        "print(len(test_predictions_before_djgnn),len(test_idx))\n",
        "\n",
        "# ✅ Model evaluation after training\n",
        "model.eval()\n",
        "#with torch.no_grad():\n",
        " #   logits = model(data.x, data.edge_index, train_idx, test_idx, initial_test_preds=initial_preds)\n",
        " #   predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "\n",
        "print(f\"🎯  Classification Accuracy after running kdd2023: {final_accuracy_before_djgnn:.4f}\")\n",
        "#print(test_predictions)\n",
        "#print(len(initial_preds))\n",
        "#print(len(test_predictions))\n",
        "\n",
        "#print(len(val_idx))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nZSz76h8VGIZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class DJGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds, n_jumps=5, dropout=0.5):\n",
        "        super(DJGNN, self).__init__()\n",
        "        self.n_jumps = n_jumps\n",
        "        self.dropout = dropout\n",
        "        self.att = nn.Parameter(torch.ones(n_jumps + 1))  # Attention weights for jumps\n",
        "        self.sm = nn.Softmax(dim=0)\n",
        "\n",
        "        # Store initial predictions (converted to one-hot)\n",
        "        self.test_indices = test_indices\n",
        "        self.initial_preds = nn.Parameter(F.one_hot(initial_preds, num_classes).float(), requires_grad=False)\n",
        "\n",
        "        # GCN layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(n_jumps):\n",
        "            self.convs.append(GCNConv(in_dim, hidden_dim))\n",
        "\n",
        "        # Extra convolution layers\n",
        "        self.conv_extra = GCNConv(in_dim, hidden_dim)\n",
        "        self.bn_extra = nn.BatchNorm1d(hidden_dim)\n",
        "        self.conv_extra2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.bn_extra_2 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        # Final classifier\n",
        "        self.classify = nn.Linear(hidden_dim * (n_jumps + 1) + num_classes, num_classes)  # Extra input for initial preds\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "      mask_attentions = self.sm(self.att)\n",
        "\n",
        "      # Extra convolutions\n",
        "      extra_conv = self.conv_extra(x, edge_index).relu()\n",
        "      print(f\"extra_conv after conv_extra: {extra_conv.shape}\")\n",
        "      extra_conv = self.bn_extra(extra_conv)\n",
        "      print(f\"extra_conv after bn_extra: {extra_conv.shape}\")\n",
        "      extra_conv = F.dropout(extra_conv, p=self.dropout, training=self.training)\n",
        "      extra_conv = self.conv_extra2(extra_conv, edge_index).relu()\n",
        "      extra_conv = self.bn_extra_2(extra_conv)\n",
        "      extra_conv = extra_conv * mask_attentions[-1]\n",
        "      print(f\"extra_conv after conv_extra2 & mask: {extra_conv.shape}\")\n",
        "\n",
        "      # Jumping knowledge mechanism: collect outputs from each conv layer\n",
        "      z_s = []\n",
        "      for i, conv in enumerate(self.convs):\n",
        "          z = conv(x, edge_index).relu() * mask_attentions[i]\n",
        "          print(f\"z from conv {i}: {z.shape}\")\n",
        "          z_s.append(z)\n",
        "\n",
        "      # Concatenate all jump outputs with extra_conv\n",
        "      final_z = torch.cat(z_s + [extra_conv], dim=1)\n",
        "      print(f\"✅ final_z shape BEFORE concatenation: {final_z.shape}\")  # Expect [num_nodes, feature_dim]\n",
        "\n",
        "      # Debug: Print test indices shape and the slice from final_z\n",
        "      print(f\"✅ self.test_indices shape: {self.test_indices.shape}\")  # Expect [num_test_samples]\n",
        "      test_slice = final_z[self.test_indices]\n",
        "      print(f\"✅ final_z[self.test_indices] shape: {test_slice.shape}\")  # Expect [num_test_samples, feature_dim]\n",
        "\n",
        "      # Ensure self.initial_preds is a LongTensor\n",
        "      num_classes = self.classify.out_features  # Get number of classes\n",
        "      initial_preds_long = self.initial_preds.long().squeeze()\n",
        "      print(f\"initial_preds_long shape after squeeze: {initial_preds_long.shape}\")\n",
        "\n",
        "      # Clamp indices to valid range\n",
        "      initial_preds_long = torch.clamp(initial_preds_long, min=0, max=num_classes - 1)\n",
        "\n",
        "      # Convert to one-hot encoding\n",
        "      one_hot_preds = F.one_hot(initial_preds_long, num_classes=num_classes).float()\n",
        "      print(f\"✅ one_hot_preds shape immediately after one_hot: {one_hot_preds.shape}\")\n",
        "\n",
        "      # If one_hot_preds still has an extra dimension, print its dimensions explicitly\n",
        "      for idx, dim in enumerate(one_hot_preds.shape):\n",
        "          print(f\"one_hot_preds dim {idx}: {dim}\")\n",
        "\n",
        "      # Attempt to remove extra dimensions by squeezing only the dims of size 1\n",
        "      one_hot_preds = one_hot_preds.squeeze()\n",
        "      print(f\"✅ one_hot_preds shape after squeeze(): {one_hot_preds.shape}\")\n",
        "\n",
        "      # Check dimensions explicitly\n",
        "      if one_hot_preds.ndim != 2:\n",
        "          print(f\"❌ one_hot_preds still has {one_hot_preds.ndim} dimensions; expected 2 dimensions!\")\n",
        "\n",
        "      # Now, try concatenation and catch errors with more prints\n",
        "      try:\n",
        "          final_z[self.test_indices] = torch.cat((final_z[self.test_indices], one_hot_preds), dim=1)\n",
        "      except RuntimeError as e:\n",
        "          print(f\"❌ ERROR: Shape mismatch at concatenation!\")\n",
        "          print(f\"🔍 final_z[self.test_indices] shape: {final_z[self.test_indices].shape}\")\n",
        "          print(f\"🔍 one_hot_preds shape: {one_hot_preds.shape}\")\n",
        "          raise e  # Re-raise after printing shapes\n",
        "\n",
        "      # Dropout and classification\n",
        "      final_z = F.dropout(final_z, p=self.dropout, training=self.training)\n",
        "      logits = self.classify(final_z).log_softmax(dim=-1)\n",
        "      return logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cldUM1jPk72E"
      },
      "outputs": [],
      "source": [
        "def train_djgnn(model, data, train_idx, test_idx, initial_preds_djgnn, epochs=100, lr=0.01):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(data.x, data.edge_index)\n",
        "        loss_supervised = criterion(logits[train_idx], data.y[train_idx])\n",
        "\n",
        "        # 🔥 NEW: Consistency Loss to prevent drastic changes\n",
        "        confidence_threshold = 0.85  # Change only high-confidence nodes\n",
        "        high_confidence_mask = logits[test_idx].softmax(dim=1).max(dim=1).values > confidence_threshold\n",
        "\n",
        "        # Apply consistency loss only to confident predictions\n",
        "        filtered_loss = F.cross_entropy(logits[test_idx][high_confidence_mask], initial_preds_djgnn[high_confidence_mask])\n",
        "        loss = loss_supervised + 0.1 * filtered_loss\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy on test set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_logits = model(data.x, data.edge_index)\n",
        "            test_preds = test_logits[test_idx].argmax(dim=1)\n",
        "            test_correct = (test_preds == data.y[test_idx]).sum().item()\n",
        "            test_acc = test_correct / len(test_idx)\n",
        "\n",
        "    #    print(f\"🧐 Epoch {epoch+1:02d} | Loss: {loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "       # if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "       #     print(f\"🔍 Logits Before Argmax (First 5 Samples):\\n{test_logits[test_idx][:5]}\")\n",
        "\n",
        "    return test_preds, test_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p936LZ0GlGf3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Ensure `initial_preds_djgnn` is a tensor and detached\n",
        "initial_preds_djgnn = test_predictions_before_djgnn.clone().detach().long()  # Explicitly convert to LongTensor\n",
        "initial_preds = initial_preds.clone().detach().long()\n",
        "\n",
        "# Get the number of unique classes from `data.y`\n",
        "num_classes = data.y.max().item() + 1  # `max() + 1` ensures it captures all labels\n",
        "\n",
        "print(f\"📊 Number of Test Samples: {len(initial_preds_djgnn)}\")\n",
        "print(f\"🔢 Number of Unique Classes: {num_classes}\")\n",
        "\n",
        "# 🚀 Initialize DJ-GNN model with test indices & initial predictions\n",
        "djgnn_model = DJGNN(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=num_classes,  # Use the correct `num_classes`\n",
        "    test_indices=torch.tensor(test_idx, dtype=torch.long, device=data.x.device),  # Ensure `test_idx` is a tensor\n",
        "    initial_preds=initial_preds_djgnn,  # Pass initial predictions (already `LongTensor`)\n",
        "    n_jumps=5,  # Use 5 hops for diffusion\n",
        "    dropout=0.5\n",
        ").to(data.x.device)  # Ensure it's on the correct device\n",
        "\n",
        "# 🚀 Train DJ-GNN and get new predictions\n",
        "new_preds, final_accuracy_after_djgnn = train_djgnn(\n",
        "    djgnn_model, data, train_idx, test_idx, initial_preds_djgnn, epochs=500, lr=0.01\n",
        ")\n",
        "\n",
        "# 🎯 Compare accuracies before & after DJ-GNN\n",
        "print(\"\\n🔥 Final Results:\")\n",
        "print(f\"🎯 Accuracy BEFORE DJ-GNN: {final_accuracy_before_djgnn:.4f}\")\n",
        "print(f\"🚀 Accuracy AFTER DJ-GNN: {final_accuracy_after_djgnn:.4f}\")\n",
        "\n",
        "# 🔍 Sample Predictions Before & After DJ-GNN (Print first 10 for debugging)\n",
        "print(\"\\n🔍 Sample Predictions Before & After DJ-GNN:\")\n",
        "for i in range(min(10, len(test_idx))):  # Ensure we don't go out of bounds\n",
        "    print(f\"🧐 Sample {i+1} | Before: {initial_preds_djgnn[i].item()} | After: {new_preds[i].item()}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}