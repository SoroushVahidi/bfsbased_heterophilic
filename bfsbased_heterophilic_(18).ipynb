{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqGs0nK9M8Kq",
        "outputId": "54b3946f-2b23-45cc-ef51-bc055c0a7317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.11/dist-packages (12.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gurobipy\n",
        "!pip install torch_geometric\n",
        "!pip install sortedcontainers\n",
        "\n",
        "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "!pip install scikit-optimize\n",
        "\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import pairwise_distances as sklearn_pairwise_distances\n",
        "import networkx as nx\n",
        " # Use \"cosine\" for cosine similarity\n",
        "import heapq\n",
        "\n",
        "\n",
        "os.environ[\"GRB_LICENSE_FILE\"] = \"gurobi (3).lic\"\n",
        "os.environ[\"GRB_WLSACCESSID\"] = \"f218200d-1f8d-4342-83f5-b7b2d9263751\"  # Replace with your actual WLSACCESSID\n",
        "os.environ[\"GRB_WLSSECRET\"] = \"528d596b-babc-4a1e-bda2-693c44f4f006\"  # Replace with your actual WLSSECRET\n",
        "os.environ[\"GRB_LICENSEID\"] = \"840285\"  # Replace with your actual LICENSEID\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from torch_geometric.datasets import WebKB, WikipediaNetwork, Actor\n",
        "\n",
        "from torch_geometric.datasets import FacebookPagePage\n",
        "\n",
        "from torch_geometric.datasets import SNAPDataset\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import networkx as nx\n",
        "from torch_geometric.datasets import WebKB\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sortedcontainers import SortedSet  # Ordered set\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "from torch_geometric.datasets import WikipediaNetwork\n",
        "from torch_geometric.datasets import Actor\n",
        "\n",
        "# Load the Film dataset (also known as Actor dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD28jxmhNmm5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZChMrfbyNoOn"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "#dataset = Actor(root='data/Film')\n",
        "data = dataset[0]\n",
        "data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "\n",
        "# âœ… Remove duplicate edges\n",
        "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "# âœ… Convert to NetworkX Graph to Find Components\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "components = list(nx.connected_components(G))\n",
        "num_components = len(components)\n",
        "\n",
        "print(f\"\\nâœ… Loaded  dataset with {data.num_nodes} nodes, {data.edge_index.shape[1]} edges\")\n",
        "print(f\"   - Features: {data.x.shape[1]}\")\n",
        "print(f\"   - Number of Classes: {len(set(data.y.numpy()))}\")\n",
        "print(f\"   - Number of Components: {num_components}\")\n",
        "\n",
        "# âœ… Set Training Percentage\n",
        "train_percentage = 0.65\n",
        "\n",
        "# âœ… Select Training Nodes\n",
        "train_indices = []\n",
        "for component in components:\n",
        "    component = list(component)\n",
        "    t = max(1, int(train_percentage * len(component)))\n",
        "    sampled_nodes = np.random.choice(component, t, replace=False)\n",
        "    train_indices.extend(sampled_nodes)\n",
        "\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "# âœ… Initialize Prediction Labels\n",
        "y_pred = np.full(data.num_nodes, -1)\n",
        "for idx in train_indices:\n",
        "    y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "# âœ… Compute Label Distribution\n",
        "total_label_counts = Counter(data.y.numpy())\n",
        "num_labels = len(set(data.y.numpy()))\n",
        "alpha = 1  # Laplace smoothing\n",
        "\n",
        "dataset_label_distribution = {\n",
        "    lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "    for lbl in total_label_counts.keys()\n",
        "}\n",
        "\n",
        "train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "train_label_distribution = {\n",
        "    lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "    for lbl in dataset_label_distribution.keys()\n",
        "}\n",
        "\n",
        "# âœ… Precompute Neighbors for Each Node\n",
        "A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "A = A.numpy()\n",
        "neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "# âœ… Track Instances Assigned to Each Label\n",
        "class_instances = defaultdict(set)\n",
        "for idx in train_indices:\n",
        "    class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "# âœ… Ordered Set for Managing Unlabeled Vertices\n",
        "ordered_set = SortedSet()\n",
        "train_labeled_nodes = set(train_indices)\n",
        "\n",
        "for node in range(data.num_nodes):\n",
        "    if y_pred[node] == -1:  # Only process unlabeled nodes\n",
        "        labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "        num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "        total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "        if total_neighbors > 0:\n",
        "            weighted_score = (num_labeled_by_propagation + 3 * num_labeled_by_train) / total_neighbors\n",
        "        else:\n",
        "            weighted_score = 0\n",
        "\n",
        "        ordered_set.add((-weighted_score, node))\n",
        "\n",
        "# âœ… Iteratively Label the Most Constrained Nodes\n",
        "while ordered_set:\n",
        "    _, node = ordered_set.pop(0)\n",
        "\n",
        "    if y_pred[node] != -1:\n",
        "        continue\n",
        "\n",
        "    # Get labeled neighbors\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    # ðŸš¨ If this node has 0 labeled neighbors\n",
        "    if not neighbor_labels:\n",
        "        print(f\"\\nðŸš¨ STRANGE: Node {node} was chosen, but it has 0 labeled neighbors!\")\n",
        "        break\n",
        "\n",
        "    # Compute Neighbor Label Distribution\n",
        "    neighbor_label_counts = Counter(neighbor_labels)\n",
        "    total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "    if total_labeled_neighbors > 0:\n",
        "        neighbor_label_distribution = {\n",
        "            lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "        }\n",
        "    else:\n",
        "        neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # âœ… Compute Feature Distance to Each Class\n",
        "    # feature_diffs = {}\n",
        "    # for lbl in dataset_label_distribution.keys():\n",
        "    #   if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "    #       instance_features = data.x[list(class_instances[lbl])]\n",
        "    #       node_feature = data.x[node].unsqueeze(0)\n",
        "\n",
        "    #       # Compute distances for each instance\n",
        "    #       distances = torch.norm(instance_features - node_feature, dim=1).tolist()\n",
        "\n",
        "    #       # Apply weight based on whether the instance is from training or predicted labels\n",
        "    #       weighted_distances = [\n",
        "    #           (3 * dist) if instance in train_indices else dist  # Give 3x weight if in training set\n",
        "    #           for instance, dist in zip(class_instances[lbl], distances)\n",
        "    #       ]\n",
        "\n",
        "    #       # Compute weighted average distance\n",
        "    #       avg_distance = sum(weighted_distances) / len(weighted_distances)\n",
        "    #       feature_diffs[lbl] = avg_distance\n",
        "    #   else:\n",
        "    #       feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    feature_diffs = {}\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "            instance_features = data.x[list(class_instances[lbl])]\n",
        "            node_feature = data.x[node].unsqueeze(0)\n",
        "           # print(len(instance_features),len(node_feature))\n",
        "            avg_distance = torch.mean(torch.norm(instance_features - node_feature, dim=1)).item()\n",
        "            feature_diffs[lbl] = avg_distance\n",
        "        else:\n",
        "            feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    # âœ… Select the Best Label Based on the Adjusted Score\n",
        "    best_label_candidates = []\n",
        "    max_value = float('-inf')\n",
        "    a1=0.5\n",
        "    a2=-6\n",
        "    a3=-2\n",
        "    a4=1\n",
        "    a5=3\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        score = (\n",
        "            a1*train_label_distribution.get(lbl, 0)\n",
        "            +a2* neighbor_label_distribution.get(lbl, 0)\n",
        "            +a3*feature_diffs[lbl]  # Penalize by average feature distance\n",
        "        )\n",
        "        print(lbl,score,)\n",
        "\n",
        "        if score - max_value > 0.01:\n",
        "            best_label_candidates = [lbl]\n",
        "            max_value = score\n",
        "        elif abs(score - max_value) <= 0.01:\n",
        "            best_label_candidates.append(lbl)\n",
        "\n",
        "\n",
        "    best_label = random.choice(best_label_candidates)\n",
        "    y_pred[node] = best_label\n",
        "    class_instances[best_label].add(node)  # Track newly labeled nodes\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    print(f\"\\nðŸ”¹ Labelling Node {node} \")\n",
        "    # âœ… Print Prediction Outcome\n",
        "    true_label = data.y[node].item()\n",
        "    correct = \"âœ…\" if best_label == true_label else \"âŒ\"\n",
        "    print(f\"   -> Predicted Label: {best_label} | True Label: {true_label} {correct}\")\n",
        "\n",
        "   # print(f\"   - Total Neighbors: {len(neighbors_dict[node])}\")\n",
        "   # print(f\"   - Labeled Neighbors: {len(neighbor_labels)}\")\n",
        "    for lbl, count in label_counts.items():\n",
        "        print(f\"   - Class {lbl}: {count} neighbors\")\n",
        "        # âœ… Update Labeled Neighbor Score for Unlabeled Neighbors\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                new_weighted_score = (a4*num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "# âœ… Evaluate Accuracy\n",
        "test_indices = [i for i in range(data.num_nodes) if i not in train_indices]\n",
        "y_true = data.y[test_indices]\n",
        "y_pred_test = y_pred[test_indices]\n",
        "\n",
        "valid_idx = [i for i in range(len(y_pred_test)) if y_pred_test[i] != -1]\n",
        "if valid_idx:\n",
        "    final_accuracy = accuracy_score(y_true[valid_idx], y_pred_test[valid_idx])\n",
        "    print(f\"\\nðŸŽ¯ Label Propagation Accuracy: {final_accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"\\nâŒ No valid predictions were made!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru9be0GZSBHA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sortedcontainers import SortedSet\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sortedcontainers import SortedSet\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predictclass(data, train_indices, test_indices, a1, a2, a3, a4, a5, a6, a7):\n",
        "   # print(f\"data.x shape: {data.x.shape}\")\n",
        "    data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "    train_indices = list(train_indices)\n",
        "    test_indices = list(test_indices)\n",
        "\n",
        "    # âœ… Remove duplicate edges\n",
        "    data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "    # âœ… Initialize Prediction Labels\n",
        "    y_pred = np.full(data.num_nodes, -1, dtype=int)\n",
        "    for idx in train_indices:\n",
        "        y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "    # âœ… Compute Label Distribution\n",
        "    total_label_counts = Counter(data.y.numpy())\n",
        "    num_labels = len(set(data.y.numpy()))\n",
        "    alpha = 1  # Laplace smoothing\n",
        "\n",
        "    dataset_label_distribution = {\n",
        "        lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "        for lbl in total_label_counts.keys()\n",
        "    }\n",
        "\n",
        "    train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "    train_label_distribution = {\n",
        "        lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "        for lbl in dataset_label_distribution.keys()\n",
        "    }\n",
        "\n",
        "    # âœ… Precompute Neighbors for Each Node\n",
        "    A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "    A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "    neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "    # âœ… Track Instances Assigned to Each Label\n",
        "    class_instances = defaultdict(set)\n",
        "    for idx in train_indices:\n",
        "        class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "    # âœ… Initialize D Table (Similarity Table)\n",
        "    D = {i: {lbl: 0.0 for lbl in dataset_label_distribution.keys()} for i in range(data.num_nodes)}\n",
        "    class_counts = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # âœ… Compute Average Feature Vector Once Per Label\n",
        "    avg_features = {}\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if class_instances[lbl]:\n",
        "            instance_list = list(map(int, class_instances[lbl]))  # Ensure list of Python ints\n",
        "            instance_list = torch.tensor(instance_list, dtype=torch.long)  # Convert to PyTorch tensor\n",
        "\n",
        "            instance_features = data.x[instance_list]\n",
        "            instance_weights = torch.tensor(\n",
        "                [(1 - a7) if inst in train_indices else a7 for inst in instance_list],\n",
        "                dtype=torch.float,\n",
        "                device=data.x.device\n",
        "            )\n",
        "            instance_weights /= instance_weights.sum()\n",
        "            avg_features[lbl] = torch.sum(instance_features * instance_weights.view(-1, 1), dim=0, keepdim=True)\n",
        "\n",
        "    # âœ… Compute Similarity for Each Unlabeled Node\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if lbl in avg_features:\n",
        "            for i in range(data.num_nodes):\n",
        "                similarity = F.cosine_similarity(data.x[i].unsqueeze(0), avg_features[lbl]).item()\n",
        "                D[i][lbl] = (similarity + 1) / 2\n",
        "\n",
        "    # âœ… Ordered Set for Managing Unlabeled Vertices\n",
        "    ordered_set = SortedSet()\n",
        "    train_labeled_nodes = set(train_indices)\n",
        "    labeled_nodes_count = 0\n",
        "\n",
        "    for node in range(data.num_nodes):\n",
        "        if y_pred[node] == -1:\n",
        "            labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "            num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "            num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "            total_neighbors = len(neighbors_dict[node])\n",
        "            weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "            similarity_score = max(D[node].values()) if D[node] else 0\n",
        "            ordered_set.add((-weighted_score - a6 * similarity_score, node))\n",
        "\n",
        "    while ordered_set:\n",
        "        _, node = ordered_set.pop(0)\n",
        "\n",
        "        if y_pred[node] != -1:\n",
        "            continue\n",
        "            print(\"This node is already labeled. Something is wrong.\")\n",
        "\n",
        "        neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "\n",
        "\n",
        "        neighbor_label_counts = Counter(neighbor_labels)\n",
        "        total_labeled_neighbors = len(neighbor_labels)\n",
        "        neighbor_label_distribution = {\n",
        "            lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "        } if total_labeled_neighbors > 0 else {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        label_similarity = {lbl: D[node][lbl] for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        best_label_candidates = []\n",
        "        max_value = float('-inf')\n",
        "\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            score = (\n",
        "                a1 * train_label_distribution.get(lbl, 0)\n",
        "                + a2 * neighbor_label_distribution.get(lbl, 0)\n",
        "                + a3 * label_similarity[lbl]\n",
        "            )\n",
        "\n",
        "            if score - max_value > 0.01:\n",
        "                best_label_candidates = [lbl]\n",
        "                max_value = score\n",
        "            elif abs(score - max_value) <= 0.01:\n",
        "                best_label_candidates.append(lbl)\n",
        "\n",
        "        best_label = random.choice(best_label_candidates)\n",
        "        y_pred[node] = best_label\n",
        "        class_instances[best_label].add(node)\n",
        "        class_counts[best_label] += 1\n",
        "        labeled_nodes_count += 1\n",
        "\n",
        "\n",
        "\n",
        "        if labeled_nodes_count % (data.num_nodes // 5) == 0 == 0:\n",
        "            avg_features = {}\n",
        "            for lbl in dataset_label_distribution.keys():\n",
        "                if class_instances[lbl]:\n",
        "                    instance_list = list(class_instances[lbl])\n",
        "                    instance_list = list(map(int, class_instances[lbl]))  # Ensure list of Python ints\n",
        "                    instance_list = torch.tensor(instance_list, dtype=torch.long)  # Convert to PyTorch tensor\n",
        "\n",
        "                    instance_features = data.x[instance_list]  # Now indexing should work\n",
        "\n",
        "                    instance_weights = torch.tensor(\n",
        "                        [(1 - a7) if inst in train_indices else a7 for inst in instance_list],\n",
        "                        dtype=torch.float,\n",
        "                        device=data.x.device\n",
        "                    )\n",
        "                    instance_weights /= instance_weights.sum()\n",
        "                    avg_features[lbl] = torch.sum(instance_features * instance_weights.view(-1, 1), dim=0, keepdim=True)\n",
        "\n",
        "            for lbl in dataset_label_distribution.keys():\n",
        "                if lbl in avg_features:\n",
        "                    for i in range(data.num_nodes):\n",
        "                        similarity = F.cosine_similarity(data.x[i].unsqueeze(0), avg_features[lbl]).item()\n",
        "                        D[i][lbl] = (similarity + 1) / 2\n",
        "\n",
        "            # âœ… Update Scores in Ordered Set\n",
        "            new_ordered_set = SortedSet()\n",
        "            for node in range(data.num_nodes):\n",
        "                if y_pred[node] == -1:\n",
        "                    labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "                    num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "                    num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "                    total_neighbors = len(neighbors_dict[node])\n",
        "                    weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "                    similarity_score = max(D[node].values()) if D[node] else 0\n",
        "                    new_ordered_set.add((-weighted_score - a6 * similarity_score, node))\n",
        "            ordered_set = new_ordered_set\n",
        "\n",
        "    return torch.tensor(y_pred[test_indices], dtype=torch.float), accuracy_score(data.y[test_indices], y_pred[test_indices])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqUQNrZolOwy"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "\n",
        "# Count occurrences of each class label\n",
        "class_counts = torch.bincount(data.y)\n",
        "\n",
        "# Print the number of elements in each class\n",
        "for class_id, count in enumerate(class_counts):\n",
        "    print(f\"Class {class_id}: {count} elements\")\n",
        "a1=0.5\n",
        "a2=-6\n",
        "a3=-2\n",
        "a4=1\n",
        "a5=3\n",
        "a6=1\n",
        "\n",
        "indices = np.arange(data.num_nodes)  # NumPy array of indices [0, 1, 2, ..., num_nodes-1]\n",
        "np.random.shuffle(indices)\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.6)\n",
        "\n",
        "# Further split train_idx into train and validation sets (e.g., 20% of train goes to validation)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.5)\n",
        "test_indices=test_idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u88m8qZfUdX-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsMOjg0RUedb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88eDCyKNUf57"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWZxuxXlygBh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import KFold\n",
        "import warnings\n",
        "warnings.simplefilter(\"error\", RuntimeWarning)  # Convert warnings to errors\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "\n",
        "\n",
        "\n",
        "def random_search(model, data, num_samples=50, num_splits=5):\n",
        "    \"\"\"\n",
        "    Perform random search for hyperparameter tuning while evaluating each set\n",
        "    of hyperparameters across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function to predict classes.\n",
        "        data: Dataset object.\n",
        "        num_samples: Number of random search samples (default: 120).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best hyperparameters found based on average accuracy.\n",
        "        best_score: The highest average accuracy obtained.\n",
        "    \"\"\"\n",
        "    best_params = None\n",
        "    best_score = float('-inf')\n",
        "    indices = np.arange(data.num_nodes)\n",
        "    maxi=1\n",
        "    for _ in range(num_samples):\n",
        "        print(\"step number \",_)\n",
        "        # Generate random hyperparameters\n",
        "        a1 = random.uniform(0, maxi)     # a1 must be positive\n",
        "        a2 = random.uniform(-maxi, -0.01)  # a2 must be negative\n",
        "        a3 = random.uniform(0, maxi)  # a3 must be negative\n",
        "        a5 = random.uniform(0, maxi)     # a5 must be positive\n",
        "        a4 = random.uniform(0, a5)    # a4 must be positive and a4 <= a5\n",
        "        a6 = random.uniform(0, maxi)\n",
        "        a7 = random.uniform(0, maxi/2)\n",
        "       # a8 = random.uniform(0, a7)\n",
        "        params = [a1, a2, a3, a4, a5, a6,a7]\n",
        "\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, *params)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "\n",
        "        if avg_score > best_score:\n",
        "            best_score = avg_score\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initial guesses for a1, a2, a3, a4, a5\n",
        "#initial_params = [0.5,-5,-2,1,3]\n",
        "\n",
        "# Bounds for parameters\n",
        " # Adjust bounds as needed\n",
        "\n",
        "# Optimize using scipy\n",
        "result,best_val = random_search(predictclass,data,num_samples=15,num_splits=5)\n",
        "#print(result)\n",
        "# Get best parameters\n",
        "best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7 = result[0],result[1],result[2],result[3],result[4],result[5],result[6]\n",
        "\n",
        "# Evaluate on test set\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(\"best validation by random search:\", best_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqOUOkBf6ACE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from skopt.space import Real\n",
        "from skopt import gp_minimize\n",
        "def bayesian_optimization(model, data, num_calls=10, num_splits=5, initial_params=None):\n",
        "    \"\"\"\n",
        "    Bayesian Optimization to find best hyperparameters (a1, a2, a3, a4, a5, a6)\n",
        "    that maximize the validation accuracy while evaluating across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function that takes (data, train_idx, val_idx, a1, a2, a3, a4, a5, a6) and returns (loss, accuracy)\n",
        "        data: Dataset object.\n",
        "        num_calls: Number of function evaluations (default: 30).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "        initial_params: Optional initial solution from random search.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best found values for [a1, a2, a3, a4, a5, a6].\n",
        "        best_accuracy: The best validation accuracy found.\n",
        "    \"\"\"\n",
        "    maxi=1\n",
        "    search_space = [\n",
        "        Real(0, maxi, name=\"a1\"),        # a1 must be positive\n",
        "        Real(-maxi, -0.01, name=\"a2\"),   # a2 must be negative\n",
        "        Real(0, maxi, name=\"a3\"),   # a3 must be negative\n",
        "        Real(0, maxi, name=\"a4\"),        # a4 must be positive and a4 â‰¤ a5\n",
        "        Real(0, maxi, name=\"a5\"),        # a5 must be positive\n",
        "        Real(0, maxi, name=\"a6\"),\n",
        "        Real(0, maxi/2, name=\"a7\") , # a6 must be positive\n",
        "       # Real(0, maxi, name=\"a8\")\n",
        "    ]\n",
        "\n",
        "    indices = np.arange(data.num_nodes)\n",
        "\n",
        "    def objective(params):\n",
        "        a1, a2, a3, a4, a5, a6,a7 = params\n",
        "        a4, a5 = min(a4, a5), max(a4, a5)  # Ensure a4 â‰¤ a5\n",
        "       # a8, a7 = min(a8, a7), max(a8, a7)\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, a1, a2, a3, a4, a5, a6,a7)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "        return -avg_score  # Since `gp_minimize` minimizes the function, we negate accuracy\n",
        "\n",
        "    if initial_params is not None:\n",
        "        print(\"initial_params=\",initial_params)\n",
        "        initial_params[3], initial_params[4] = min(initial_params[3], initial_params[4]), max(initial_params[3], initial_params[4])\n",
        "\n",
        "        #initial_params[7], initial_params[6] = min(initial_params[7], initial_params[6]), max(initial_params[7], initial_params[6])\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, x0=[initial_params], random_state=None)\n",
        "    else:\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, random_state=None)\n",
        "\n",
        "    best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7 = result.x\n",
        "    best_a4, best_a5 = min(best_a4, best_a5), max(best_a4, best_a5)  # Ensure a4 â‰¤ a5\n",
        "    #best_a8, best_a7 = min(best_a8, best_a7), max(best_a8, best_a7)\n",
        "    best_accuracy = -result.fun\n",
        "\n",
        "    best_params = [best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7]\n",
        "\n",
        "    return best_params, best_accuracy\n",
        "\n",
        "# Example Usage:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH9DxCcGSpLc"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_accuracies = []\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "for run in range(num_iterations):\n",
        "    print(f\"\\nðŸ”„ Iteration {run + 1}/{num_iterations}\")\n",
        "\n",
        "    indices = np.arange(data.num_nodes)\n",
        "\n",
        "# Step 1: Split into 80% train+validation and 20% test\n",
        "    train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=run, shuffle=True)\n",
        "\n",
        "\n",
        "    train_idx = torch.tensor(train_idx, dtype=torch.long).contiguous()\n",
        "\n",
        "    test_idx = torch.tensor(test_idx, dtype=torch.long).contiguous()\n",
        "\n",
        "\n",
        "    # Now call subgraph()\n",
        "    train_data = data.subgraph(train_idx)\n",
        "    test_data = data.subgraph(test_idx)\n",
        "\n",
        "\n",
        "\n",
        "    # Convert indices to PyTorch tensors for PyG subgraph function\n",
        "    #train_idx = torch.tensor(train_idx, dtype=torch.long)\n",
        "    #test_idx = torch.tensor(test_idx, dtype=torch.long)\n",
        "\n",
        "\n",
        "    # Step 2: Split train+validation into 75% train and 25% validation\n",
        "    #train_idx, val_idx = train_test_split(train_val_idx, test_size=0.25, random_state=run)\n",
        "    # (0.25 * 80%) = 20% of total, so remaining 60% is train\n",
        "\n",
        "    # Now we have:\n",
        "    # - train_idx (60% of total)\n",
        "    # - val_idx (20% of total)\n",
        "    # - test_idx (20% of total)\n",
        "\n",
        "    # Run hyperparameter tuning\n",
        "    best_params_random, best_val_random = random_search(predictclass, train_data, num_samples=15, num_splits=5)\n",
        "\n",
        "    best_params_bayes, best_val_bayes = bayesian_optimization(predictclass, train_data, num_calls=30, initial_params=best_params_random)\n",
        "\n",
        "    best_params = best_params_bayes if best_val_bayes >= best_val_random else best_params_random\n",
        "\n",
        "    # Extract optimized hyperparameters\n",
        "    best_a1, best_a2, best_a3, best_a4, best_a5, best_a6, best_a7 = best_params\n",
        "    #print(\"best params found\")\n",
        "    #print(len(data),len(train_idx),len(test_idx))\n",
        "    #print(data)\n",
        "    # Run predictclass with best parameters on test set\n",
        "    _, final_test_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5, best_a6, best_a7)\n",
        "\n",
        "    # Store the result\n",
        "    test_accuracies.append(final_test_accuracy)\n",
        "\n",
        "    print(f\"ðŸŽ¯ Test Accuracy for iteration {run + 1}: {final_test_accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbhUt_lv1Vh_"
      },
      "outputs": [],
      "source": [
        "mean_accuracy = np.mean(test_accuracies)\n",
        "std_accuracy = np.std(test_accuracies)\n",
        "\n",
        "print(f\"Mean: {mean_accuracy:.4f}, Std: {std_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_sXm_FtUhXF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.nn import Linear, Sequential, ReLU, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class HighPassConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, amp=0.5, **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(**kwargs)\n",
        "        self.amp = amp\n",
        "        self.lin = Linear(in_channels, out_channels)\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.lin(x)\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "        out = self.amp * x - out\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "class Augmenter(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, amp=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = HighPassConv(in_dim, hidden_dim, amp=amp)\n",
        "        self.conv2 = HighPassConv(hidden_dim, hidden_dim, amp=amp)\n",
        "        self.mlp_edge_model = Sequential(\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim, hidden_dim * 2),\n",
        "            ReLU(),\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        src, dst = edge_index[0], edge_index[1]\n",
        "        edge_emb = x[src] + x[dst]\n",
        "        return torch.sigmoid(self.mlp_edge_model(edge_emb))\n",
        "\n",
        "class HeterophilicNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds=None):\n",
        "        super().__init__()\n",
        "        self.augmenter = Augmenter(in_dim, hidden_dim)\n",
        "        self.gnn_high = HighPassConv(in_dim, hidden_dim)\n",
        "        self.offset_mlp = Sequential(\n",
        "            Linear(in_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.final_mlp = Sequential(\n",
        "            Linear(hidden_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self.test_indices = test_indices  # Store test indices\n",
        "\n",
        "        # Store initial predictions but only for test indices (not trained)\n",
        "        if initial_preds is not None:\n",
        "            self.initial_preds = F.one_hot(initial_preds.long(), num_classes=num_classes).float()\n",
        "        else:\n",
        "            self.initial_preds = None\n",
        "\n",
        "    def forward(self, x, edge_index, train_indices):\n",
        "        edge_weights = self.augmenter(x, edge_index)\n",
        "        h = self.gnn_high(x, edge_index, edge_weights)\n",
        "        offset = self.offset_mlp(x)\n",
        "        logits = self.final_mlp(h + offset)\n",
        "\n",
        "        # If initial_preds exists, add it **only for test nodes**\n",
        "        if self.initial_preds is not None:\n",
        "            logits[self.test_indices] = logits[self.test_indices] + self.initial_preds\n",
        "\n",
        "        return F.log_softmax(logits, dim=1)\n",
        "\n",
        "# Training and Evaluation Code\n",
        "def train_and_evaluate(model, data, train_indices, test_indices, initial_preds, epochs=2000, lr=0.01):\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        loss = criterion(logits[train_indices], data.y[train_indices])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        predicted_classes = torch.argmax(logits, dim=1)\n",
        "        test_predictions = predicted_classes[test_indices]\n",
        "        final_accuracy = accuracy_score(data.y[test_indices].cpu().numpy(), test_predictions.cpu().numpy())\n",
        "\n",
        "    return final_accuracy, test_predictions\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtC0NBH7UhKO"
      },
      "outputs": [],
      "source": [
        "# Compute initial test predictions\n",
        "initial_preds, initial_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6)\n",
        "\n",
        "# Ensure `initial_preds` is a tensor and on the correct device\n",
        "initial_preds = initial_preds.clone().detach()  # Ensures a proper detached copy\n",
        "\n",
        "\n",
        "print(f\"ðŸ“Š Initial Classification Accuracy: {initial_accuracy:.4f}\")\n",
        "\n",
        "# Create the model\n",
        "model = HeterophilicNodeClassifier(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=len(set(data.y.tolist())),test_indices=test_indices, initial_preds=initial_preds\n",
        ").to(data.x.device)  # Ensure model is on the correct device\n",
        "\n",
        "# ðŸ”„ Train the model before inference\n",
        "final_accuracy_before_djgnn, test_predictions_before_djgnn = train_and_evaluate(\n",
        "    model, data, train_idx, test_idx, initial_preds, epochs=100, lr=0.01\n",
        ")\n",
        "\n",
        "print(len(test_predictions_before_djgnn),len(test_idx))\n",
        "\n",
        "# âœ… Model evaluation after training\n",
        "model.eval()\n",
        "#with torch.no_grad():\n",
        " #   logits = model(data.x, data.edge_index, train_idx, test_idx, initial_test_preds=initial_preds)\n",
        " #   predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "\n",
        "print(f\"ðŸŽ¯  Classification Accuracy after running kdd2023: {final_accuracy_before_djgnn:.4f}\")\n",
        "#print(test_predictions)\n",
        "#print(len(initial_preds))\n",
        "#print(len(test_predictions))\n",
        "\n",
        "#print(len(val_idx))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZSz76h8VGIZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class DJGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds, n_jumps=5, dropout=0.5):\n",
        "        super(DJGNN, self).__init__()\n",
        "        self.n_jumps = n_jumps\n",
        "        self.dropout = dropout\n",
        "        self.att = nn.Parameter(torch.ones(n_jumps + 1))  # Attention weights for jumps\n",
        "        self.sm = nn.Softmax(dim=0)\n",
        "\n",
        "        # Store initial predictions (converted to one-hot)\n",
        "        self.test_indices = test_indices\n",
        "        self.initial_preds = nn.Parameter(F.one_hot(initial_preds, num_classes).float(), requires_grad=False)\n",
        "\n",
        "        # GCN layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(n_jumps):\n",
        "            self.convs.append(GCNConv(in_dim, hidden_dim))\n",
        "\n",
        "        # Extra convolution layers\n",
        "        self.conv_extra = GCNConv(in_dim, hidden_dim)\n",
        "        self.bn_extra = nn.BatchNorm1d(hidden_dim)\n",
        "        self.conv_extra2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.bn_extra_2 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        # Final classifier\n",
        "        self.classify = nn.Linear(hidden_dim * (n_jumps + 1) + num_classes, num_classes)  # Extra input for initial preds\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "      mask_attentions = self.sm(self.att)\n",
        "\n",
        "      # Extra convolutions\n",
        "      extra_conv = self.conv_extra(x, edge_index).relu()\n",
        "      print(f\"extra_conv after conv_extra: {extra_conv.shape}\")\n",
        "      extra_conv = self.bn_extra(extra_conv)\n",
        "      print(f\"extra_conv after bn_extra: {extra_conv.shape}\")\n",
        "      extra_conv = F.dropout(extra_conv, p=self.dropout, training=self.training)\n",
        "      extra_conv = self.conv_extra2(extra_conv, edge_index).relu()\n",
        "      extra_conv = self.bn_extra_2(extra_conv)\n",
        "      extra_conv = extra_conv * mask_attentions[-1]\n",
        "      print(f\"extra_conv after conv_extra2 & mask: {extra_conv.shape}\")\n",
        "\n",
        "      # Jumping knowledge mechanism: collect outputs from each conv layer\n",
        "      z_s = []\n",
        "      for i, conv in enumerate(self.convs):\n",
        "          z = conv(x, edge_index).relu() * mask_attentions[i]\n",
        "          print(f\"z from conv {i}: {z.shape}\")\n",
        "          z_s.append(z)\n",
        "\n",
        "      # Concatenate all jump outputs with extra_conv\n",
        "      final_z = torch.cat(z_s + [extra_conv], dim=1)\n",
        "      print(f\"âœ… final_z shape BEFORE concatenation: {final_z.shape}\")  # Expect [num_nodes, feature_dim]\n",
        "\n",
        "      # Debug: Print test indices shape and the slice from final_z\n",
        "      print(f\"âœ… self.test_indices shape: {self.test_indices.shape}\")  # Expect [num_test_samples]\n",
        "      test_slice = final_z[self.test_indices]\n",
        "      print(f\"âœ… final_z[self.test_indices] shape: {test_slice.shape}\")  # Expect [num_test_samples, feature_dim]\n",
        "\n",
        "      # Ensure self.initial_preds is a LongTensor\n",
        "      num_classes = self.classify.out_features  # Get number of classes\n",
        "      initial_preds_long = self.initial_preds.long().squeeze()\n",
        "      print(f\"initial_preds_long shape after squeeze: {initial_preds_long.shape}\")\n",
        "\n",
        "      # Clamp indices to valid range\n",
        "      initial_preds_long = torch.clamp(initial_preds_long, min=0, max=num_classes - 1)\n",
        "\n",
        "      # Convert to one-hot encoding\n",
        "      one_hot_preds = F.one_hot(initial_preds_long, num_classes=num_classes).float()\n",
        "      print(f\"âœ… one_hot_preds shape immediately after one_hot: {one_hot_preds.shape}\")\n",
        "\n",
        "      # If one_hot_preds still has an extra dimension, print its dimensions explicitly\n",
        "      for idx, dim in enumerate(one_hot_preds.shape):\n",
        "          print(f\"one_hot_preds dim {idx}: {dim}\")\n",
        "\n",
        "      # Attempt to remove extra dimensions by squeezing only the dims of size 1\n",
        "      one_hot_preds = one_hot_preds.squeeze()\n",
        "      print(f\"âœ… one_hot_preds shape after squeeze(): {one_hot_preds.shape}\")\n",
        "\n",
        "      # Check dimensions explicitly\n",
        "      if one_hot_preds.ndim != 2:\n",
        "          print(f\"âŒ one_hot_preds still has {one_hot_preds.ndim} dimensions; expected 2 dimensions!\")\n",
        "\n",
        "      # Now, try concatenation and catch errors with more prints\n",
        "      try:\n",
        "          final_z[self.test_indices] = torch.cat((final_z[self.test_indices], one_hot_preds), dim=1)\n",
        "      except RuntimeError as e:\n",
        "          print(f\"âŒ ERROR: Shape mismatch at concatenation!\")\n",
        "          print(f\"ðŸ” final_z[self.test_indices] shape: {final_z[self.test_indices].shape}\")\n",
        "          print(f\"ðŸ” one_hot_preds shape: {one_hot_preds.shape}\")\n",
        "          raise e  # Re-raise after printing shapes\n",
        "\n",
        "      # Dropout and classification\n",
        "      final_z = F.dropout(final_z, p=self.dropout, training=self.training)\n",
        "      logits = self.classify(final_z).log_softmax(dim=-1)\n",
        "      return logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cldUM1jPk72E"
      },
      "outputs": [],
      "source": [
        "def train_djgnn(model, data, train_idx, test_idx, initial_preds_djgnn, epochs=100, lr=0.01):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(data.x, data.edge_index)\n",
        "        loss_supervised = criterion(logits[train_idx], data.y[train_idx])\n",
        "\n",
        "        # ðŸ”¥ NEW: Consistency Loss to prevent drastic changes\n",
        "        confidence_threshold = 0.85  # Change only high-confidence nodes\n",
        "        high_confidence_mask = logits[test_idx].softmax(dim=1).max(dim=1).values > confidence_threshold\n",
        "\n",
        "        # Apply consistency loss only to confident predictions\n",
        "        filtered_loss = F.cross_entropy(logits[test_idx][high_confidence_mask], initial_preds_djgnn[high_confidence_mask])\n",
        "        loss = loss_supervised + 0.1 * filtered_loss\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy on test set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_logits = model(data.x, data.edge_index)\n",
        "            test_preds = test_logits[test_idx].argmax(dim=1)\n",
        "            test_correct = (test_preds == data.y[test_idx]).sum().item()\n",
        "            test_acc = test_correct / len(test_idx)\n",
        "\n",
        "    #    print(f\"ðŸ§ Epoch {epoch+1:02d} | Loss: {loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "       # if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "       #     print(f\"ðŸ” Logits Before Argmax (First 5 Samples):\\n{test_logits[test_idx][:5]}\")\n",
        "\n",
        "    return test_preds, test_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p936LZ0GlGf3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Ensure `initial_preds_djgnn` is a tensor and detached\n",
        "initial_preds_djgnn = test_predictions_before_djgnn.clone().detach().long()  # Explicitly convert to LongTensor\n",
        "initial_preds = initial_preds.clone().detach().long()\n",
        "\n",
        "# Get the number of unique classes from `data.y`\n",
        "num_classes = data.y.max().item() + 1  # `max() + 1` ensures it captures all labels\n",
        "\n",
        "print(f\"ðŸ“Š Number of Test Samples: {len(initial_preds_djgnn)}\")\n",
        "print(f\"ðŸ”¢ Number of Unique Classes: {num_classes}\")\n",
        "\n",
        "# ðŸš€ Initialize DJ-GNN model with test indices & initial predictions\n",
        "djgnn_model = DJGNN(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=num_classes,  # Use the correct `num_classes`\n",
        "    test_indices=torch.tensor(test_idx, dtype=torch.long, device=data.x.device),  # Ensure `test_idx` is a tensor\n",
        "    initial_preds=initial_preds_djgnn,  # Pass initial predictions (already `LongTensor`)\n",
        "    n_jumps=5,  # Use 5 hops for diffusion\n",
        "    dropout=0.5\n",
        ").to(data.x.device)  # Ensure it's on the correct device\n",
        "\n",
        "# ðŸš€ Train DJ-GNN and get new predictions\n",
        "new_preds, final_accuracy_after_djgnn = train_djgnn(\n",
        "    djgnn_model, data, train_idx, test_idx, initial_preds_djgnn, epochs=500, lr=0.01\n",
        ")\n",
        "\n",
        "# ðŸŽ¯ Compare accuracies before & after DJ-GNN\n",
        "print(\"\\nðŸ”¥ Final Results:\")\n",
        "print(f\"ðŸŽ¯ Accuracy BEFORE DJ-GNN: {final_accuracy_before_djgnn:.4f}\")\n",
        "print(f\"ðŸš€ Accuracy AFTER DJ-GNN: {final_accuracy_after_djgnn:.4f}\")\n",
        "\n",
        "# ðŸ” Sample Predictions Before & After DJ-GNN (Print first 10 for debugging)\n",
        "print(\"\\nðŸ” Sample Predictions Before & After DJ-GNN:\")\n",
        "for i in range(min(10, len(test_idx))):  # Ensure we don't go out of bounds\n",
        "    print(f\"ðŸ§ Sample {i+1} | Before: {initial_preds_djgnn[i].item()} | After: {new_preds[i].item()}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}