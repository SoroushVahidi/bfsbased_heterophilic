{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CqGs0nK9M8Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caeeb386-d4b4-48ee-efb8-2e6fb97e400d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.11/dist-packages (12.0.1)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gurobipy\n",
        "!pip install torch_geometric\n",
        "!pip install sortedcontainers\n",
        "\n",
        "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "!pip install scikit-optimize\n",
        "\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import pairwise_distances as sklearn_pairwise_distances\n",
        "import networkx as nx\n",
        " # Use \"cosine\" for cosine similarity\n",
        "import heapq\n",
        "\n",
        "\n",
        "os.environ[\"GRB_LICENSE_FILE\"] = \"gurobi (3).lic\"\n",
        "os.environ[\"GRB_WLSACCESSID\"] = \"f218200d-1f8d-4342-83f5-b7b2d9263751\"  # Replace with your actual WLSACCESSID\n",
        "os.environ[\"GRB_WLSSECRET\"] = \"528d596b-babc-4a1e-bda2-693c44f4f006\"  # Replace with your actual WLSSECRET\n",
        "os.environ[\"GRB_LICENSEID\"] = \"840285\"  # Replace with your actual LICENSEID\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from torch_geometric.datasets import WebKB, WikipediaNetwork, Actor\n",
        "\n",
        "from torch_geometric.datasets import FacebookPagePage\n",
        "\n",
        "from torch_geometric.datasets import SNAPDataset\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import networkx as nx\n",
        "from torch_geometric.datasets import WebKB\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sortedcontainers import SortedSet  # Ordered set\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "from torch_geometric.datasets import WikipediaNetwork\n",
        "from torch_geometric.datasets import Actor\n",
        "\n",
        "# Load the Film dataset (also known as Actor dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BD28jxmhNmm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "#dataset = Actor(root='data/Film')\n",
        "data = dataset[0]\n",
        "data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "\n",
        "# ✅ Remove duplicate edges\n",
        "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "# ✅ Convert to NetworkX Graph to Find Components\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "components = list(nx.connected_components(G))\n",
        "num_components = len(components)\n",
        "\n",
        "print(f\"\\n✅ Loaded  dataset with {data.num_nodes} nodes, {data.edge_index.shape[1]} edges\")\n",
        "print(f\"   - Features: {data.x.shape[1]}\")\n",
        "print(f\"   - Number of Classes: {len(set(data.y.numpy()))}\")\n",
        "print(f\"   - Number of Components: {num_components}\")\n",
        "\n",
        "# ✅ Set Training Percentage\n",
        "train_percentage = 0.65\n",
        "\n",
        "# ✅ Select Training Nodes\n",
        "train_indices = []\n",
        "for component in components:\n",
        "    component = list(component)\n",
        "    t = max(1, int(train_percentage * len(component)))\n",
        "    sampled_nodes = np.random.choice(component, t, replace=False)\n",
        "    train_indices.extend(sampled_nodes)\n",
        "\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "# ✅ Initialize Prediction Labels\n",
        "y_pred = np.full(data.num_nodes, -1)\n",
        "for idx in train_indices:\n",
        "    y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "# ✅ Compute Label Distribution\n",
        "total_label_counts = Counter(data.y.numpy())\n",
        "num_labels = len(set(data.y.numpy()))\n",
        "alpha = 1  # Laplace smoothing\n",
        "\n",
        "dataset_label_distribution = {\n",
        "    lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "    for lbl in total_label_counts.keys()\n",
        "}\n",
        "\n",
        "train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "train_label_distribution = {\n",
        "    lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "    for lbl in dataset_label_distribution.keys()\n",
        "}\n",
        "\n",
        "# ✅ Precompute Neighbors for Each Node\n",
        "A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "A = A.numpy()\n",
        "neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "# ✅ Track Instances Assigned to Each Label\n",
        "class_instances = defaultdict(set)\n",
        "for idx in train_indices:\n",
        "    class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "# ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "ordered_set = SortedSet()\n",
        "train_labeled_nodes = set(train_indices)\n",
        "\n",
        "for node in range(data.num_nodes):\n",
        "    if y_pred[node] == -1:  # Only process unlabeled nodes\n",
        "        labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "        num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "        total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "        if total_neighbors > 0:\n",
        "            weighted_score = (num_labeled_by_propagation + 3 * num_labeled_by_train) / total_neighbors\n",
        "        else:\n",
        "            weighted_score = 0\n",
        "\n",
        "        ordered_set.add((-weighted_score, node))\n",
        "\n",
        "# ✅ Iteratively Label the Most Constrained Nodes\n",
        "while ordered_set:\n",
        "    _, node = ordered_set.pop(0)\n",
        "\n",
        "    if y_pred[node] != -1:\n",
        "        continue\n",
        "\n",
        "    # Get labeled neighbors\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    # 🚨 If this node has 0 labeled neighbors\n",
        "    if not neighbor_labels:\n",
        "        print(f\"\\n🚨 STRANGE: Node {node} was chosen, but it has 0 labeled neighbors!\")\n",
        "        break\n",
        "\n",
        "    # Compute Neighbor Label Distribution\n",
        "    neighbor_label_counts = Counter(neighbor_labels)\n",
        "    total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "    if total_labeled_neighbors > 0:\n",
        "        neighbor_label_distribution = {\n",
        "            lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "        }\n",
        "    else:\n",
        "        neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # ✅ Compute Feature Distance to Each Class\n",
        "    # feature_diffs = {}\n",
        "    # for lbl in dataset_label_distribution.keys():\n",
        "    #   if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "    #       instance_features = data.x[list(class_instances[lbl])]\n",
        "    #       node_feature = data.x[node].unsqueeze(0)\n",
        "\n",
        "    #       # Compute distances for each instance\n",
        "    #       distances = torch.norm(instance_features - node_feature, dim=1).tolist()\n",
        "\n",
        "    #       # Apply weight based on whether the instance is from training or predicted labels\n",
        "    #       weighted_distances = [\n",
        "    #           (3 * dist) if instance in train_indices else dist  # Give 3x weight if in training set\n",
        "    #           for instance, dist in zip(class_instances[lbl], distances)\n",
        "    #       ]\n",
        "\n",
        "    #       # Compute weighted average distance\n",
        "    #       avg_distance = sum(weighted_distances) / len(weighted_distances)\n",
        "    #       feature_diffs[lbl] = avg_distance\n",
        "    #   else:\n",
        "    #       feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    feature_diffs = {}\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "            instance_features = data.x[list(class_instances[lbl])]\n",
        "            node_feature = data.x[node].unsqueeze(0)\n",
        "           # print(len(instance_features),len(node_feature))\n",
        "            avg_distance = torch.mean(torch.norm(instance_features - node_feature, dim=1)).item()\n",
        "            feature_diffs[lbl] = avg_distance\n",
        "        else:\n",
        "            feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    # ✅ Select the Best Label Based on the Adjusted Score\n",
        "    best_label_candidates = []\n",
        "    max_value = float('-inf')\n",
        "    a1=0.5\n",
        "    a2=-6\n",
        "    a3=-2\n",
        "    a4=1\n",
        "    a5=3\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        score = (\n",
        "            a1*train_label_distribution.get(lbl, 0)\n",
        "            +a2* neighbor_label_distribution.get(lbl, 0)\n",
        "            +a3*feature_diffs[lbl]  # Penalize by average feature distance\n",
        "        )\n",
        "        print(lbl,score,)\n",
        "\n",
        "        if score - max_value > 0.01:\n",
        "            best_label_candidates = [lbl]\n",
        "            max_value = score\n",
        "        elif abs(score - max_value) <= 0.01:\n",
        "            best_label_candidates.append(lbl)\n",
        "\n",
        "\n",
        "    best_label = random.choice(best_label_candidates)\n",
        "    y_pred[node] = best_label\n",
        "    class_instances[best_label].add(node)  # Track newly labeled nodes\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    print(f\"\\n🔹 Labelling Node {node} \")\n",
        "    # ✅ Print Prediction Outcome\n",
        "    true_label = data.y[node].item()\n",
        "    correct = \"✅\" if best_label == true_label else \"❌\"\n",
        "    print(f\"   -> Predicted Label: {best_label} | True Label: {true_label} {correct}\")\n",
        "\n",
        "   # print(f\"   - Total Neighbors: {len(neighbors_dict[node])}\")\n",
        "   # print(f\"   - Labeled Neighbors: {len(neighbor_labels)}\")\n",
        "    for lbl, count in label_counts.items():\n",
        "        print(f\"   - Class {lbl}: {count} neighbors\")\n",
        "        # ✅ Update Labeled Neighbor Score for Unlabeled Neighbors\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                new_weighted_score = (a4*num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "# ✅ Evaluate Accuracy\n",
        "test_indices = [i for i in range(data.num_nodes) if i not in train_indices]\n",
        "y_true = data.y[test_indices]\n",
        "y_pred_test = y_pred[test_indices]\n",
        "\n",
        "valid_idx = [i for i in range(len(y_pred_test)) if y_pred_test[i] != -1]\n",
        "if valid_idx:\n",
        "    final_accuracy = accuracy_score(y_true[valid_idx], y_pred_test[valid_idx])\n",
        "    print(f\"\\n🎯 Label Propagation Accuracy: {final_accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"\\n❌ No valid predictions were made!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZChMrfbyNoOn",
        "outputId": "8009d1ed-d712-4699-928b-45799c832e8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_9.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Loaded  dataset with 183 nodes, 574 edges\n",
            "   - Features: 1703\n",
            "   - Number of Classes: 5\n",
            "   - Number of Components: 1\n",
            "3 -30.695926883356357\n",
            "0 -30.607773695534807\n",
            "2 -31.69418330308868\n",
            "4 -37.09909383262076\n",
            "1 0.0040650406504065045\n",
            "\n",
            "🔹 Labelling Node 1 \n",
            "   -> Predicted Label: 1 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.8846094395087\n",
            "0 -17.24294177109633\n",
            "2 -17.583314849109186\n",
            "4 -16.977374472269197\n",
            "1 -29.995934959349594\n",
            "\n",
            "🔹 Labelling Node 2 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -15.459719874994542\n",
            "0 -18.76177493149672\n",
            "2 -24.087614012927546\n",
            "4 -16.924876608499666\n",
            "1 -30.06252812951561\n",
            "\n",
            "🔹 Labelling Node 25 \n",
            "   -> Predicted Label: 3 | True Label: 1 ❌\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.007923343317294\n",
            "0 -21.059718046731096\n",
            "2 -20.86294551011993\n",
            "4 -22.874400534280916\n",
            "1 -31.044284339842758\n",
            "\n",
            "🔹 Labelling Node 36 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -31.542278506891513\n",
            "0 -25.701788816994767\n",
            "2 -27.11705012437774\n",
            "4 -26.5070261141149\n",
            "1 -30.850432868895492\n",
            "\n",
            "🔹 Labelling Node 40 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.748902537958408\n",
            "0 -16.475039396828752\n",
            "2 -17.472997618884577\n",
            "4 -16.497386374124666\n",
            "1 -29.5255808791494\n",
            "\n",
            "🔹 Labelling Node 51 \n",
            "   -> Predicted Label: 0 | True Label: 3 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -29.126711108820224\n",
            "0 -29.37581530625258\n",
            "2 -29.750373793811335\n",
            "4 -35.46321813071646\n",
            "1 -33.641141410765606\n",
            "\n",
            "🔹 Labelling Node 92 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.87529013408878\n",
            "0 -22.109543715066057\n",
            "2 -21.629775954455866\n",
            "4 -20.184302725443025\n",
            "1 -31.55540227502342\n",
            "\n",
            "🔹 Labelling Node 99 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.416653850214267\n",
            "0 -16.555216703957658\n",
            "2 -18.69730372545196\n",
            "4 -16.831178106912752\n",
            "1 -29.593232627806625\n",
            "\n",
            "🔹 Labelling Node 173 \n",
            "   -> Predicted Label: 0 | True Label: 2 ❌\n",
            "   - Class 3: 5 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.171119907037998\n",
            "0 -27.85556634820989\n",
            "2 -27.056451750964655\n",
            "4 -31.60856054884216\n",
            "1 -34.17194890588279\n",
            "\n",
            "🔹 Labelling Node 16 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 6 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.240263202326084\n",
            "0 -28.43438235337172\n",
            "2 -24.242534590930475\n",
            "4 -21.82672063315787\n",
            "1 -31.995934959349594\n",
            "\n",
            "🔹 Labelling Node 131 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 5 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.396948077814365\n",
            "0 -20.207220945901017\n",
            "2 -26.16643328782989\n",
            "4 -18.95121900046744\n",
            "1 -30.655354972777328\n",
            "\n",
            "🔹 Labelling Node 23 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 2: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.73909399761417\n",
            "0 -27.976738844460588\n",
            "2 -22.074449492663874\n",
            "4 -20.313832678445955\n",
            "1 -31.68189382165428\n",
            "\n",
            "🔹 Labelling Node 4 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.55922339214542\n",
            "0 -20.501904402321916\n",
            "2 -26.204379988879694\n",
            "4 -18.921756186136385\n",
            "1 -30.32743596642967\n",
            "\n",
            "🔹 Labelling Node 31 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.863453128473544\n",
            "0 -19.750100050515275\n",
            "2 -21.273054076404108\n",
            "4 -23.535785116800447\n",
            "1 -29.593232627806625\n",
            "\n",
            "🔹 Labelling Node 50 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.981225548720943\n",
            "0 -19.11853050604099\n",
            "2 -20.276664051583143\n",
            "4 -19.666289724954744\n",
            "1 -29.995934959349594\n",
            "\n",
            "🔹 Labelling Node 56 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 52 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 10 neighbors\n",
            "   - Class 4: 9 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.557808139459873\n",
            "0 -25.036198530739885\n",
            "2 -26.613830519885553\n",
            "4 -21.793580450662752\n",
            "1 -31.55540227502342\n",
            "\n",
            "🔹 Labelling Node 153 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.852991321222568\n",
            "0 -25.85899058396254\n",
            "2 -20.322139693469538\n",
            "4 -18.974721350320955\n",
            "1 -30.45902776330467\n",
            "\n",
            "🔹 Labelling Node 49 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -28.198284366266513\n",
            "0 -27.83410159165297\n",
            "2 -25.570945693225397\n",
            "4 -27.26342717612662\n",
            "1 -31.55540227502342\n",
            "\n",
            "🔹 Labelling Node 82 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.54185507549503\n",
            "0 -30.131628904885392\n",
            "2 -24.342107726306452\n",
            "4 -23.807748236307283\n",
            "1 -32.36876439660545\n",
            "\n",
            "🔹 Labelling Node 93 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -15.98808310283878\n",
            "0 -21.353691969460588\n",
            "2 -22.113582564563288\n",
            "4 -17.615300573953768\n",
            "1 -30.06252812951561\n",
            "\n",
            "🔹 Labelling Node 110 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -29.46210310711124\n",
            "0 -26.37678423935805\n",
            "2 -28.033412886828913\n",
            "4 -30.185454764017244\n",
            "1 -31.172849174437484\n",
            "\n",
            "🔹 Labelling Node 156 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.245290973322177\n",
            "0 -21.8535298448268\n",
            "2 -22.35580439683868\n",
            "4 -17.74261418784537\n",
            "1 -30.06252812951561\n",
            "\n",
            "🔹 Labelling Node 170 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.852771976129794\n",
            "0 -24.322970305031877\n",
            "2 -21.58485789415313\n",
            "4 -23.1507028719274\n",
            "1 -31.364709373412094\n",
            "\n",
            "🔹 Labelling Node 178 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.879459598200107\n",
            "0 -20.85075655991469\n",
            "2 -21.077075911731256\n",
            "4 -20.539880194315096\n",
            "1 -30.590051170287094\n",
            "\n",
            "🔹 Labelling Node 108 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 3: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -37.382808902399326\n",
            "0 -33.52960291916762\n",
            "2 -34.19154162523223\n",
            "4 -35.40913335288443\n",
            "1 -36.27264928430076\n",
            "\n",
            "🔹 Labelling Node 20 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.93437407268741\n",
            "0 -28.617102537697892\n",
            "2 -24.78908724901153\n",
            "4 -24.12000981772818\n",
            "1 -33.52204274743553\n",
            "\n",
            "🔹 Labelling Node 146 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 3: 3 neighbors\n",
            "   - Class 0: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.17051146282413\n",
            "0 -20.604899321145158\n",
            "2 -21.870218230456842\n",
            "4 -26.998313345560213\n",
            "1 -29.995934959349594\n",
            "\n",
            "🔹 Labelling Node 78 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 4: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.393923022882724\n",
            "0 -23.350447569436174\n",
            "2 -22.967218352527155\n",
            "4 -21.618871130594393\n",
            "1 -30.06252812951561\n",
            "\n",
            "🔹 Labelling Node 64 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.079990604059482\n",
            "0 -27.75504771286879\n",
            "2 -21.913194609851374\n",
            "4 -20.55691281760611\n",
            "1 -31.300887580809555\n",
            "\n",
            "🔹 Labelling Node 86 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.49633047832706\n",
            "0 -25.495121870583635\n",
            "2 -25.021444274158014\n",
            "4 -20.307084478983064\n",
            "1 -30.850432868895492\n",
            "\n",
            "🔹 Labelling Node 171 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.742120959894443\n",
            "0 -26.603474531716447\n",
            "2 -25.631872130603327\n",
            "4 -22.917876639017244\n",
            "1 -32.182889457640606\n",
            "\n",
            "🔹 Labelling Node 129 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -32.77043745769718\n",
            "0 -27.87437716538344\n",
            "2 -27.75247950670196\n",
            "4 -27.61007443869986\n",
            "1 -32.7373442611074\n",
            "\n",
            "🔹 Labelling Node 58 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 3: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.52723524822452\n",
            "0 -29.525137816018205\n",
            "2 -23.17256541368438\n",
            "4 -22.025840201028963\n",
            "1 -31.995934959349594\n",
            "\n",
            "🔹 Labelling Node 3 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.31475088848331\n",
            "0 -24.35757914597426\n",
            "2 -22.445239974231256\n",
            "4 -21.519397177347322\n",
            "1 -29.795264717040023\n",
            "\n",
            "🔹 Labelling Node 6 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -15.40962908519962\n",
            "0 -18.53228274399672\n",
            "2 -18.965103102893366\n",
            "4 -23.612199225076814\n",
            "1 -30.06252812951561\n",
            "\n",
            "🔹 Labelling Node 10 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.106319644586826\n",
            "0 -31.10624400193129\n",
            "2 -24.073860121936335\n",
            "4 -23.654645361551424\n",
            "1 -33.16218328088279\n",
            "\n",
            "🔹 Labelling Node 26 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.534466006891513\n",
            "0 -29.49891749436293\n",
            "2 -23.199773741931452\n",
            "4 -22.585139670023104\n",
            "1 -31.618710990843734\n",
            "\n",
            "🔹 Labelling Node 32 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.15860960735538\n",
            "0 -25.174214277810197\n",
            "2 -19.431228591174616\n",
            "4 -18.044917502054354\n",
            "1 -29.995934959349594\n",
            "\n",
            "🔹 Labelling Node 33 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.487518527643466\n",
            "0 -25.479395781106096\n",
            "2 -20.166702223987116\n",
            "4 -19.158469595560213\n",
            "1 -29.457774635252914\n",
            "\n",
            "🔹 Labelling Node 52 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.039764621393466\n",
            "0 -30.87095347458754\n",
            "2 -24.28256983873321\n",
            "4 -23.924374975809236\n",
            "1 -32.553575035033184\n",
            "\n",
            "🔹 Labelling Node 68 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.93796751751163\n",
            "0 -27.605574522561174\n",
            "2 -21.43425555345489\n",
            "4 -20.05352727378287\n",
            "1 -30.45902776330467\n",
            "\n",
            "🔹 Labelling Node 73 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.685312488214755\n",
            "0 -25.572148237771135\n",
            "2 -22.06431574937774\n",
            "4 -24.806310095438143\n",
            "1 -32.614949699339824\n",
            "\n",
            "🔹 Labelling Node 81 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -31.704817035333896\n",
            "0 -27.260802183693986\n",
            "2 -26.552314711780085\n",
            "4 -25.917336859354158\n",
            "1 -33.81900548547264\n",
            "\n",
            "🔹 Labelling Node 83 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.606624820368076\n",
            "0 -25.509480391091447\n",
            "2 -19.44098277208282\n",
            "4 -18.557565130838533\n",
            "1 -30.32743596642967\n",
            "\n",
            "🔹 Labelling Node 91 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.780174472467685\n",
            "0 -30.50480357224379\n",
            "2 -24.207536650867\n",
            "4 -23.12148801291861\n",
            "1 -31.044284339842758\n",
            "\n",
            "🔹 Labelling Node 98 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.98897192730167\n",
            "0 -22.962645445412736\n",
            "2 -19.907422972888483\n",
            "4 -21.829492010721346\n",
            "1 -29.5255808791494\n",
            "\n",
            "🔹 Labelling Node 102 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -30.865663745538974\n",
            "0 -28.120129499978166\n",
            "2 -29.005325270862116\n",
            "4 -31.784394659647127\n",
            "1 -33.28256749719139\n",
            "\n",
            "🔹 Labelling Node 88 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.740705707208896\n",
            "0 -21.842907820290666\n",
            "2 -22.05328745958282\n",
            "4 -27.558616079935213\n",
            "1 -31.044284339842758\n",
            "\n",
            "🔹 Labelling Node 107 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.76948187603214\n",
            "0 -26.320080671853166\n",
            "2 -19.822885466784967\n",
            "4 -19.876696982034822\n",
            "1 -30.915185447630844\n",
            "\n",
            "🔹 Labelling Node 115 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.20086691631534\n",
            "0 -26.662697706765275\n",
            "2 -22.838191939563288\n",
            "4 -25.167642035135408\n",
            "1 -31.744950767455062\n",
            "\n",
            "🔹 Labelling Node 117 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.58183310283878\n",
            "0 -27.694958601540666\n",
            "2 -24.422542525500788\n",
            "4 -27.12500707114615\n",
            "1 -32.05837392419334\n",
            "\n",
            "🔹 Labelling Node 119 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.14910719646671\n",
            "0 -26.862969313210588\n",
            "2 -20.693368865222467\n",
            "4 -19.96096364463248\n",
            "1 -31.108632560667953\n",
            "\n",
            "🔹 Labelling Node 128 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -15.164452769892003\n",
            "0 -23.9113911729518\n",
            "2 -17.750362349719538\n",
            "4 -17.278533377298494\n",
            "1 -29.728072639403305\n",
            "\n",
            "🔹 Labelling Node 136 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.93376372112491\n",
            "0 -27.109011564797502\n",
            "2 -25.975076628894342\n",
            "4 -29.042727865823885\n",
            "1 -32.920091148314434\n",
            "\n",
            "🔹 Labelling Node 140 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.16226408733585\n",
            "0 -22.254374418801408\n",
            "2 -22.165895415515436\n",
            "4 -20.971616186746736\n",
            "1 -30.655354972777328\n",
            "\n",
            "🔹 Labelling Node 39 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.73865340007999\n",
            "0 -28.74900523240004\n",
            "2 -22.652725173205866\n",
            "4 -21.842524923929354\n",
            "1 -32.3069243392324\n",
            "\n",
            "🔹 Labelling Node 142 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.2885401035712\n",
            "0 -26.54404917771254\n",
            "2 -19.972936583728327\n",
            "4 -19.584552206644197\n",
            "1 -31.172849174437484\n",
            "\n",
            "🔹 Labelling Node 143 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.588796832697177\n",
            "0 -28.541527662819963\n",
            "2 -22.574724150867\n",
            "4 -20.903222479471346\n",
            "1 -30.979802604613266\n",
            "\n",
            "🔹 Labelling Node 149 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.85038779033878\n",
            "0 -29.233940992898088\n",
            "2 -22.671327544421686\n",
            "4 -22.230790533670564\n",
            "1 -32.49208974450584\n",
            "\n",
            "🔹 Labelling Node 155 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -31.523033359186435\n",
            "0 -26.280522261208635\n",
            "2 -27.066245986194147\n",
            "4 -26.460797705301424\n",
            "1 -31.55540227502342\n",
            "\n",
            "🔹 Labelling Node 158 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.048450687067294\n",
            "0 -25.88246241623793\n",
            "2 -25.55149073717071\n",
            "4 -21.556876577982088\n",
            "1 -30.850432868895492\n",
            "\n",
            "🔹 Labelling Node 90 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.98268530620792\n",
            "0 -19.81892291123305\n",
            "2 -21.573100997180475\n",
            "4 -20.463618673929354\n",
            "1 -29.457774635252914\n",
            "\n",
            "🔹 Labelling Node 113 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.062603213922763\n",
            "0 -33.2122773271266\n",
            "2 -26.731136275500788\n",
            "4 -26.123828329691072\n",
            "1 -33.87808370202537\n",
            "\n",
            "🔹 Labelling Node 172 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.4795858646796\n",
            "0 -23.262429152077775\n",
            "2 -23.051183654040827\n",
            "4 -28.102181830057283\n",
            "1 -30.785542961058578\n",
            "\n",
            "🔹 Labelling Node 163 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "🎯 Label Propagation Accuracy: 0.6923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sortedcontainers import SortedSet\n",
        "from sklearn.metrics import accuracy_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "def predictclass(data, train_indices, test_indices, a1, a2, a3, a4, a5):\n",
        "    data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "    train_indices = list(train_indices)\n",
        "    test_indices = list(test_indices)\n",
        "\n",
        "    # ✅ Remove duplicate edges\n",
        "    data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "    # ✅ Initialize Prediction Labels\n",
        "    y_pred = np.full(data.num_nodes, -1, dtype=int)\n",
        "    for idx in train_indices:\n",
        "        y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "    # ✅ Compute Label Distribution\n",
        "    total_label_counts = Counter(data.y.numpy())\n",
        "    num_labels = len(set(data.y.numpy()))\n",
        "    alpha = 1  # Laplace smoothing\n",
        "\n",
        "    dataset_label_distribution = {\n",
        "        lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "        for lbl in total_label_counts.keys()\n",
        "    }\n",
        "\n",
        "    train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "    train_label_distribution = {\n",
        "        lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "        for lbl in dataset_label_distribution.keys()\n",
        "    }\n",
        "\n",
        "    # ✅ Precompute Neighbors for Each Node\n",
        "    A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "    A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "    neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "    # ✅ Track Instances Assigned to Each Label\n",
        "    class_instances = defaultdict(set)\n",
        "    for idx in train_indices:\n",
        "        class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "    # ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "    ordered_set = SortedSet()\n",
        "    train_labeled_nodes = set(train_indices)\n",
        "\n",
        "    for node in range(data.num_nodes):\n",
        "        if y_pred[node] == -1:\n",
        "            labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "            num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "            num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "            total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "            if total_neighbors > 0:\n",
        "                weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors\n",
        "            else:\n",
        "                weighted_score = 0\n",
        "\n",
        "            ordered_set.add((-weighted_score, node))\n",
        "\n",
        "    # ✅ Iteratively Label the Most Constrained Nodes\n",
        "    while ordered_set:\n",
        "        _, node = ordered_set.pop(0)\n",
        "\n",
        "        if y_pred[node] != -1:\n",
        "            continue  # Skip already labeled nodes\n",
        "\n",
        "        # Get labeled neighbors\n",
        "        neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        label_counts = Counter(neighbor_labels)\n",
        "\n",
        "        # 🚨 If this node has 0 labeled neighbors\n",
        "        if not neighbor_labels:\n",
        "            continue\n",
        "\n",
        "        # Compute Neighbor Label Distribution\n",
        "        neighbor_label_counts = Counter(neighbor_labels)\n",
        "        total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "        if total_labeled_neighbors > 0:\n",
        "            neighbor_label_distribution = {\n",
        "                lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "            }\n",
        "        else:\n",
        "            neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        feature_diffs = {}\n",
        "\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "                instance_features = data.x[list(class_instances[lbl])]\n",
        "                node_feature = data.x[node].unsqueeze(0)\n",
        "\n",
        "                if instance_features.numel() > 0:  # ✅ Ensure instance_features is not empty\n",
        "                    avg_distance = torch.mean(torch.norm(instance_features - node_feature, dim=1)).item()\n",
        "                else:\n",
        "                    avg_distance = 0  # ✅ Avoid empty slice issue\n",
        "                feature_diffs[lbl] = avg_distance\n",
        "            else:\n",
        "                feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "        # ✅ Select the Best Label Based on the Adjusted Score\n",
        "        best_label_candidates = []\n",
        "        max_value = float('-inf')\n",
        "\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            score = (\n",
        "                a1 * train_label_distribution.get(lbl, 0)\n",
        "                + a2 * neighbor_label_distribution.get(lbl, 0)\n",
        "                + a3 * feature_diffs[lbl]  # Penalize by average feature distance\n",
        "            )\n",
        "\n",
        "            if score - max_value > 0.01:\n",
        "                best_label_candidates = [lbl]\n",
        "                max_value = score\n",
        "            elif abs(score - max_value) <= 0.01:\n",
        "                best_label_candidates.append(lbl)\n",
        "\n",
        "        best_label = random.choice(best_label_candidates)\n",
        "        y_pred[node] = best_label\n",
        "        class_instances[best_label].add(node)  # Track newly labeled nodes\n",
        "\n",
        "        # ✅ Update Labeled Neighbor Score for Unlabeled Neighbors\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                new_weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "\n",
        "    # ✅ Convert to PyTorch Tensor for Neural Network\n",
        "    y_pred_test = torch.tensor(y_pred[test_indices], dtype=torch.float)\n",
        "\n",
        "    # ✅ Compute Initial Classification Accuracy\n",
        "    y_true = data.y[test_indices]\n",
        "    valid_idx = [i for i in range(len(y_pred_test)) if y_pred_test[i] != -1]\n",
        "    if valid_idx:\n",
        "        initial_accuracy = accuracy_score(y_true[valid_idx], y_pred_test[valid_idx])\n",
        "    else:\n",
        "        initial_accuracy = 0.0  # No valid predictions\n",
        "\n",
        "    return y_pred_test, initial_accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "Ru9be0GZSBHA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "\n",
        "# Count occurrences of each class label\n",
        "class_counts = torch.bincount(data.y)\n",
        "\n",
        "# Print the number of elements in each class\n",
        "for class_id, count in enumerate(class_counts):\n",
        "    print(f\"Class {class_id}: {count} elements\")\n",
        "a1=0.5\n",
        "a2=-6\n",
        "a3=-2\n",
        "a4=1\n",
        "a5=3\n",
        "\n",
        "indices = np.arange(data.num_nodes)  # NumPy array of indices [0, 1, 2, ..., num_nodes-1]\n",
        "np.random.shuffle(indices)\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.52)\n",
        "\n",
        "# Further split train_idx into train and validation sets (e.g., 20% of train goes to validation)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.38)\n",
        "print(predictclass(data,train_idx,valid_idx,a1,a2,a3,a4,a5))"
      ],
      "metadata": {
        "id": "qqUQNrZolOwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7c4ec3-34a3-430c-ae4e-c552d82e35f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 33 elements\n",
            "Class 1: 1 elements\n",
            "Class 2: 18 elements\n",
            "Class 3: 101 elements\n",
            "Class 4: 30 elements\n",
            "(tensor([3., 1., 3., 3., 4., 3., 3., 4., 4., 3., 3., 4., 3., 3., 3., 4., 3., 3.,\n",
            "        4., 3., 0., 3., 3., 3., 3., 1., 3., 3., 3., 2., 3., 3., 3., 3., 3., 3.,\n",
            "        3., 3., 3., 3., 4., 4., 4., 3., 3., 3., 3., 3., 0., 3., 4., 3., 3., 3.,\n",
            "        3., 3., 0., 2., 4., 4., 4., 3., 3., 3., 3.]), 0.6923076923076923)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u88m8qZfUdX-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsMOjg0RUedb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88eDCyKNUf57"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import minimize\n",
        "import warnings\n",
        "warnings.simplefilter(\"error\", RuntimeWarning)  # Convert warnings to errors\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "num_nodes = data.x.shape[0]\n",
        "indices = np.arange(num_nodes)\n",
        "\n",
        "# Split into training (70%) and testing (30%) randomly\n",
        "from sklearn.model_selection import train_test_split\n",
        "random_seed = 42\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.3, random_state=random_seed)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "\n",
        "# Function to optimize (negate accuracy since we minimize)\n",
        "# Function to optimize (maximize train accuracy by minimizing negative accuracy)\n",
        "\n",
        "def random_search(model,data, train_idx,val_idx, num_samples=70):\n",
        "    best_params = None\n",
        "    best_score = float('-inf')\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        a1 = random.uniform(0, 10)     # a1 must be positive\n",
        "        a2 = random.uniform(-10, -0.01)  # a2 must be negative\n",
        "        a3 = random.uniform(-10, -0.01)  # a3 must be negative\n",
        "        a5 = random.uniform(0, 10)     # a5 must be positive\n",
        "        a4 = random.uniform(0,a5 )    # a4 must be positive and a4 <= a5\n",
        "\n",
        "        params = [a1, a2, a3, a4, a5]\n",
        "\n",
        "\n",
        "        _,score = model(data,train_idx,val_idx,params[0],params[1],params[2],params[3],params[4])\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_score\n",
        "\n",
        "\n",
        "\n",
        "# Initial guesses for a1, a2, a3, a4, a5\n",
        "#initial_params = [0.5,-5,-2,1,3]\n",
        "\n",
        "# Bounds for parameters\n",
        " # Adjust bounds as needed\n",
        "\n",
        "# Optimize using scipy\n",
        "result,best_val = random_search(predictclass,data,train_idx,val_idx,num_samples=20)\n",
        "#print(result)\n",
        "# Get best parameters\n",
        "best_a1, best_a2, best_a3, best_a4, best_a5 = result[0],result[1],result[2],result[3],result[4]\n",
        "\n",
        "# Evaluate on test set\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(\"best validation by random search:\", best_val)\n"
      ],
      "metadata": {
        "id": "xWZxuxXlygBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ba7a44-344a-4bda-f5d9-6f772bf06dea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best validation by random search: 0.5897435897435898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def bayesian_optimization(model, data, train_idx, val_idx,  initial_params,num_calls=15):\n",
        "    \"\"\"\n",
        "    Bayesian Optimization to find best hyperparameters (a1, a2, a3, a4, a5)\n",
        "    that maximize the validation accuracy.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function that takes (data, train_idx, val_idx, a1, a2, a3, a4, a5) and returns (loss, accuracy)\n",
        "        data: Dataset object\n",
        "        train_idx: Training indices\n",
        "        val_idx: Validation indices\n",
        "        num_calls: Number of function evaluations (default: 50)\n",
        "        initial_params: Optional initial solution [a1, a2, a3, a4, a5] (default: None)\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best found values for [a1, a2, a3, a4, a5]\n",
        "        best_accuracy: The best validation accuracy found\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the search space for a1, a2, a3, a4, a5\n",
        "    search_space = [\n",
        "        Real(0, 10, name=\"a1\"),        # a1 must be positive\n",
        "        Real(-10, -0.01, name=\"a2\"),   # a2 must be negative\n",
        "        Real(-10, -0.01, name=\"a3\"),   # a3 must be negative\n",
        "        Real(0, 10, name=\"a5\"),        # a5 must be positive\n",
        "        Real(0, 10, name=\"a4\"),        # a4 must be positive and a4 ≤ a5\n",
        "    ]\n",
        "\n",
        "    # Define the objective function for minimization\n",
        "    def objective(params):\n",
        "        a1, a2, a3, a5, a4 = params  # Bayesian optimization orders variables alphabetically\n",
        "        a4 = min(a4, a5)  # Ensure a4 ≤ a5\n",
        "\n",
        "        _, score = model(data, train_idx, val_idx, a1, a2, a3, a4, a5)\n",
        "        return -score  # Since `gp_minimize` minimizes the function, we negate accuracy\n",
        "\n",
        "    # Run Bayesian Optimization with an initial solution if provided\n",
        "    if initial_params is not None:\n",
        "        initial_params[3] = max(initial_params[3], initial_params[4])  # Ensure a4 ≤ a5\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, x0=initial_params, random_state=None)\n",
        "    else:\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, random_state=None)\n",
        "\n",
        "    # Extract best parameters\n",
        "    best_a1, best_a2, best_a3, best_a5, best_a4 = result.x\n",
        "    best_a4 = min(best_a4, best_a5)  # Ensure a4 ≤ a5\n",
        "    best_accuracy = -result.fun\n",
        "\n",
        "    best_params = [best_a1, best_a2, best_a3, best_a4, best_a5]\n",
        "\n",
        "    return best_params, best_accuracy\n",
        "\n",
        "# Example Usage:\n",
        "best_params, best_validation_score = bayesian_optimization(predictclass, data, train_idx, val_idx,result)\n",
        "print(\"best_validation by Bayesian=\",best_validation_score)\n",
        "if best_validation_score<best_val:\n",
        "  print(\"Bayesian made the parameters worse\")\n",
        "else:\n",
        "  best_a1, best_a2, best_a3, best_a4, best_a5 = best_params\n",
        "\n",
        "# # # # Step 2: Test the Model Using the Best Parameters\n",
        "y_pred_test, final_test_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5)\n",
        "\n",
        "y_pred_val, final_val_accuracy = predictclass(data, train_idx, val_idx, best_a1, best_a2, best_a3, best_a4, best_a5)\n",
        "\n",
        "# # # Step 3: Print the Final Accuracy on the Test Set\n",
        "print(\"\\n🎯 Final Val Set Accuracy:\", final_val_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n🎯 Final Test Set Accuracy:\", final_test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqOUOkBf6ACE",
        "outputId": "449a7b17-a40b-40cc-f7b4-477b4e402a75"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_validation by Bayesian= 0.6153846153846154\n",
            "\n",
            "🎯 Final Val Set Accuracy: 0.6153846153846154\n",
            "\n",
            "🎯 Final Test Set Accuracy: 0.5818181818181818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.nn import Linear, ReLU, Dropout, Sequential\n",
        "from torch_geometric.nn.conv import APPNP\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.utils import add_remaining_self_loops\n",
        "from torch_geometric.typing import Adj, OptTensor\n",
        "from torch_geometric.nn.inits import zeros\n",
        "\n",
        "class HighPassConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, amp=0.5, **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(**kwargs)\n",
        "        self.amp = amp\n",
        "        self.lin = Linear(in_channels, out_channels)\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        zeros(self.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.lin(x)\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "        out = self.amp * x - out\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "class Augmenter(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, amp=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = HighPassConv(in_dim, hidden_dim, amp=amp)\n",
        "        self.conv2 = HighPassConv(hidden_dim, hidden_dim, amp=amp)\n",
        "        self.mlp_edge_model = Sequential(\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim, hidden_dim * 2),\n",
        "            ReLU(),\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        src, dst = edge_index[0], edge_index[1]\n",
        "        edge_emb = x[src] + x[dst]\n",
        "        return torch.sigmoid(self.mlp_edge_model(edge_emb))\n",
        "\n",
        "class HeterophilicNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.augmenter = Augmenter(in_dim, hidden_dim)\n",
        "        self.gnn_high = HighPassConv(in_dim, hidden_dim)\n",
        "        self.offset_mlp = Sequential(\n",
        "            Linear(in_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.final_mlp = Sequential(\n",
        "            Linear(hidden_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, train_indices, test_indices, initial_test_preds=None):\n",
        "      #  print(\"\\n🔄 Forward pass started\")\n",
        "        edge_weights = self.augmenter(x, edge_index)\n",
        "        h = self.gnn_high(x, edge_index, edge_weights)\n",
        "        offset = self.offset_mlp(x)\n",
        "        logits = self.final_mlp(h + offset)\n",
        "        expanded_preds = torch.zeros_like(logits)\n",
        "\n",
        "        if initial_test_preds is not None:\n",
        "            if initial_test_preds.shape[0] > len(test_indices):\n",
        "                initial_test_preds = initial_test_preds[:len(test_indices)]\n",
        "            one_hot_preds = F.one_hot(initial_test_preds.long(), num_classes=logits.shape[1]).float()\n",
        "            expanded_preds[test_indices] = one_hot_preds\n",
        "            logits = logits + 0.1 * (logits - expanded_preds)\n",
        "\n",
        "        return F.log_softmax(logits, dim=1)\n",
        "\n",
        "# Training and Evaluation Code\n",
        "def train_and_evaluate(model, data, train_indices, test_indices, initial_preds, epochs=2000, lr=0.01):\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, train_indices, test_indices, initial_preds)\n",
        "        loss = criterion(logits[train_indices], data.y[train_indices])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, train_indices, test_indices, initial_preds)\n",
        "        predicted_classes = torch.argmax(logits, dim=1)\n",
        "        test_predictions = predicted_classes[test_indices]\n",
        "        final_accuracy = accuracy_score(data.y[test_indices].cpu().numpy(), test_predictions.cpu().numpy())\n",
        "\n",
        "   # print(f\"\\n🎯 Final Test Accuracy: {final_accuracy:.4f}\")\n",
        "    return final_accuracy, test_predictions"
      ],
      "metadata": {
        "id": "c_sXm_FtUhXF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute initial test predictions\n",
        "initial_preds, initial_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5)\n",
        "\n",
        "# Ensure `initial_preds` is a tensor and on the correct device\n",
        "initial_preds = torch.tensor(initial_preds, dtype=torch.long, device=data.x.device)\n",
        "\n",
        "print(f\"📊 Initial Classification Accuracy: {initial_accuracy:.4f}\")\n",
        "\n",
        "# Create the model\n",
        "model = HeterophilicNodeClassifier(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=len(set(data.y.tolist()))\n",
        ").to(data.x.device)  # Ensure model is on the correct device\n",
        "\n",
        "# 🔄 Train the model before inference\n",
        "final_accuracy, test_predictions = train_and_evaluate(\n",
        "    model, data, train_idx, test_idx, initial_preds, epochs=100, lr=0.01\n",
        ")\n",
        "\n",
        "# ✅ Model evaluation after training\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(data.x, data.edge_index, train_idx, test_idx, initial_test_preds=initial_preds)\n",
        "    predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "print(f\"🎯 Final Classification Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtC0NBH7UhKO",
        "outputId": "fcf48a5b-5ed4-428a-9c74-575bc488aef5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-0b9ea04df471>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  initial_preds = torch.tensor(initial_preds, dtype=torch.long, device=data.x.device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Initial Classification Accuracy: 0.5818\n",
            "🎯 Final Classification Accuracy: 0.7818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class DiffusionPump(nn.Module):\n",
        "    \"\"\"Computes diffusion distances using learned eigenfunctions.\"\"\"\n",
        "    def __init__(self, num_nodes, num_features, num_eigenvectors=5):\n",
        "        super(DiffusionPump, self).__init__()\n",
        "        self.num_eigenvectors = num_eigenvectors\n",
        "        self.eigenvectors = nn.Linear(num_features, num_eigenvectors, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Computes diffusion distances as pairwise differences of learned eigenvectors.\"\"\"\n",
        "        U = self.eigenvectors(x)  # Approximate eigenvectors\n",
        "        diffusion_distances = torch.cdist(U, U, p=2)  # Pairwise Euclidean distances\n",
        "        return diffusion_distances\n",
        "\n",
        "class JumpFilter(nn.Module):\n",
        "    \"\"\"Creates jump-based structural filters for message passing.\"\"\"\n",
        "    def __init__(self, num_jumps=20):\n",
        "        super(JumpFilter, self).__init__()\n",
        "        self.num_jumps = num_jumps\n",
        "        self.thresholds = nn.Parameter(torch.linspace(0, 1, num_jumps))\n",
        "\n",
        "    def forward(self, diffusion_distances):\n",
        "        \"\"\"Creates jump-based adjacency matrices.\"\"\"\n",
        "        filters = []\n",
        "        for t in self.thresholds:\n",
        "            jump_adj = (diffusion_distances < t).float()\n",
        "            filters.append(jump_adj)\n",
        "        return filters\n",
        "\n",
        "class GNNLayer(nn.Module):\n",
        "    \"\"\"A simple GCN layer for processing each jump-based adjacency matrix.\"\"\"\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super(GNNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return F.log_softmax(self.conv(x, edge_index), dim=1)\n",
        "\n",
        "class DiffusionJumpGNN(nn.Module):\n",
        "    \"\"\"Full Diffusion-Jump GNN model with diffusion pump, jump filters, and parallel GNNs.\"\"\"\n",
        "    def __init__(self, num_nodes, in_dim, hidden_dim, out_dim, num_jumps=5, num_eigenvectors=5):\n",
        "        super(DiffusionJumpGNN, self).__init__()\n",
        "        self.diffusion_pump = DiffusionPump(num_nodes, in_dim, num_eigenvectors)\n",
        "        self.jump_filter = JumpFilter(num_jumps)\n",
        "        self.gnns = nn.ModuleList([GNNLayer(in_dim, hidden_dim) for _ in range(num_jumps)])\n",
        "        self.fc = nn.Linear(hidden_dim * num_jumps, out_dim)  # Concatenated features\n",
        "\n",
        "    def forward(self, x, edge_index, train_indices, test_indices, initial_preds):\n",
        "        diffusion_distances = self.diffusion_pump(x)\n",
        "        jump_adjs = self.jump_filter(diffusion_distances)\n",
        "\n",
        "        embeddings = []\n",
        "        for i, jump_adj in enumerate(jump_adjs):\n",
        "            edge_index_jump = jump_adj.nonzero(as_tuple=False).t().contiguous()\n",
        "            embeddings.append(self.gnns[i](x, edge_index_jump))\n",
        "\n",
        "        h = torch.cat(embeddings, dim=-1)\n",
        "        return self.fc(h)\n",
        "\n",
        "\n",
        "def train_and_evaluate_djgnn(model, data, train_indices, test_indices, initial_preds, epochs=2000, lr=0.01):\n",
        "    \"\"\"Train and evaluate the Diffusion-Jump GNN.\"\"\"\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, train_indices, test_indices, initial_preds)\n",
        "        loss = criterion(logits[train_indices], data.y[train_indices])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, train_indices, test_indices, initial_preds)\n",
        "        predicted_classes = torch.argmax(logits, dim=1)\n",
        "        test_predictions = predicted_classes[test_indices]\n",
        "        final_accuracy = accuracy_score(data.y[test_indices].cpu().numpy(), test_predictions.cpu().numpy())\n",
        "\n",
        "    return final_accuracy, test_predictions\n",
        "final_accuracy, test_predictions = train_and_evaluate_djgnn(\n",
        "    model, data, train_idx, test_idx, test_predictions, epochs=100, lr=0.01\n",
        ")\n",
        "print(f\"🎯 Final Classification Accuracy: {final_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "nZSz76h8VGIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7a5390-c376-4bfd-9ce6-b8aeb6935757"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Final Classification Accuracy: 0.8545\n"
          ]
        }
      ]
    }
  ]
}