{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqGs0nK9M8Kq",
        "outputId": "5aea0d7c-6401-4d9a-ac29-42138e6c7624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gurobipy\n",
            "  Downloading gurobipy-12.0.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (16 kB)\n",
            "Downloading gurobipy-12.0.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (14.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gurobipy\n",
            "Successfully installed gurobipy-12.0.1\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m800.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp (from torch_geometric)\n",
            "  Downloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch_geometric)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
            "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
            "  Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
            "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.3/231.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.1/344.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: propcache, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch_geometric\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.13 aiosignal-1.3.2 frozenlist-1.5.0 propcache-0.3.0 torch_geometric-2.6.1 yarl-1.18.3\n",
            "Collecting sortedcontainers\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers\n",
            "Successfully installed sortedcontainers-2.4.0\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gurobipy\n",
        "!pip install torch_geometric\n",
        "!pip install sortedcontainers\n",
        "\n",
        "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "!pip install scikit-optimize\n",
        "\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import pairwise_distances as sklearn_pairwise_distances\n",
        "import networkx as nx\n",
        " # Use \"cosine\" for cosine similarity\n",
        "import heapq\n",
        "\n",
        "\n",
        "os.environ[\"GRB_LICENSE_FILE\"] = \"gurobi (3).lic\"\n",
        "os.environ[\"GRB_WLSACCESSID\"] = \"f218200d-1f8d-4342-83f5-b7b2d9263751\"  # Replace with your actual WLSACCESSID\n",
        "os.environ[\"GRB_WLSSECRET\"] = \"528d596b-babc-4a1e-bda2-693c44f4f006\"  # Replace with your actual WLSSECRET\n",
        "os.environ[\"GRB_LICENSEID\"] = \"840285\"  # Replace with your actual LICENSEID\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from torch_geometric.datasets import WebKB, WikipediaNetwork, Actor\n",
        "\n",
        "from torch_geometric.datasets import FacebookPagePage\n",
        "\n",
        "from torch_geometric.datasets import SNAPDataset\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import networkx as nx\n",
        "from torch_geometric.datasets import WebKB\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sortedcontainers import SortedSet  # Ordered set\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "from torch_geometric.datasets import WikipediaNetwork\n",
        "from torch_geometric.datasets import Actor\n",
        "\n",
        "# Load the Film dataset (also known as Actor dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD28jxmhNmm5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZChMrfbyNoOn",
        "outputId": "e9547126-5f1b-4adf-8bd1-8c6d473e19cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_9.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Loaded  dataset with 183 nodes, 574 edges\n",
            "   - Features: 1703\n",
            "   - Number of Classes: 5\n",
            "   - Number of Components: 1\n",
            "3 -30.784514155814318\n",
            "0 -30.97820274228972\n",
            "2 -31.609341567124776\n",
            "4 -37.139855795759495\n",
            "1 -30.058463088865203\n",
            "\n",
            "🔹 Labelling Node 1 \n",
            "   -> Predicted Label: 1 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.98315116448131\n",
            "0 -33.821742933940115\n",
            "2 -26.960358565415792\n",
            "4 -26.007382803816135\n",
            "1 -28.519171707029265\n",
            "\n",
            "🔹 Labelling Node 14 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -37.997692790457876\n",
            "0 -34.10797302122039\n",
            "2 -34.11592573460525\n",
            "4 -34.83827345933371\n",
            "1 -34.65293788134567\n",
            "\n",
            "🔹 Labelling Node 20 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 3 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.028895106742052\n",
            "0 -32.522514265727224\n",
            "2 -25.15766996678298\n",
            "4 -24.445311957258518\n",
            "1 -27.63112734972946\n",
            "\n",
            "🔹 Labelling Node 27 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.732468333670763\n",
            "0 -24.594842833232104\n",
            "2 -25.05946440037673\n",
            "4 -19.37210600938254\n",
            "1 -22.36872386157028\n",
            "\n",
            "🔹 Labelling Node 31 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.226467814871935\n",
            "0 -27.009645384501635\n",
            "2 -19.80706495579665\n",
            "4 -17.86588614549094\n",
            "1 -21.236868850583953\n",
            "\n",
            "🔹 Labelling Node 33 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.056288447806505\n",
            "0 -29.39602081174773\n",
            "2 -22.13144583043044\n",
            "4 -20.97411482896262\n",
            "1 -24.60166644274704\n",
            "\n",
            "🔹 Labelling Node 43 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.606762614676622\n",
            "0 -27.245613020610033\n",
            "2 -20.49215025242751\n",
            "4 -19.090905600446995\n",
            "1 -22.002900115842742\n",
            "\n",
            "🔹 Labelling Node 52 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.726578441092638\n",
            "0 -25.128101271342455\n",
            "2 -20.756924574937276\n",
            "4 -19.351579123396213\n",
            "1 -22.574273101682586\n",
            "\n",
            "🔹 Labelling Node 53 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.118660655448107\n",
            "0 -26.107042235087572\n",
            "2 -24.24717420872634\n",
            "4 -20.962434225935276\n",
            "1 -24.17629908740036\n",
            "\n",
            "🔹 Labelling Node 59 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.618616786429552\n",
            "0 -26.276531141947924\n",
            "2 -24.663666670884542\n",
            "4 -20.218078070539768\n",
            "1 -23.833861343259734\n",
            "\n",
            "🔹 Labelling Node 63 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.454170909354357\n",
            "0 -24.924011152934252\n",
            "2 -23.40376371678298\n",
            "4 -21.760201865095432\n",
            "1 -22.771132461423797\n",
            "\n",
            "🔹 Labelling Node 64 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.538168635794786\n",
            "0 -27.45078269834441\n",
            "2 -19.810561125840596\n",
            "4 -18.44541495408469\n",
            "1 -22.266133300657195\n",
            "\n",
            "🔹 Labelling Node 69 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.395540919730333\n",
            "0 -21.408071440409838\n",
            "2 -25.802651351060327\n",
            "4 -18.855142050642307\n",
            "1 -22.029566757078094\n",
            "\n",
            "🔹 Labelling Node 72 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.879759517142443\n",
            "0 -24.42593566770476\n",
            "2 -18.993401473130636\n",
            "4 -17.323821478742893\n",
            "1 -20.60250186144821\n",
            "\n",
            "🔹 Labelling Node 74 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.83600303215709\n",
            "0 -22.124500197123705\n",
            "2 -22.132359450425557\n",
            "4 -26.77954238023215\n",
            "1 -23.35901927172653\n",
            "\n",
            "🔹 Labelling Node 111 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.99943992180553\n",
            "0 -23.91347114438933\n",
            "2 -23.400505965318136\n",
            "4 -22.6587538060134\n",
            "1 -24.924662582273406\n",
            "\n",
            "🔹 Labelling Node 114 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.154894557425646\n",
            "0 -23.802158278178393\n",
            "2 -23.679604476060323\n",
            "4 -22.44045775498801\n",
            "1 -24.94582461535446\n",
            "\n",
            "🔹 Labelling Node 121 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.393528666922716\n",
            "0 -29.165334624003588\n",
            "2 -21.65364927586501\n",
            "4 -20.181331091780002\n",
            "1 -23.165085784788054\n",
            "\n",
            "🔹 Labelling Node 124 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.223410335013536\n",
            "0 -26.808175963114916\n",
            "2 -21.582999175157003\n",
            "4 -20.44980376328879\n",
            "1 -23.8002958220195\n",
            "\n",
            "🔹 Labelling Node 125 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.093947139212755\n",
            "0 -28.32681457395476\n",
            "2 -21.095978682603292\n",
            "4 -19.19922583665305\n",
            "1 -23.031533233518523\n",
            "\n",
            "🔹 Labelling Node 128 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.20137282891002\n",
            "0 -28.08312789792937\n",
            "2 -20.07195562657302\n",
            "4 -19.149718695539768\n",
            "1 -22.86043643176071\n",
            "\n",
            "🔹 Labelling Node 143 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.558790889212755\n",
            "0 -29.86299507017058\n",
            "2 -22.653347914781026\n",
            "4 -20.325301581281956\n",
            "1 -24.086129180784148\n",
            "\n",
            "🔹 Labelling Node 149 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.67271873039928\n",
            "0 -27.766319197367846\n",
            "2 -24.492403929795675\n",
            "4 -21.065780096906956\n",
            "1 -24.431857101316375\n",
            "\n",
            "🔹 Labelling Node 150 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.645828929373888\n",
            "0 -26.920532149028002\n",
            "2 -27.359414046372823\n",
            "4 -21.953849249738987\n",
            "1 -24.991148940915984\n",
            "\n",
            "🔹 Labelling Node 153 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.567904200980333\n",
            "0 -27.190254133891283\n",
            "2 -26.936007445420675\n",
            "4 -32.04663985337668\n",
            "1 -27.56143092333786\n",
            "\n",
            "🔹 Labelling Node 158 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.128269877860216\n",
            "0 -25.54793731565398\n",
            "2 -23.742039626206807\n",
            "4 -18.60521834458762\n",
            "1 -22.474587432737273\n",
            "\n",
            "🔹 Labelling Node 162 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -15.23994990868297\n",
            "0 -25.50968162412566\n",
            "2 -18.366644805039815\n",
            "4 -16.766211920637424\n",
            "1 -20.233918182248992\n",
            "\n",
            "🔹 Labelling Node 169 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -29.59965392632213\n",
            "0 -30.632001799296557\n",
            "2 -30.42028326329177\n",
            "4 -35.61502402390891\n",
            "1 -31.051260940427703\n",
            "\n",
            "🔹 Labelling Node 174 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.29083701653209\n",
            "0 -28.606325072001635\n",
            "2 -21.0085420065779\n",
            "4 -19.536233359236057\n",
            "1 -23.13263987719528\n",
            "\n",
            "🔹 Labelling Node 181 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.7016970781776\n",
            "0 -26.951723021220385\n",
            "2 -24.26188368138259\n",
            "4 -20.38572829331809\n",
            "1 -24.021445266599578\n",
            "\n",
            "🔹 Labelling Node 171 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 3 neighbors\n",
            "   - Class 2: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.65766402764049\n",
            "0 -29.705045622538744\n",
            "2 -27.009819930161886\n",
            "4 -23.667384558576877\n",
            "1 -27.179402343625945\n",
            "\n",
            "🔹 Labelling Node 41 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.96509538488798\n",
            "0 -28.840422416536374\n",
            "2 -26.188197081651143\n",
            "4 -25.097505026716526\n",
            "1 -27.80073069750778\n",
            "\n",
            "🔹 Labelling Node 116 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 3: 5 neighbors\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.821030345389513\n",
            "0 -27.169280928324877\n",
            "2 -25.023140853013448\n",
            "4 -22.936473303694065\n",
            "1 -25.076876632566375\n",
            "\n",
            "🔹 Labelling Node 147 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.435867991873888\n",
            "0 -30.054415434550464\n",
            "2 -24.94125952061599\n",
            "4 -22.295148306745823\n",
            "1 -25.372702590818328\n",
            "\n",
            "🔹 Labelling Node 131 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 4 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.92745276970592\n",
            "0 -19.15714446897429\n",
            "2 -19.082768385972432\n",
            "4 -17.635760718244846\n",
            "1 -20.70659922778122\n",
            "\n",
            "🔹 Labelling Node 173 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 3: 5 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.70188018364635\n",
            "0 -31.529853743266283\n",
            "2 -24.19231886204665\n",
            "4 -22.97618239488059\n",
            "1 -26.22056483447067\n",
            "\n",
            "🔹 Labelling Node 24 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.689448085257677\n",
            "0 -25.042318266581713\n",
            "2 -23.25075620945876\n",
            "4 -18.91672080125266\n",
            "1 -22.702630035276336\n",
            "\n",
            "🔹 Labelling Node 30 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.079121318289904\n",
            "0 -27.165056151103197\n",
            "2 -22.70950979527419\n",
            "4 -24.813075476545627\n",
            "1 -24.635018340940398\n",
            "\n",
            "🔹 Labelling Node 75 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.637812343070177\n",
            "0 -26.88282577390593\n",
            "2 -22.588997786607198\n",
            "4 -21.60214751328879\n",
            "1 -24.79527186572067\n",
            "\n",
            "🔹 Labelling Node 94 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.188196864554552\n",
            "0 -25.765146177958666\n",
            "2 -21.083664839829854\n",
            "4 -22.70557349290305\n",
            "1 -23.228169433469695\n",
            "\n",
            "🔹 Labelling Node 104 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.12017509026256\n",
            "0 -21.144403380107104\n",
            "2 -21.36930746373122\n",
            "4 -23.145574026960666\n",
            "1 -23.02941416918747\n",
            "\n",
            "🔹 Labelling Node 113 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.02861472649303\n",
            "0 -25.30500594968718\n",
            "2 -21.00355619725173\n",
            "4 -22.179564886946018\n",
            "1 -22.373635284299773\n",
            "\n",
            "🔹 Labelling Node 145 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.723503795096544\n",
            "0 -26.49416534299773\n",
            "2 -22.455113356675557\n",
            "4 -21.747062140363987\n",
            "1 -24.626479141111297\n",
            "\n",
            "🔹 Labelling Node 151 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.58121558708873\n",
            "0 -25.82625953550261\n",
            "2 -21.428420012559346\n",
            "4 -22.70047324265891\n",
            "1 -23.13263987719528\n",
            "\n",
            "🔹 Labelling Node 89 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.307686534354357\n",
            "0 -26.116701048564135\n",
            "2 -22.913811629380636\n",
            "4 -19.26091139878684\n",
            "1 -22.70731257616989\n",
            "\n",
            "🔹 Labelling Node 95 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.028650966117052\n",
            "0 -23.950998228739916\n",
            "2 -19.081910079087667\n",
            "4 -18.22241347398215\n",
            "1 -21.547972671384734\n",
            "\n",
            "🔹 Labelling Node 46 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.950438228079943\n",
            "0 -26.062543791484057\n",
            "2 -19.8704862051863\n",
            "4 -18.28879302110129\n",
            "1 -21.713593475217742\n",
            "\n",
            "🔹 Labelling Node 9 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -15.693936076590685\n",
            "0 -18.471031111430346\n",
            "2 -18.160008376206807\n",
            "4 -22.88724272813254\n",
            "1 -20.688807479734344\n",
            "\n",
            "🔹 Labelling Node 28 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.264918055960802\n",
            "0 -21.875564497660815\n",
            "2 -21.90541929539626\n",
            "4 -27.034875327009495\n",
            "1 -23.652125350828094\n",
            "\n",
            "🔹 Labelling Node 78 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.339157786795763\n",
            "0 -27.471727293681322\n",
            "2 -20.336358016099386\n",
            "4 -18.83431189622336\n",
            "1 -22.058388702268523\n",
            "\n",
            "🔹 Labelling Node 120 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.439404216239122\n",
            "0 -28.472185057353197\n",
            "2 -21.447531645860128\n",
            "4 -19.681971960920627\n",
            "1 -23.513752929563445\n",
            "\n",
            "🔹 Labelling Node 132 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.109272685477404\n",
            "0 -23.695566099833666\n",
            "2 -22.177008574571065\n",
            "4 -22.602605276960666\n",
            "1 -24.431857101316375\n",
            "\n",
            "🔹 Labelling Node 99 \n",
            "   -> Predicted Label: 2 | True Label: 4 ❌\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -26.58642608208385\n",
            "0 -27.94043075437468\n",
            "2 -25.02855963047927\n",
            "4 -25.43057501878196\n",
            "1 -27.29057788073532\n",
            "\n",
            "🔹 Labelling Node 146 \n",
            "   -> Predicted Label: 2 | True Label: 3 ❌\n",
            "   - Class 3: 3 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.83036681694713\n",
            "0 -26.69443694944304\n",
            "2 -25.413859313096456\n",
            "4 -20.69754546250754\n",
            "1 -24.495104781980437\n",
            "\n",
            "🔹 Labelling Node 4 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.768011775443224\n",
            "0 -22.057443541239916\n",
            "2 -26.458060210313256\n",
            "4 -18.911536627668674\n",
            "1 -22.30950640856735\n",
            "\n",
            "🔹 Labelling Node 148 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 2: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.23816176933971\n",
            "0 -27.58073417539519\n",
            "2 -20.172059004868917\n",
            "4 -18.579900198835666\n",
            "1 -22.177233688230437\n",
            "\n",
            "🔹 Labelling Node 39 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -31.730005946585802\n",
            "0 -28.23028365964812\n",
            "2 -26.67282766636794\n",
            "4 -25.897307806867893\n",
            "1 -28.90340518176071\n",
            "\n",
            "🔹 Labelling Node 83 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -29.450587001273302\n",
            "0 -27.960246962260424\n",
            "2 -26.33197302159255\n",
            "4 -27.36461012925559\n",
            "1 -27.89947032153122\n",
            "\n",
            "🔹 Labelling Node 140 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 3: 3 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.27095290703502\n",
            "0 -23.182865065287768\n",
            "2 -22.475090926255636\n",
            "4 -26.90408843125754\n",
            "1 -24.635018340940398\n",
            "\n",
            "🔹 Labelling Node 70 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.768183436820177\n",
            "0 -21.517154616069018\n",
            "2 -22.10679334935134\n",
            "4 -20.925837927717502\n",
            "1 -23.718642227048797\n",
            "\n",
            "🔹 Labelling Node 100 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -26.679362025687364\n",
            "0 -24.761444014262377\n",
            "2 -23.64711851414626\n",
            "4 -21.777429037946995\n",
            "1 -24.949875823850554\n",
            "\n",
            "🔹 Labelling Node 106 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.031189647147325\n",
            "0 -22.991462629985033\n",
            "2 -23.44227690037673\n",
            "4 -22.082950049299534\n",
            "1 -24.385767928953094\n",
            "\n",
            "🔹 Labelling Node 130 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -15.381224360892443\n",
            "0 -18.462451857279955\n",
            "2 -18.49081320103591\n",
            "4 -23.02269118394309\n",
            "1 -20.587645522947234\n",
            "\n",
            "🔹 Labelling Node 160 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.442566600272325\n",
            "0 -21.67952339048308\n",
            "2 -24.987749999131612\n",
            "4 -20.61316626634055\n",
            "1 -23.29113291918747\n",
            "\n",
            "🔹 Labelling Node 164 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "🎯 Label Propagation Accuracy: 0.5846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "#dataset = Actor(root='data/Film')\n",
        "data = dataset[0]\n",
        "data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "\n",
        "# ✅ Remove duplicate edges\n",
        "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "# ✅ Convert to NetworkX Graph to Find Components\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "components = list(nx.connected_components(G))\n",
        "num_components = len(components)\n",
        "\n",
        "print(f\"\\n✅ Loaded  dataset with {data.num_nodes} nodes, {data.edge_index.shape[1]} edges\")\n",
        "print(f\"   - Features: {data.x.shape[1]}\")\n",
        "print(f\"   - Number of Classes: {len(set(data.y.numpy()))}\")\n",
        "print(f\"   - Number of Components: {num_components}\")\n",
        "\n",
        "# ✅ Set Training Percentage\n",
        "train_percentage = 0.65\n",
        "\n",
        "# ✅ Select Training Nodes\n",
        "train_indices = []\n",
        "for component in components:\n",
        "    component = list(component)\n",
        "    t = max(1, int(train_percentage * len(component)))\n",
        "    sampled_nodes = np.random.choice(component, t, replace=False)\n",
        "    train_indices.extend(sampled_nodes)\n",
        "\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "# ✅ Initialize Prediction Labels\n",
        "y_pred = np.full(data.num_nodes, -1)\n",
        "for idx in train_indices:\n",
        "    y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "# ✅ Compute Label Distribution\n",
        "total_label_counts = Counter(data.y.numpy())\n",
        "num_labels = len(set(data.y.numpy()))\n",
        "alpha = 1  # Laplace smoothing\n",
        "\n",
        "dataset_label_distribution = {\n",
        "    lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "    for lbl in total_label_counts.keys()\n",
        "}\n",
        "\n",
        "train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "train_label_distribution = {\n",
        "    lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "    for lbl in dataset_label_distribution.keys()\n",
        "}\n",
        "\n",
        "# ✅ Precompute Neighbors for Each Node\n",
        "A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "A = A.numpy()\n",
        "neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "# ✅ Track Instances Assigned to Each Label\n",
        "class_instances = defaultdict(set)\n",
        "for idx in train_indices:\n",
        "    class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "# ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "ordered_set = SortedSet()\n",
        "train_labeled_nodes = set(train_indices)\n",
        "\n",
        "for node in range(data.num_nodes):\n",
        "    if y_pred[node] == -1:  # Only process unlabeled nodes\n",
        "        labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "        num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "        total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "        if total_neighbors > 0:\n",
        "            weighted_score = (num_labeled_by_propagation + 3 * num_labeled_by_train) / total_neighbors\n",
        "        else:\n",
        "            weighted_score = 0\n",
        "\n",
        "        ordered_set.add((-weighted_score, node))\n",
        "\n",
        "# ✅ Iteratively Label the Most Constrained Nodes\n",
        "while ordered_set:\n",
        "    _, node = ordered_set.pop(0)\n",
        "\n",
        "    if y_pred[node] != -1:\n",
        "        continue\n",
        "\n",
        "    # Get labeled neighbors\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    # 🚨 If this node has 0 labeled neighbors\n",
        "    if not neighbor_labels:\n",
        "        print(f\"\\n🚨 STRANGE: Node {node} was chosen, but it has 0 labeled neighbors!\")\n",
        "        break\n",
        "\n",
        "    # Compute Neighbor Label Distribution\n",
        "    neighbor_label_counts = Counter(neighbor_labels)\n",
        "    total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "    if total_labeled_neighbors > 0:\n",
        "        neighbor_label_distribution = {\n",
        "            lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "        }\n",
        "    else:\n",
        "        neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # ✅ Compute Feature Distance to Each Class\n",
        "    # feature_diffs = {}\n",
        "    # for lbl in dataset_label_distribution.keys():\n",
        "    #   if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "    #       instance_features = data.x[list(class_instances[lbl])]\n",
        "    #       node_feature = data.x[node].unsqueeze(0)\n",
        "\n",
        "    #       # Compute distances for each instance\n",
        "    #       distances = torch.norm(instance_features - node_feature, dim=1).tolist()\n",
        "\n",
        "    #       # Apply weight based on whether the instance is from training or predicted labels\n",
        "    #       weighted_distances = [\n",
        "    #           (3 * dist) if instance in train_indices else dist  # Give 3x weight if in training set\n",
        "    #           for instance, dist in zip(class_instances[lbl], distances)\n",
        "    #       ]\n",
        "\n",
        "    #       # Compute weighted average distance\n",
        "    #       avg_distance = sum(weighted_distances) / len(weighted_distances)\n",
        "    #       feature_diffs[lbl] = avg_distance\n",
        "    #   else:\n",
        "    #       feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    feature_diffs = {}\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "            instance_features = data.x[list(class_instances[lbl])]\n",
        "            node_feature = data.x[node].unsqueeze(0)\n",
        "           # print(len(instance_features),len(node_feature))\n",
        "            avg_distance = torch.mean(torch.norm(instance_features - node_feature, dim=1)).item()\n",
        "            feature_diffs[lbl] = avg_distance\n",
        "        else:\n",
        "            feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    # ✅ Select the Best Label Based on the Adjusted Score\n",
        "    best_label_candidates = []\n",
        "    max_value = float('-inf')\n",
        "    a1=0.5\n",
        "    a2=-6\n",
        "    a3=-2\n",
        "    a4=1\n",
        "    a5=3\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        score = (\n",
        "            a1*train_label_distribution.get(lbl, 0)\n",
        "            +a2* neighbor_label_distribution.get(lbl, 0)\n",
        "            +a3*feature_diffs[lbl]  # Penalize by average feature distance\n",
        "        )\n",
        "        print(lbl,score,)\n",
        "\n",
        "        if score - max_value > 0.01:\n",
        "            best_label_candidates = [lbl]\n",
        "            max_value = score\n",
        "        elif abs(score - max_value) <= 0.01:\n",
        "            best_label_candidates.append(lbl)\n",
        "\n",
        "\n",
        "    best_label = random.choice(best_label_candidates)\n",
        "    y_pred[node] = best_label\n",
        "    class_instances[best_label].add(node)  # Track newly labeled nodes\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    print(f\"\\n🔹 Labelling Node {node} \")\n",
        "    # ✅ Print Prediction Outcome\n",
        "    true_label = data.y[node].item()\n",
        "    correct = \"✅\" if best_label == true_label else \"❌\"\n",
        "    print(f\"   -> Predicted Label: {best_label} | True Label: {true_label} {correct}\")\n",
        "\n",
        "   # print(f\"   - Total Neighbors: {len(neighbors_dict[node])}\")\n",
        "   # print(f\"   - Labeled Neighbors: {len(neighbor_labels)}\")\n",
        "    for lbl, count in label_counts.items():\n",
        "        print(f\"   - Class {lbl}: {count} neighbors\")\n",
        "        # ✅ Update Labeled Neighbor Score for Unlabeled Neighbors\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                new_weighted_score = (a4*num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "# ✅ Evaluate Accuracy\n",
        "test_indices = [i for i in range(data.num_nodes) if i not in train_indices]\n",
        "y_true = data.y[test_indices]\n",
        "y_pred_test = y_pred[test_indices]\n",
        "\n",
        "valid_idx = [i for i in range(len(y_pred_test)) if y_pred_test[i] != -1]\n",
        "if valid_idx:\n",
        "    final_accuracy = accuracy_score(y_true[valid_idx], y_pred_test[valid_idx])\n",
        "    print(f\"\\n🎯 Label Propagation Accuracy: {final_accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"\\n❌ No valid predictions were made!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Ru9be0GZSBHA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sortedcontainers import SortedSet\n",
        "from sklearn.metrics import accuracy_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "def predictclass(data, train_indices, test_indices, a1, a2, a3, a4, a5, a6, a7, a8):\n",
        "    data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "    train_indices = list(train_indices)\n",
        "    test_indices = list(test_indices)\n",
        "\n",
        "    # ✅ Remove duplicate edges\n",
        "    data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "    # ✅ Initialize Prediction Labels\n",
        "    y_pred = np.full(data.num_nodes, -1, dtype=int)\n",
        "    for idx in train_indices:\n",
        "        y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "    # ✅ Compute Label Distribution\n",
        "    total_label_counts = Counter(data.y.numpy())\n",
        "    num_labels = len(set(data.y.numpy()))\n",
        "    alpha = 1  # Laplace smoothing\n",
        "\n",
        "    dataset_label_distribution = {\n",
        "        lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "        for lbl in total_label_counts.keys()\n",
        "    }\n",
        "\n",
        "    train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "    train_label_distribution = {\n",
        "        lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "        for lbl in dataset_label_distribution.keys()\n",
        "    }\n",
        "\n",
        "    # ✅ Precompute Neighbors for Each Node\n",
        "    A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "    A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "    neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "    # ✅ Track Instances Assigned to Each Label\n",
        "    class_instances = defaultdict(set)\n",
        "    for idx in train_indices:\n",
        "        class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "    # ✅ Initialize D Table (Similarity Table)\n",
        "    D = {i: {lbl: 0.0 for lbl in dataset_label_distribution.keys()} for i in range(data.num_nodes)}\n",
        "    class_counts = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # ✅ Explicitly Initialize D Using Training Set\n",
        "    for i in range(data.num_nodes):\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            if class_instances[lbl]:  # Compute similarity only if class has instances\n",
        "                sims = [feature_similarity(i, {lbl: {node}}, data, train_indices, test_indices, a7, a8)\n",
        "                        for node in class_instances[lbl]]\n",
        "                D[i][lbl] = sum(sims) / len(sims) if sims else 0.0\n",
        "                class_counts[lbl] = len(class_instances[lbl])  # Track number of nodes in class\n",
        "\n",
        "    # ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "    ordered_set = SortedSet()\n",
        "    train_labeled_nodes = set(train_indices)\n",
        "    labeled_nodes_count = 0  # Counter for recomputing D\n",
        "\n",
        "    for node in range(data.num_nodes):\n",
        "        if y_pred[node] == -1:\n",
        "            labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "            num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "            num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "            total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "            if total_neighbors > 0:\n",
        "                weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors\n",
        "            else:\n",
        "                weighted_score = 0\n",
        "\n",
        "            similarity_score = max(D[node].values()) if D[node] else 0\n",
        "            ordered_set.add((-weighted_score - a6 * similarity_score, node))\n",
        "\n",
        "    # ✅ Iteratively Label the Most Constrained Nodes\n",
        "    while ordered_set:\n",
        "       # print(len(ordered_set))\n",
        "        _, node = ordered_set.pop(0)\n",
        "\n",
        "        if y_pred[node] != -1:\n",
        "            continue  # Skip already labeled nodes\n",
        "\n",
        "        # Get labeled neighbors\n",
        "        neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        label_counts = Counter(neighbor_labels)\n",
        "\n",
        "        # 🚨 If this node has 0 labeled neighbors\n",
        "        if not neighbor_labels:\n",
        "            continue\n",
        "\n",
        "        # Compute Neighbor Label Distribution\n",
        "        neighbor_label_counts = Counter(neighbor_labels)\n",
        "        total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "        if total_labeled_neighbors > 0:\n",
        "            neighbor_label_distribution = {\n",
        "                lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "            }\n",
        "        else:\n",
        "            neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        feature_diffs = {lbl: D[node][lbl] for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        # ✅ Select the Best Label Based on the Adjusted Score\n",
        "        best_label_candidates = []\n",
        "        max_value = float('-inf')\n",
        "\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            score = (\n",
        "                a1 * train_label_distribution.get(lbl, 0)\n",
        "                + a2 * neighbor_label_distribution.get(lbl, 0)\n",
        "                + a3 * feature_diffs[lbl]\n",
        "            )\n",
        "\n",
        "            if score - max_value > 0.01:\n",
        "                best_label_candidates = [lbl]\n",
        "                max_value = score\n",
        "            elif abs(score - max_value) <= 0.01:\n",
        "                best_label_candidates.append(lbl)\n",
        "\n",
        "        best_label = random.choice(best_label_candidates)\n",
        "        y_pred[node] = best_label\n",
        "        class_instances[best_label].add(node)\n",
        "        class_counts[best_label] += 1\n",
        "        labeled_nodes_count += 1  # Increment labeled count\n",
        "\n",
        "        # ✅ Update D Table for Neighbors Only\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            for lbl in dataset_label_distribution.keys():\n",
        "                if class_instances[lbl]:\n",
        "                    sims = [feature_similarity(neighbor, {lbl: {n}}, data, train_indices, test_indices, a7, a8)\n",
        "                            for n in class_instances[lbl]]\n",
        "                    D[neighbor][lbl] = sum(sims) / len(sims) if sims else 0.0\n",
        "\n",
        "        # ✅ Recompute Entire D Table Every 5 Nodes\n",
        "        if labeled_nodes_count % 10 == 0:\n",
        "          for i in range(data.num_nodes):\n",
        "              if y_pred[i] == -1:  # ✅ Only update unlabeled nodes\n",
        "                  for lbl in dataset_label_distribution.keys():\n",
        "                      if class_instances[lbl]:  # ✅ Ensure class has labeled instances\n",
        "                          instance_list = list(class_instances[lbl])\n",
        "                          instance_features = data.x[instance_list]\n",
        "\n",
        "                          # ✅ Assign weights: (1 - a7) for training instances, a7 for others\n",
        "                          instance_weights = torch.tensor(\n",
        "                              [(1 - a7) if inst in train_indices else a7 for inst in instance_list],\n",
        "                              dtype=torch.float,\n",
        "                              device=data.x.device\n",
        "                          )\n",
        "\n",
        "                          # ✅ Normalize weights to ensure they sum to 1\n",
        "                          instance_weights /= instance_weights.sum()\n",
        "\n",
        "                          # ✅ Compute weighted average feature vector\n",
        "                          avg_feature = torch.sum(instance_features * instance_weights.view(-1, 1), dim=0, keepdim=True)\n",
        "\n",
        "                          # ✅ Compute cosine similarity between node i and avg_feature\n",
        "                          similarity = F.cosine_similarity(data.x[i].unsqueeze(0), avg_feature).item()\n",
        "\n",
        "                          D[i][lbl] = similarity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # ✅ Update Adjacent Nodes in Ordered Set\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for x in neighbors_dict[neighbor] if y_pred[x] != -1 and x in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for x in neighbors_dict[neighbor] if y_pred[x] != -1 and x not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                similarity_score = max(D[neighbor].values()) if D[neighbor] else 0\n",
        "                new_weighted_score = ((a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0) + a6 * similarity_score\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "\n",
        "    return torch.tensor(y_pred[test_indices], dtype=torch.float), accuracy_score(data.y[test_indices], y_pred[test_indices])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqUQNrZolOwy",
        "outputId": "9903f6c9-d4c9-4781-f4d7-0f7937b8bfee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 33 elements\n",
            "Class 1: 1 elements\n",
            "Class 2: 18 elements\n",
            "Class 3: 101 elements\n",
            "Class 4: 30 elements\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "\n",
        "# Count occurrences of each class label\n",
        "class_counts = torch.bincount(data.y)\n",
        "\n",
        "# Print the number of elements in each class\n",
        "for class_id, count in enumerate(class_counts):\n",
        "    print(f\"Class {class_id}: {count} elements\")\n",
        "a1=0.5\n",
        "a2=-6\n",
        "a3=-2\n",
        "a4=1\n",
        "a5=3\n",
        "a6=1\n",
        "\n",
        "indices = np.arange(data.num_nodes)  # NumPy array of indices [0, 1, 2, ..., num_nodes-1]\n",
        "np.random.shuffle(indices)\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.6)\n",
        "\n",
        "# Further split train_idx into train and validation sets (e.g., 20% of train goes to validation)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.5)\n",
        "test_indices=test_idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u88m8qZfUdX-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsMOjg0RUedb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88eDCyKNUf57"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWZxuxXlygBh",
        "outputId": "f04114e4-e5c5-4cd8-b3ed-9d07aeae4822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "best validation by random search: 0.645045045045045\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import minimize\n",
        "import warnings\n",
        "warnings.simplefilter(\"error\", RuntimeWarning)  # Convert warnings to errors\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "\n",
        "\n",
        "\n",
        "def random_search(model, data, num_samples=50, num_splits=5):\n",
        "    \"\"\"\n",
        "    Perform random search for hyperparameter tuning while evaluating each set\n",
        "    of hyperparameters across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function to predict classes.\n",
        "        data: Dataset object.\n",
        "        num_samples: Number of random search samples (default: 120).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best hyperparameters found based on average accuracy.\n",
        "        best_score: The highest average accuracy obtained.\n",
        "    \"\"\"\n",
        "    best_params = None\n",
        "    best_score = float('-inf')\n",
        "    indices = np.arange(data.num_nodes)\n",
        "    maxi=1\n",
        "    for _ in range(num_samples):\n",
        "        print(\"step number \",_)\n",
        "        # Generate random hyperparameters\n",
        "        a1 = random.uniform(0, maxi)     # a1 must be positive\n",
        "        a2 = random.uniform(-maxi, -0.01)  # a2 must be negative\n",
        "        a3 = random.uniform(-maxi, -0.01)  # a3 must be negative\n",
        "        a5 = random.uniform(0, maxi)     # a5 must be positive\n",
        "        a4 = random.uniform(0, a5)    # a4 must be positive and a4 <= a5\n",
        "        a6 = random.uniform(0, maxi)\n",
        "        a7 = random.uniform(0, maxi)\n",
        "        a8 = random.uniform(0, a7)\n",
        "        params = [a1, a2, a3, a4, a5, a6,a7,a8]\n",
        "\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, *params)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "\n",
        "        if avg_score > best_score:\n",
        "            best_score = avg_score\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initial guesses for a1, a2, a3, a4, a5\n",
        "#initial_params = [0.5,-5,-2,1,3]\n",
        "\n",
        "# Bounds for parameters\n",
        " # Adjust bounds as needed\n",
        "\n",
        "# Optimize using scipy\n",
        "result,best_val = random_search(predictclass,data,num_samples=15,num_splits=5)\n",
        "#print(result)\n",
        "# Get best parameters\n",
        "best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7,best_a8 = result[0],result[1],result[2],result[3],result[4],result[5],result[6], result[7]\n",
        "\n",
        "# Evaluate on test set\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(\"best validation by random search:\", best_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqOUOkBf6ACE",
        "outputId": "648b1801-3a54-467d-93a4-e86d7e768752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial_params= [0.3515128494985965, -0.960108016381609, -0.06649444212768996, 4.542906006292986e-05, 0.005051865027275282, 0.5967083367495941, 0.03526265069962886, 0.004312203948864216]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from skopt.space import Real\n",
        "from skopt import gp_minimize\n",
        "def bayesian_optimization(model, data, num_calls=10, num_splits=5, initial_params=None):\n",
        "    \"\"\"\n",
        "    Bayesian Optimization to find best hyperparameters (a1, a2, a3, a4, a5, a6)\n",
        "    that maximize the validation accuracy while evaluating across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function that takes (data, train_idx, val_idx, a1, a2, a3, a4, a5, a6) and returns (loss, accuracy)\n",
        "        data: Dataset object.\n",
        "        num_calls: Number of function evaluations (default: 30).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "        initial_params: Optional initial solution from random search.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best found values for [a1, a2, a3, a4, a5, a6].\n",
        "        best_accuracy: The best validation accuracy found.\n",
        "    \"\"\"\n",
        "    maxi=1\n",
        "    search_space = [\n",
        "        Real(0, maxi, name=\"a1\"),        # a1 must be positive\n",
        "        Real(-maxi, -0.01, name=\"a2\"),   # a2 must be negative\n",
        "        Real(-maxi, -0.01, name=\"a3\"),   # a3 must be negative\n",
        "        Real(0, maxi, name=\"a4\"),        # a4 must be positive and a4 ≤ a5\n",
        "        Real(0, maxi, name=\"a5\"),        # a5 must be positive\n",
        "        Real(0, maxi, name=\"a6\"),\n",
        "        Real(0, maxi, name=\"a7\") , # a6 must be positive\n",
        "        Real(0, maxi, name=\"a8\")\n",
        "    ]\n",
        "\n",
        "    indices = np.arange(data.num_nodes)\n",
        "\n",
        "    def objective(params):\n",
        "        a1, a2, a3, a4, a5, a6,a7,a8 = params\n",
        "        a4, a5 = min(a4, a5), max(a4, a5)  # Ensure a4 ≤ a5\n",
        "        a8, a7 = min(a8, a7), max(a8, a7)\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, a1, a2, a3, a4, a5, a6,a7,a8)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "        return -avg_score  # Since `gp_minimize` minimizes the function, we negate accuracy\n",
        "\n",
        "    if initial_params is not None:\n",
        "        print(\"initial_params=\",initial_params)\n",
        "        initial_params[3], initial_params[4] = min(initial_params[3], initial_params[4]), max(initial_params[3], initial_params[4])\n",
        "\n",
        "        initial_params[7], initial_params[6] = min(initial_params[7], initial_params[6]), max(initial_params[7], initial_params[6])\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, x0=[initial_params], random_state=None)\n",
        "    else:\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, random_state=None)\n",
        "\n",
        "    best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7,best_a8 = result.x\n",
        "    best_a4, best_a5 = min(best_a4, best_a5), max(best_a4, best_a5)  # Ensure a4 ≤ a5\n",
        "    best_a8, best_a7 = min(best_a8, best_a7), max(best_a8, best_a7)\n",
        "    best_accuracy = -result.fun\n",
        "\n",
        "    best_params = [best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7,best_a8]\n",
        "\n",
        "    return best_params, best_accuracy\n",
        "\n",
        "# Example Usage:\n",
        "best_params, best_validation_score = bayesian_optimization(predictclass, data, num_calls=30, initial_params=result)\n",
        "\n",
        "print(\"best_validation by Bayesian=\",best_validation_score)\n",
        "if best_validation_score<best_val:\n",
        "  print(\"Bayesian made the parameters worse\")\n",
        "  best_params=result\n",
        "else:\n",
        "  best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7,best_a8 = best_params\n",
        "print(\"best params found =\", best_params)\n",
        "\n",
        "# # # # Step 2: Test the Model Using the Best Parameters\n",
        "y_pred_test, final_test_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7,best_a8)\n",
        "\n",
        "y_pred_val, final_val_accuracy = predictclass(data, train_idx, val_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7,best_a8)\n",
        "\n",
        "# # # Step 3: Print the Final Accuracy on the Test Set\n",
        "print(\"\\n🎯 Final Val Set Accuracy:\", final_val_accuracy)\n",
        "\n",
        "\n",
        "print(len(y_pred_test),len(test_idx))\n",
        "\n",
        "print(\"\\n🎯 Final Test Set Accuracy:\", final_test_accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FH9DxCcGSpLc"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c_sXm_FtUhXF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.nn import Linear, Sequential, ReLU, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class HighPassConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, amp=0.5, **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(**kwargs)\n",
        "        self.amp = amp\n",
        "        self.lin = Linear(in_channels, out_channels)\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.lin(x)\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "        out = self.amp * x - out\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "class Augmenter(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, amp=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = HighPassConv(in_dim, hidden_dim, amp=amp)\n",
        "        self.conv2 = HighPassConv(hidden_dim, hidden_dim, amp=amp)\n",
        "        self.mlp_edge_model = Sequential(\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim, hidden_dim * 2),\n",
        "            ReLU(),\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        src, dst = edge_index[0], edge_index[1]\n",
        "        edge_emb = x[src] + x[dst]\n",
        "        return torch.sigmoid(self.mlp_edge_model(edge_emb))\n",
        "\n",
        "class HeterophilicNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds=None):\n",
        "        super().__init__()\n",
        "        self.augmenter = Augmenter(in_dim, hidden_dim)\n",
        "        self.gnn_high = HighPassConv(in_dim, hidden_dim)\n",
        "        self.offset_mlp = Sequential(\n",
        "            Linear(in_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.final_mlp = Sequential(\n",
        "            Linear(hidden_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self.test_indices = test_indices  # Store test indices\n",
        "\n",
        "        # Store initial predictions but only for test indices (not trained)\n",
        "        if initial_preds is not None:\n",
        "            self.initial_preds = F.one_hot(initial_preds.long(), num_classes=num_classes).float()\n",
        "        else:\n",
        "            self.initial_preds = None\n",
        "\n",
        "    def forward(self, x, edge_index, train_indices):\n",
        "        edge_weights = self.augmenter(x, edge_index)\n",
        "        h = self.gnn_high(x, edge_index, edge_weights)\n",
        "        offset = self.offset_mlp(x)\n",
        "        logits = self.final_mlp(h + offset)\n",
        "\n",
        "        # If initial_preds exists, add it **only for test nodes**\n",
        "        if self.initial_preds is not None:\n",
        "            logits[self.test_indices] = logits[self.test_indices] + self.initial_preds\n",
        "\n",
        "        return F.log_softmax(logits, dim=1)\n",
        "\n",
        "# Training and Evaluation Code\n",
        "def train_and_evaluate(model, data, train_indices, test_indices, initial_preds, epochs=2000, lr=0.01):\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        loss = criterion(logits[train_indices], data.y[train_indices])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        predicted_classes = torch.argmax(logits, dim=1)\n",
        "        test_predictions = predicted_classes[test_indices]\n",
        "        final_accuracy = accuracy_score(data.y[test_indices].cpu().numpy(), test_predictions.cpu().numpy())\n",
        "\n",
        "    return final_accuracy, test_predictions\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TtC0NBH7UhKO"
      },
      "outputs": [],
      "source": [
        "# Compute initial test predictions\n",
        "initial_preds, initial_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6)\n",
        "\n",
        "# Ensure `initial_preds` is a tensor and on the correct device\n",
        "initial_preds = initial_preds.clone().detach()  # Ensures a proper detached copy\n",
        "\n",
        "\n",
        "print(f\"📊 Initial Classification Accuracy: {initial_accuracy:.4f}\")\n",
        "\n",
        "# Create the model\n",
        "model = HeterophilicNodeClassifier(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=len(set(data.y.tolist())),test_indices=test_indices, initial_preds=initial_preds\n",
        ").to(data.x.device)  # Ensure model is on the correct device\n",
        "\n",
        "# 🔄 Train the model before inference\n",
        "final_accuracy_before_djgnn, test_predictions_before_djgnn = train_and_evaluate(\n",
        "    model, data, train_idx, test_idx, initial_preds, epochs=100, lr=0.01\n",
        ")\n",
        "\n",
        "print(len(test_predictions_before_djgnn),len(test_idx))\n",
        "\n",
        "# ✅ Model evaluation after training\n",
        "model.eval()\n",
        "#with torch.no_grad():\n",
        " #   logits = model(data.x, data.edge_index, train_idx, test_idx, initial_test_preds=initial_preds)\n",
        " #   predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "\n",
        "print(f\"🎯  Classification Accuracy after running kdd2023: {final_accuracy_before_djgnn:.4f}\")\n",
        "#print(test_predictions)\n",
        "#print(len(initial_preds))\n",
        "#print(len(test_predictions))\n",
        "\n",
        "#print(len(val_idx))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nZSz76h8VGIZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class DJGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds, n_jumps=5, dropout=0.5):\n",
        "        super(DJGNN, self).__init__()\n",
        "        self.n_jumps = n_jumps\n",
        "        self.dropout = dropout\n",
        "        self.att = nn.Parameter(torch.ones(n_jumps + 1))  # Attention weights for jumps\n",
        "        self.sm = nn.Softmax(dim=0)\n",
        "\n",
        "        # Store initial predictions (converted to one-hot)\n",
        "        self.test_indices = test_indices\n",
        "        self.initial_preds = nn.Parameter(F.one_hot(initial_preds, num_classes).float(), requires_grad=False)\n",
        "\n",
        "        # GCN layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(n_jumps):\n",
        "            self.convs.append(GCNConv(in_dim, hidden_dim))\n",
        "\n",
        "        # Extra convolution layers\n",
        "        self.conv_extra = GCNConv(in_dim, hidden_dim)\n",
        "        self.bn_extra = nn.BatchNorm1d(hidden_dim)\n",
        "        self.conv_extra2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.bn_extra_2 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        # Final classifier\n",
        "        self.classify = nn.Linear(hidden_dim * (n_jumps + 1) + num_classes, num_classes)  # Extra input for initial preds\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "      mask_attentions = self.sm(self.att)\n",
        "\n",
        "      # Extra convolutions\n",
        "      extra_conv = self.conv_extra(x, edge_index).relu()\n",
        "      print(f\"extra_conv after conv_extra: {extra_conv.shape}\")\n",
        "      extra_conv = self.bn_extra(extra_conv)\n",
        "      print(f\"extra_conv after bn_extra: {extra_conv.shape}\")\n",
        "      extra_conv = F.dropout(extra_conv, p=self.dropout, training=self.training)\n",
        "      extra_conv = self.conv_extra2(extra_conv, edge_index).relu()\n",
        "      extra_conv = self.bn_extra_2(extra_conv)\n",
        "      extra_conv = extra_conv * mask_attentions[-1]\n",
        "      print(f\"extra_conv after conv_extra2 & mask: {extra_conv.shape}\")\n",
        "\n",
        "      # Jumping knowledge mechanism: collect outputs from each conv layer\n",
        "      z_s = []\n",
        "      for i, conv in enumerate(self.convs):\n",
        "          z = conv(x, edge_index).relu() * mask_attentions[i]\n",
        "          print(f\"z from conv {i}: {z.shape}\")\n",
        "          z_s.append(z)\n",
        "\n",
        "      # Concatenate all jump outputs with extra_conv\n",
        "      final_z = torch.cat(z_s + [extra_conv], dim=1)\n",
        "      print(f\"✅ final_z shape BEFORE concatenation: {final_z.shape}\")  # Expect [num_nodes, feature_dim]\n",
        "\n",
        "      # Debug: Print test indices shape and the slice from final_z\n",
        "      print(f\"✅ self.test_indices shape: {self.test_indices.shape}\")  # Expect [num_test_samples]\n",
        "      test_slice = final_z[self.test_indices]\n",
        "      print(f\"✅ final_z[self.test_indices] shape: {test_slice.shape}\")  # Expect [num_test_samples, feature_dim]\n",
        "\n",
        "      # Ensure self.initial_preds is a LongTensor\n",
        "      num_classes = self.classify.out_features  # Get number of classes\n",
        "      initial_preds_long = self.initial_preds.long().squeeze()\n",
        "      print(f\"initial_preds_long shape after squeeze: {initial_preds_long.shape}\")\n",
        "\n",
        "      # Clamp indices to valid range\n",
        "      initial_preds_long = torch.clamp(initial_preds_long, min=0, max=num_classes - 1)\n",
        "\n",
        "      # Convert to one-hot encoding\n",
        "      one_hot_preds = F.one_hot(initial_preds_long, num_classes=num_classes).float()\n",
        "      print(f\"✅ one_hot_preds shape immediately after one_hot: {one_hot_preds.shape}\")\n",
        "\n",
        "      # If one_hot_preds still has an extra dimension, print its dimensions explicitly\n",
        "      for idx, dim in enumerate(one_hot_preds.shape):\n",
        "          print(f\"one_hot_preds dim {idx}: {dim}\")\n",
        "\n",
        "      # Attempt to remove extra dimensions by squeezing only the dims of size 1\n",
        "      one_hot_preds = one_hot_preds.squeeze()\n",
        "      print(f\"✅ one_hot_preds shape after squeeze(): {one_hot_preds.shape}\")\n",
        "\n",
        "      # Check dimensions explicitly\n",
        "      if one_hot_preds.ndim != 2:\n",
        "          print(f\"❌ one_hot_preds still has {one_hot_preds.ndim} dimensions; expected 2 dimensions!\")\n",
        "\n",
        "      # Now, try concatenation and catch errors with more prints\n",
        "      try:\n",
        "          final_z[self.test_indices] = torch.cat((final_z[self.test_indices], one_hot_preds), dim=1)\n",
        "      except RuntimeError as e:\n",
        "          print(f\"❌ ERROR: Shape mismatch at concatenation!\")\n",
        "          print(f\"🔍 final_z[self.test_indices] shape: {final_z[self.test_indices].shape}\")\n",
        "          print(f\"🔍 one_hot_preds shape: {one_hot_preds.shape}\")\n",
        "          raise e  # Re-raise after printing shapes\n",
        "\n",
        "      # Dropout and classification\n",
        "      final_z = F.dropout(final_z, p=self.dropout, training=self.training)\n",
        "      logits = self.classify(final_z).log_softmax(dim=-1)\n",
        "      return logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cldUM1jPk72E"
      },
      "outputs": [],
      "source": [
        "def train_djgnn(model, data, train_idx, test_idx, initial_preds_djgnn, epochs=100, lr=0.01):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(data.x, data.edge_index)\n",
        "        loss_supervised = criterion(logits[train_idx], data.y[train_idx])\n",
        "\n",
        "        # 🔥 NEW: Consistency Loss to prevent drastic changes\n",
        "        confidence_threshold = 0.85  # Change only high-confidence nodes\n",
        "        high_confidence_mask = logits[test_idx].softmax(dim=1).max(dim=1).values > confidence_threshold\n",
        "\n",
        "        # Apply consistency loss only to confident predictions\n",
        "        filtered_loss = F.cross_entropy(logits[test_idx][high_confidence_mask], initial_preds_djgnn[high_confidence_mask])\n",
        "        loss = loss_supervised + 0.1 * filtered_loss\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy on test set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_logits = model(data.x, data.edge_index)\n",
        "            test_preds = test_logits[test_idx].argmax(dim=1)\n",
        "            test_correct = (test_preds == data.y[test_idx]).sum().item()\n",
        "            test_acc = test_correct / len(test_idx)\n",
        "\n",
        "    #    print(f\"🧐 Epoch {epoch+1:02d} | Loss: {loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "       # if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "       #     print(f\"🔍 Logits Before Argmax (First 5 Samples):\\n{test_logits[test_idx][:5]}\")\n",
        "\n",
        "    return test_preds, test_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p936LZ0GlGf3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Ensure `initial_preds_djgnn` is a tensor and detached\n",
        "initial_preds_djgnn = test_predictions_before_djgnn.clone().detach().long()  # Explicitly convert to LongTensor\n",
        "initial_preds = initial_preds.clone().detach().long()\n",
        "\n",
        "# Get the number of unique classes from `data.y`\n",
        "num_classes = data.y.max().item() + 1  # `max() + 1` ensures it captures all labels\n",
        "\n",
        "print(f\"📊 Number of Test Samples: {len(initial_preds_djgnn)}\")\n",
        "print(f\"🔢 Number of Unique Classes: {num_classes}\")\n",
        "\n",
        "# 🚀 Initialize DJ-GNN model with test indices & initial predictions\n",
        "djgnn_model = DJGNN(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=num_classes,  # Use the correct `num_classes`\n",
        "    test_indices=torch.tensor(test_idx, dtype=torch.long, device=data.x.device),  # Ensure `test_idx` is a tensor\n",
        "    initial_preds=initial_preds_djgnn,  # Pass initial predictions (already `LongTensor`)\n",
        "    n_jumps=5,  # Use 5 hops for diffusion\n",
        "    dropout=0.5\n",
        ").to(data.x.device)  # Ensure it's on the correct device\n",
        "\n",
        "# 🚀 Train DJ-GNN and get new predictions\n",
        "new_preds, final_accuracy_after_djgnn = train_djgnn(\n",
        "    djgnn_model, data, train_idx, test_idx, initial_preds_djgnn, epochs=500, lr=0.01\n",
        ")\n",
        "\n",
        "# 🎯 Compare accuracies before & after DJ-GNN\n",
        "print(\"\\n🔥 Final Results:\")\n",
        "print(f\"🎯 Accuracy BEFORE DJ-GNN: {final_accuracy_before_djgnn:.4f}\")\n",
        "print(f\"🚀 Accuracy AFTER DJ-GNN: {final_accuracy_after_djgnn:.4f}\")\n",
        "\n",
        "# 🔍 Sample Predictions Before & After DJ-GNN (Print first 10 for debugging)\n",
        "print(\"\\n🔍 Sample Predictions Before & After DJ-GNN:\")\n",
        "for i in range(min(10, len(test_idx))):  # Ensure we don't go out of bounds\n",
        "    print(f\"🧐 Sample {i+1} | Before: {initial_preds_djgnn[i].item()} | After: {new_preds[i].item()}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}