{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CqGs0nK9M8Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc73f99-b08a-4cc4-9197-b50f9b4c40b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.11/dist-packages (12.0.1)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gurobipy\n",
        "!pip install torch_geometric\n",
        "!pip install sortedcontainers\n",
        "\n",
        "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "!pip install scikit-optimize\n",
        "\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import pairwise_distances as sklearn_pairwise_distances\n",
        "import networkx as nx\n",
        " # Use \"cosine\" for cosine similarity\n",
        "import heapq\n",
        "\n",
        "\n",
        "os.environ[\"GRB_LICENSE_FILE\"] = \"gurobi (3).lic\"\n",
        "os.environ[\"GRB_WLSACCESSID\"] = \"f218200d-1f8d-4342-83f5-b7b2d9263751\"  # Replace with your actual WLSACCESSID\n",
        "os.environ[\"GRB_WLSSECRET\"] = \"528d596b-babc-4a1e-bda2-693c44f4f006\"  # Replace with your actual WLSSECRET\n",
        "os.environ[\"GRB_LICENSEID\"] = \"840285\"  # Replace with your actual LICENSEID\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from torch_geometric.datasets import WebKB, WikipediaNetwork, Actor\n",
        "\n",
        "from torch_geometric.datasets import FacebookPagePage\n",
        "\n",
        "from torch_geometric.datasets import SNAPDataset\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import networkx as nx\n",
        "from torch_geometric.datasets import WebKB\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sortedcontainers import SortedSet  # Ordered set\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "from torch_geometric.datasets import WikipediaNetwork\n",
        "from torch_geometric.datasets import Actor\n",
        "\n",
        "# Load the Film dataset (also known as Actor dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BD28jxmhNmm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "#dataset = Actor(root='data/Film')\n",
        "data = dataset[0]\n",
        "data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "\n",
        "# ✅ Remove duplicate edges\n",
        "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "# ✅ Convert to NetworkX Graph to Find Components\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "components = list(nx.connected_components(G))\n",
        "num_components = len(components)\n",
        "\n",
        "print(f\"\\n✅ Loaded  dataset with {data.num_nodes} nodes, {data.edge_index.shape[1]} edges\")\n",
        "print(f\"   - Features: {data.x.shape[1]}\")\n",
        "print(f\"   - Number of Classes: {len(set(data.y.numpy()))}\")\n",
        "print(f\"   - Number of Components: {num_components}\")\n",
        "\n",
        "# ✅ Set Training Percentage\n",
        "train_percentage = 0.65\n",
        "\n",
        "# ✅ Select Training Nodes\n",
        "train_indices = []\n",
        "for component in components:\n",
        "    component = list(component)\n",
        "    t = max(1, int(train_percentage * len(component)))\n",
        "    sampled_nodes = np.random.choice(component, t, replace=False)\n",
        "    train_indices.extend(sampled_nodes)\n",
        "\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "# ✅ Initialize Prediction Labels\n",
        "y_pred = np.full(data.num_nodes, -1)\n",
        "for idx in train_indices:\n",
        "    y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "# ✅ Compute Label Distribution\n",
        "total_label_counts = Counter(data.y.numpy())\n",
        "num_labels = len(set(data.y.numpy()))\n",
        "alpha = 1  # Laplace smoothing\n",
        "\n",
        "dataset_label_distribution = {\n",
        "    lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "    for lbl in total_label_counts.keys()\n",
        "}\n",
        "\n",
        "train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "train_label_distribution = {\n",
        "    lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "    for lbl in dataset_label_distribution.keys()\n",
        "}\n",
        "\n",
        "# ✅ Precompute Neighbors for Each Node\n",
        "A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "A = A.numpy()\n",
        "neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "# ✅ Track Instances Assigned to Each Label\n",
        "class_instances = defaultdict(set)\n",
        "for idx in train_indices:\n",
        "    class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "# ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "ordered_set = SortedSet()\n",
        "train_labeled_nodes = set(train_indices)\n",
        "\n",
        "for node in range(data.num_nodes):\n",
        "    if y_pred[node] == -1:  # Only process unlabeled nodes\n",
        "        labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "        num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "        total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "        if total_neighbors > 0:\n",
        "            weighted_score = (num_labeled_by_propagation + 3 * num_labeled_by_train) / total_neighbors\n",
        "        else:\n",
        "            weighted_score = 0\n",
        "\n",
        "        ordered_set.add((-weighted_score, node))\n",
        "\n",
        "# ✅ Iteratively Label the Most Constrained Nodes\n",
        "while ordered_set:\n",
        "    _, node = ordered_set.pop(0)\n",
        "\n",
        "    if y_pred[node] != -1:\n",
        "        continue\n",
        "\n",
        "    # Get labeled neighbors\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    # 🚨 If this node has 0 labeled neighbors\n",
        "    if not neighbor_labels:\n",
        "        print(f\"\\n🚨 STRANGE: Node {node} was chosen, but it has 0 labeled neighbors!\")\n",
        "        break\n",
        "\n",
        "    # Compute Neighbor Label Distribution\n",
        "    neighbor_label_counts = Counter(neighbor_labels)\n",
        "    total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "    if total_labeled_neighbors > 0:\n",
        "        neighbor_label_distribution = {\n",
        "            lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "        }\n",
        "    else:\n",
        "        neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # ✅ Compute Feature Distance to Each Class\n",
        "    # feature_diffs = {}\n",
        "    # for lbl in dataset_label_distribution.keys():\n",
        "    #   if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "    #       instance_features = data.x[list(class_instances[lbl])]\n",
        "    #       node_feature = data.x[node].unsqueeze(0)\n",
        "\n",
        "    #       # Compute distances for each instance\n",
        "    #       distances = torch.norm(instance_features - node_feature, dim=1).tolist()\n",
        "\n",
        "    #       # Apply weight based on whether the instance is from training or predicted labels\n",
        "    #       weighted_distances = [\n",
        "    #           (3 * dist) if instance in train_indices else dist  # Give 3x weight if in training set\n",
        "    #           for instance, dist in zip(class_instances[lbl], distances)\n",
        "    #       ]\n",
        "\n",
        "    #       # Compute weighted average distance\n",
        "    #       avg_distance = sum(weighted_distances) / len(weighted_distances)\n",
        "    #       feature_diffs[lbl] = avg_distance\n",
        "    #   else:\n",
        "    #       feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    feature_diffs = {}\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "            instance_features = data.x[list(class_instances[lbl])]\n",
        "            node_feature = data.x[node].unsqueeze(0)\n",
        "           # print(len(instance_features),len(node_feature))\n",
        "            avg_distance = torch.mean(torch.norm(instance_features - node_feature, dim=1)).item()\n",
        "            feature_diffs[lbl] = avg_distance\n",
        "        else:\n",
        "            feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    # ✅ Select the Best Label Based on the Adjusted Score\n",
        "    best_label_candidates = []\n",
        "    max_value = float('-inf')\n",
        "    a1=0.5\n",
        "    a2=-6\n",
        "    a3=-2\n",
        "    a4=1\n",
        "    a5=3\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        score = (\n",
        "            a1*train_label_distribution.get(lbl, 0)\n",
        "            +a2* neighbor_label_distribution.get(lbl, 0)\n",
        "            +a3*feature_diffs[lbl]  # Penalize by average feature distance\n",
        "        )\n",
        "        print(lbl,score,)\n",
        "\n",
        "        if score - max_value > 0.01:\n",
        "            best_label_candidates = [lbl]\n",
        "            max_value = score\n",
        "        elif abs(score - max_value) <= 0.01:\n",
        "            best_label_candidates.append(lbl)\n",
        "\n",
        "\n",
        "    best_label = random.choice(best_label_candidates)\n",
        "    y_pred[node] = best_label\n",
        "    class_instances[best_label].add(node)  # Track newly labeled nodes\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    print(f\"\\n🔹 Labelling Node {node} \")\n",
        "    # ✅ Print Prediction Outcome\n",
        "    true_label = data.y[node].item()\n",
        "    correct = \"✅\" if best_label == true_label else \"❌\"\n",
        "    print(f\"   -> Predicted Label: {best_label} | True Label: {true_label} {correct}\")\n",
        "\n",
        "   # print(f\"   - Total Neighbors: {len(neighbors_dict[node])}\")\n",
        "   # print(f\"   - Labeled Neighbors: {len(neighbor_labels)}\")\n",
        "    for lbl, count in label_counts.items():\n",
        "        print(f\"   - Class {lbl}: {count} neighbors\")\n",
        "        # ✅ Update Labeled Neighbor Score for Unlabeled Neighbors\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                new_weighted_score = (a4*num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "# ✅ Evaluate Accuracy\n",
        "test_indices = [i for i in range(data.num_nodes) if i not in train_indices]\n",
        "y_true = data.y[test_indices]\n",
        "y_pred_test = y_pred[test_indices]\n",
        "\n",
        "valid_idx = [i for i in range(len(y_pred_test)) if y_pred_test[i] != -1]\n",
        "if valid_idx:\n",
        "    final_accuracy = accuracy_score(y_true[valid_idx], y_pred_test[valid_idx])\n",
        "    print(f\"\\n🎯 Label Propagation Accuracy: {final_accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"\\n❌ No valid predictions were made!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZChMrfbyNoOn",
        "outputId": "ffde6545-6cde-4d29-94e1-1fce3d8ebc70"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Loaded  dataset with 183 nodes, 574 edges\n",
            "   - Features: 1703\n",
            "   - Number of Classes: 5\n",
            "   - Number of Components: 1\n",
            "3 -17.556696635920826\n",
            "0 -23.1232427581539\n",
            "2 -22.140234908437343\n",
            "4 -19.062000197123705\n",
            "1 -14.274726859922332\n",
            "\n",
            "🔹 Labelling Node 0 \n",
            "   -> Predicted Label: 1 | True Label: 3 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -30.863053065974537\n",
            "0 -30.978721044897064\n",
            "2 -31.193642577504725\n",
            "4 -37.2165641009323\n",
            "1 -30.223849288816375\n",
            "\n",
            "🔹 Labelling Node 1 \n",
            "   -> Predicted Label: 1 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.942539912898365\n",
            "0 -26.936925314306244\n",
            "2 -21.92062278685531\n",
            "4 -20.438049238871752\n",
            "1 -22.65191363512985\n",
            "\n",
            "🔹 Labelling Node 4 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.606652003962818\n",
            "0 -20.42047061765097\n",
            "2 -20.65581031737289\n",
            "4 -23.929500502299486\n",
            "1 -21.09605883776657\n",
            "\n",
            "🔹 Labelling Node 7 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.430821162898365\n",
            "0 -29.732724569677337\n",
            "2 -27.061867675160975\n",
            "4 -30.71828071470183\n",
            "1 -27.955187789792937\n",
            "\n",
            "🔹 Labelling Node 16 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 6 neighbors\n",
            "   - Class 0: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.788017970759693\n",
            "0 -29.06103458249472\n",
            "2 -22.06745811400375\n",
            "4 -21.358657759379565\n",
            "1 -22.434168807859344\n",
            "\n",
            "🔹 Labelling Node 19 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.306362849910084\n",
            "0 -31.53066577756308\n",
            "2 -23.948716124868007\n",
            "4 -23.578493040751635\n",
            "1 -24.931267730588836\n",
            "\n",
            "🔹 Labelling Node 26 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.17717621966106\n",
            "0 -31.79749812924765\n",
            "2 -24.822655639028163\n",
            "4 -24.457658690165697\n",
            "1 -25.96051310717575\n",
            "\n",
            "🔹 Labelling Node 27 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -28.649450999934498\n",
            "0 -28.31226100766562\n",
            "2 -26.542757949208827\n",
            "4 -28.057945173930346\n",
            "1 -27.32902239977829\n",
            "\n",
            "🔹 Labelling Node 29 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 3: 3 neighbors\n",
            "   - Class 4: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.872551662165943\n",
            "0 -22.84005298459433\n",
            "2 -22.18724342284164\n",
            "4 -19.002220076274096\n",
            "1 -20.253140441770476\n",
            "\n",
            "🔹 Labelling Node 30 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.8768622700761\n",
            "0 -29.97960033261679\n",
            "2 -23.408595046376796\n",
            "4 -22.364416044902026\n",
            "1 -23.5526094359111\n",
            "\n",
            "🔹 Labelling Node 32 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.526718837458912\n",
            "0 -26.985427282690033\n",
            "2 -20.579289397573085\n",
            "4 -19.293146055888354\n",
            "1 -20.6059541624736\n",
            "\n",
            "🔹 Labelling Node 35 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.755257350642506\n",
            "0 -21.82910861813925\n",
            "2 -21.186243972158046\n",
            "4 -23.012880247782885\n",
            "1 -21.846592895383758\n",
            "\n",
            "🔹 Labelling Node 36 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.551455241877857\n",
            "0 -25.677241705297455\n",
            "2 -18.948729476308436\n",
            "4 -18.031814497660815\n",
            "1 -19.366995803708953\n",
            "\n",
            "🔹 Labelling Node 38 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -28.842543346125904\n",
            "0 -26.9773630126705\n",
            "2 -27.03428359923324\n",
            "4 -29.487869185160815\n",
            "1 -26.968911163206023\n",
            "\n",
            "🔹 Labelling Node 48 \n",
            "   -> Predicted Label: 1 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.25195763750774\n",
            "0 -31.363017462133392\n",
            "2 -24.364066085195155\n",
            "4 -23.88455383176726\n",
            "1 -25.57323168932907\n",
            "\n",
            "🔹 Labelling Node 68 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.96517441912395\n",
            "0 -26.27760066831015\n",
            "2 -19.48750968871078\n",
            "4 -18.581550520610033\n",
            "1 -21.088576309080047\n",
            "\n",
            "🔹 Labelling Node 69 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.05834077044231\n",
            "0 -26.098649404882416\n",
            "2 -19.550934752797694\n",
            "4 -17.94120208616179\n",
            "1 -21.101256362790984\n",
            "\n",
            "🔹 Labelling Node 91 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.611330730159107\n",
            "0 -31.108100317358\n",
            "2 -24.30159088072738\n",
            "4 -24.04245750303191\n",
            "1 -25.507086746091765\n",
            "\n",
            "🔹 Labelling Node 93 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.33874962969524\n",
            "0 -22.074172399877533\n",
            "2 -22.494437178945155\n",
            "4 -22.23800269956511\n",
            "1 -23.46943186938278\n",
            "\n",
            "🔹 Labelling Node 101 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -26.293869716365162\n",
            "0 -21.2754587157955\n",
            "2 -21.851633986806483\n",
            "4 -21.483970564555346\n",
            "1 -22.816378585691375\n",
            "\n",
            "🔹 Labelling Node 105 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.05839417620403\n",
            "0 -26.421113394140228\n",
            "2 -19.67557807860336\n",
            "4 -18.716682356547533\n",
            "1 -20.975415222043914\n",
            "\n",
            "🔹 Labelling Node 109 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.32234452410442\n",
            "0 -30.133349798559173\n",
            "2 -23.126654586171718\n",
            "4 -22.25295440549773\n",
            "1 -24.795525543088836\n",
            "\n",
            "🔹 Labelling Node 112 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.005568248469654\n",
            "0 -26.563620947240814\n",
            "2 -19.79904075560531\n",
            "4 -19.641462248515307\n",
            "1 -21.98366641222946\n",
            "\n",
            "🔹 Labelling Node 115 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.512514812190357\n",
            "0 -26.783191107152923\n",
            "2 -23.040465316152186\n",
            "4 -21.55593292112273\n",
            "1 -24.47379779040329\n",
            "\n",
            "🔹 Labelling Node 117 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.375746471125904\n",
            "0 -23.57625331723593\n",
            "2 -19.988104781484218\n",
            "4 -21.74570457334441\n",
            "1 -21.5041475218486\n",
            "\n",
            "🔹 Labelling Node 118 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.57275269671184\n",
            "0 -23.403178594945892\n",
            "2 -22.879609069203944\n",
            "4 -18.836751860331713\n",
            "1 -21.229966155881804\n",
            "\n",
            "🔹 Labelling Node 120 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.560841304499927\n",
            "0 -25.64432086789511\n",
            "2 -21.393622359609218\n",
            "4 -20.36944381589812\n",
            "1 -22.992247573728484\n",
            "\n",
            "🔹 Labelling Node 125 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.36985085650188\n",
            "0 -27.05872859799765\n",
            "2 -20.730685195302577\n",
            "4 -19.567790907572924\n",
            "1 -21.705279342527312\n",
            "\n",
            "🔹 Labelling Node 128 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.655823451716724\n",
            "0 -24.50625934445761\n",
            "2 -21.164380034780116\n",
            "4 -22.67096511716765\n",
            "1 -22.39857577502243\n",
            "\n",
            "🔹 Labelling Node 132 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.90914986773235\n",
            "0 -29.0242437347164\n",
            "2 -22.34342666563949\n",
            "4 -21.05349342222136\n",
            "1 -23.306889526243133\n",
            "\n",
            "🔹 Labelling Node 139 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.207203609187427\n",
            "0 -24.31104030454062\n",
            "2 -23.70546050963363\n",
            "4 -18.75277130002898\n",
            "1 -21.759514800901336\n",
            "\n",
            "🔹 Labelling Node 145 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.855780345637623\n",
            "0 -28.832581899999603\n",
            "2 -22.322808226918788\n",
            "4 -20.438405913066088\n",
            "1 -23.059569351072234\n",
            "\n",
            "🔹 Labelling Node 149 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.623938304621998\n",
            "0 -26.170586965917572\n",
            "2 -19.82437034544906\n",
            "4 -18.185453337382494\n",
            "1 -20.718253127927703\n",
            "\n",
            "🔹 Labelling Node 154 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.252461177546802\n",
            "0 -28.479768179296478\n",
            "2 -21.94878669676742\n",
            "4 -21.00149146909636\n",
            "1 -23.39738940417282\n",
            "\n",
            "🔹 Labelling Node 179 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -26.213398677546802\n",
            "0 -21.782380483983978\n",
            "2 -20.9127282708641\n",
            "4 -20.87750045652312\n",
            "1 -22.839978210325164\n",
            "\n",
            "🔹 Labelling Node 108 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 3: 4 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.37608216448528\n",
            "0 -23.809815786718353\n",
            "2 -20.893914183950038\n",
            "4 -21.80893699521941\n",
            "1 -21.89645289599411\n",
            "\n",
            "🔹 Labelling Node 11 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.877657634455982\n",
            "0 -26.20593204343222\n",
            "2 -22.98672195372543\n",
            "4 -24.81744949216765\n",
            "1 -24.576258651609344\n",
            "\n",
            "🔹 Labelling Node 147 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.729778987605396\n",
            "0 -29.261926077245697\n",
            "2 -26.30379386839828\n",
            "4 -27.977195662211596\n",
            "1 -30.186095229978484\n",
            "\n",
            "🔹 Labelling Node 167 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.043554240901297\n",
            "0 -26.438778875707612\n",
            "2 -23.281356963491053\n",
            "4 -20.305707853984057\n",
            "1 -23.532122604246062\n",
            "\n",
            "🔹 Labelling Node 171 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 3 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.069520180936603\n",
            "0 -23.64449458333982\n",
            "2 -23.708251400840812\n",
            "4 -23.815514266900976\n",
            "1 -24.36854471751792\n",
            "\n",
            "🔹 Labelling Node 84 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 4: 5 neighbors\n",
            "   - Class 3: 3 neighbors\n",
            "   - Class 2: 3 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.93609307451946\n",
            "0 -23.47839298093222\n",
            "2 -22.719319304799647\n",
            "4 -19.117895048808276\n",
            "1 -21.618319503660125\n",
            "\n",
            "🔹 Labelling Node 31 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.617615443904224\n",
            "0 -24.653178594945892\n",
            "2 -22.394698104238124\n",
            "4 -24.351226729106127\n",
            "1 -22.913233749265594\n",
            "\n",
            "🔹 Labelling Node 6 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.939211589534107\n",
            "0 -30.249566458105072\n",
            "2 -26.640759429311366\n",
            "4 -25.525604170512377\n",
            "1 -27.807269088621062\n",
            "\n",
            "🔹 Labelling Node 61 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.830519420344654\n",
            "0 -25.766528509496673\n",
            "2 -22.24350448546371\n",
            "4 -21.84037010068816\n",
            "1 -23.33379840075485\n",
            "\n",
            "🔹 Labelling Node 151 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.312702876765552\n",
            "0 -23.631066702245697\n",
            "2 -19.891844710683436\n",
            "4 -21.67546073789519\n",
            "1 -20.786133758420867\n",
            "\n",
            "🔹 Labelling Node 165 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -28.585406810481373\n",
            "0 -27.436386679052337\n",
            "2 -25.939038237905116\n",
            "4 -25.232377928446947\n",
            "1 -27.00824259936325\n",
            "\n",
            "🔹 Labelling Node 116 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 3: 4 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.206129771907154\n",
            "0 -26.110345266698822\n",
            "2 -22.24105735716781\n",
            "4 -25.13345519895476\n",
            "1 -23.883875839109344\n",
            "\n",
            "🔹 Labelling Node 75 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.482201320369068\n",
            "0 -20.834592245458587\n",
            "2 -22.11215110716781\n",
            "4 -27.482316893290697\n",
            "1 -22.422245971555633\n",
            "\n",
            "🔹 Labelling Node 76 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 4: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -14.926782352168386\n",
            "0 -20.96863307797812\n",
            "2 -17.32109352049789\n",
            "4 -19.88784973020476\n",
            "1 -18.860085479612273\n",
            "\n",
            "🔹 Labelling Node 161 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.422285396296804\n",
            "0 -23.68799648129843\n",
            "2 -21.48690696654281\n",
            "4 -22.15721237058562\n",
            "1 -23.166247360105437\n",
            "\n",
            "🔹 Labelling Node 57 \n",
            "   -> Predicted Label: 2 | True Label: 2 ✅\n",
            "   - Class 3: 3 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.457094890315357\n",
            "0 -22.67306842648886\n",
            "2 -21.906153640126796\n",
            "4 -18.07757369871062\n",
            "1 -20.26389216601364\n",
            "\n",
            "🔹 Labelling Node 110 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.67582009478313\n",
            "0 -22.881629370092377\n",
            "2 -22.129336318349452\n",
            "4 -18.324321669291674\n",
            "1 -20.670662872190398\n",
            "\n",
            "🔹 Labelling Node 170 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.970833522517506\n",
            "0 -22.19244327390097\n",
            "2 -27.034666976308436\n",
            "4 -20.232919615458666\n",
            "1 -22.388951293821258\n",
            "\n",
            "🔹 Labelling Node 13 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.958895427424732\n",
            "0 -28.47172679746054\n",
            "2 -34.636675795888515\n",
            "4 -28.808793944071947\n",
            "1 -29.01034449755661\n",
            "\n",
            "🔹 Labelling Node 88 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.346747142512623\n",
            "0 -22.475417517065033\n",
            "2 -21.677298507070155\n",
            "4 -18.582757872294604\n",
            "1 -20.658209792966765\n",
            "\n",
            "🔹 Labelling Node 102 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -17.61311028643352\n",
            "0 -26.692912481664642\n",
            "2 -20.220213851308436\n",
            "4 -19.17451850767058\n",
            "1 -21.248732559080047\n",
            "\n",
            "🔹 Labelling Node 134 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.013529521663013\n",
            "0 -24.73743953549765\n",
            "2 -20.46261497435531\n",
            "4 -20.041105192851244\n",
            "1 -22.40229319750778\n",
            "\n",
            "🔹 Labelling Node 47 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.324490291316334\n",
            "0 -25.1112855895748\n",
            "2 -22.31541152892074\n",
            "4 -22.804634016703783\n",
            "1 -23.633803359861297\n",
            "\n",
            "🔹 Labelling Node 180 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.232403499324146\n",
            "0 -28.054725073217377\n",
            "2 -21.371172866201015\n",
            "4 -19.849319380473315\n",
            "1 -22.483492843503875\n",
            "\n",
            "🔹 Labelling Node 73 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.46180985613567\n",
            "0 -19.00370921933554\n",
            "2 -18.44622322020492\n",
            "4 -17.901613157939135\n",
            "1 -20.053027145261687\n",
            "\n",
            "🔹 Labelling Node 122 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.508185130793873\n",
            "0 -21.613921545385345\n",
            "2 -20.47170730528793\n",
            "4 -25.38426200742644\n",
            "1 -22.246092788572234\n",
            "\n",
            "🔹 Labelling Node 152 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -31.714039546687427\n",
            "0 -26.238109014867767\n",
            "2 -26.625119170522304\n",
            "4 -26.26865569944304\n",
            "1 -27.214743606443328\n",
            "\n",
            "🔹 Labelling Node 158 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -15.743996364314382\n",
            "0 -17.353679083227142\n",
            "2 -17.18864150938949\n",
            "4 -23.05881683225554\n",
            "1 -19.184967986936492\n",
            "\n",
            "🔹 Labelling Node 160 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.46967766924602\n",
            "0 -19.92468967282675\n",
            "2 -24.95344444212875\n",
            "4 -17.828946989726244\n",
            "1 -20.419075958127898\n",
            "\n",
            "🔹 Labelling Node 67 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "🎯 Label Propagation Accuracy: 0.6923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sortedcontainers import SortedSet\n",
        "from sklearn.metrics import accuracy_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "def predictclass(data, train_indices, test_indices, a1, a2, a3, a4, a5,a6):\n",
        "    data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "    train_indices = list(train_indices)\n",
        "    test_indices = list(test_indices)\n",
        "\n",
        "    # ✅ Remove duplicate edges\n",
        "    data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "    # ✅ Initialize Prediction Labels\n",
        "    y_pred = np.full(data.num_nodes, -1, dtype=int)\n",
        "    for idx in train_indices:\n",
        "        y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "    # ✅ Compute Label Distribution\n",
        "    total_label_counts = Counter(data.y.numpy())\n",
        "    num_labels = len(set(data.y.numpy()))\n",
        "    alpha = 1  # Laplace smoothing\n",
        "\n",
        "    dataset_label_distribution = {\n",
        "        lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "        for lbl in total_label_counts.keys()\n",
        "    }\n",
        "\n",
        "    train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "    train_label_distribution = {\n",
        "        lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "        for lbl in dataset_label_distribution.keys()\n",
        "    }\n",
        "\n",
        "    # ✅ Precompute Neighbors for Each Node\n",
        "    A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "    A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "    neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "    # ✅ Track Instances Assigned to Each Label\n",
        "    class_instances = defaultdict(set)\n",
        "    for idx in train_indices:\n",
        "        class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "    # ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "    ordered_set = SortedSet()\n",
        "    train_labeled_nodes = set(train_indices)\n",
        "\n",
        "    for node in range(data.num_nodes):\n",
        "        if y_pred[node] == -1:\n",
        "            labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "            num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "            num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "            total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "            if total_neighbors > 0:\n",
        "                weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors\n",
        "            else:\n",
        "                weighted_score = 0\n",
        "\n",
        "            ordered_set.add((-weighted_score, node))\n",
        "\n",
        "    # ✅ Iteratively Label the Most Constrained Nodes\n",
        "    while ordered_set:\n",
        "        _, node = ordered_set.pop(0)\n",
        "\n",
        "        if y_pred[node] != -1:\n",
        "            continue  # Skip already labeled nodes\n",
        "\n",
        "        # Get labeled neighbors\n",
        "        neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        label_counts = Counter(neighbor_labels)\n",
        "\n",
        "        # 🚨 If this node has 0 labeled neighbors\n",
        "        if not neighbor_labels:\n",
        "            continue\n",
        "\n",
        "        # Compute Neighbor Label Distribution\n",
        "        neighbor_label_counts = Counter(neighbor_labels)\n",
        "        total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "        if total_labeled_neighbors > 0:\n",
        "            neighbor_label_distribution = {\n",
        "                lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "            }\n",
        "        else:\n",
        "            neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        feature_diffs = {}\n",
        "\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "                instance_features = data.x[list(class_instances[lbl])]\n",
        "                node_feature = data.x[node].unsqueeze(0)\n",
        "\n",
        "                if instance_features.numel() > 0:  # ✅ Ensure instance_features is not empty\n",
        "                    avg_distance = torch.mean(torch.norm(instance_features - node_feature, dim=1)).item()\n",
        "                else:\n",
        "                    avg_distance = 0  # ✅ Avoid empty slice issue\n",
        "                feature_diffs[lbl] = avg_distance\n",
        "            else:\n",
        "                feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "        # ✅ Select the Best Label Based on the Adjusted Score\n",
        "        best_label_candidates = []\n",
        "        max_value = float('-inf')\n",
        "\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            score = (\n",
        "                a1 * train_label_distribution.get(lbl, 0)\n",
        "                + a2 * neighbor_label_distribution.get(lbl, 0)\n",
        "                + a3 * feature_diffs[lbl]  # Penalize by average feature distance\n",
        "            )\n",
        "\n",
        "            if score - max_value > 0.01:\n",
        "                best_label_candidates = [lbl]\n",
        "                max_value = score\n",
        "            elif abs(score - max_value) <= 0.01:\n",
        "                best_label_candidates.append(lbl)\n",
        "\n",
        "        best_label = random.choice(best_label_candidates)\n",
        "        y_pred[node] = best_label\n",
        "        class_instances[best_label].add(node)  # Track newly labeled nodes\n",
        "\n",
        "        # ✅ Update Labeled Neighbor Score for Unlabeled Neighbors\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "          if y_pred[neighbor] == -1:\n",
        "              old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "\n",
        "              if old_entry:\n",
        "                  ordered_set.discard(old_entry)\n",
        "\n",
        "              num_labeled_by_train = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n in train_labeled_nodes)\n",
        "              num_labeled_by_propagation = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n not in train_labeled_nodes)\n",
        "              total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "              # Compute feature similarity score\n",
        "              similarity_score = feature_similarity(neighbor, class_instances, data)\n",
        "\n",
        "              # Compute new weighted score with feature similarity factor\n",
        "              new_weighted_score = ((a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0) + a6 * similarity_score\n",
        "\n",
        "              ordered_set.add((-new_weighted_score, neighbor))\n",
        "\n",
        "\n",
        "    # ✅ Convert to PyTorch Tensor for Neural Network\n",
        "    y_pred_test = torch.tensor(y_pred[test_indices], dtype=torch.float)\n",
        "\n",
        "    # ✅ Compute Initial Classification Accuracy\n",
        "    y_true = data.y[test_indices]\n",
        "    valid_idx = [i for i in range(len(y_pred_test)) if y_pred_test[i] != -1]\n",
        "    if valid_idx:\n",
        "        initial_accuracy = accuracy_score(y_true[valid_idx], y_pred_test[valid_idx])\n",
        "    else:\n",
        "        initial_accuracy = 0.0  # No valid predictions\n",
        "\n",
        "    return y_pred_test, initial_accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "Ru9be0GZSBHA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "\n",
        "# Count occurrences of each class label\n",
        "class_counts = torch.bincount(data.y)\n",
        "\n",
        "# Print the number of elements in each class\n",
        "for class_id, count in enumerate(class_counts):\n",
        "    print(f\"Class {class_id}: {count} elements\")\n",
        "a1=0.5\n",
        "a2=-6\n",
        "a3=-2\n",
        "a4=1\n",
        "a5=3\n",
        "a6=1\n",
        "\n",
        "indices = np.arange(data.num_nodes)  # NumPy array of indices [0, 1, 2, ..., num_nodes-1]\n",
        "np.random.shuffle(indices)\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.6)\n",
        "\n",
        "# Further split train_idx into train and validation sets (e.g., 20% of train goes to validation)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.5)\n",
        "test_indices=test_idx\n",
        "\n"
      ],
      "metadata": {
        "id": "qqUQNrZolOwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0ea979-0351-44f7-8d15-81f13846bc1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 33 elements\n",
            "Class 1: 1 elements\n",
            "Class 2: 18 elements\n",
            "Class 3: 101 elements\n",
            "Class 4: 30 elements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u88m8qZfUdX-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsMOjg0RUedb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88eDCyKNUf57"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import minimize\n",
        "import warnings\n",
        "warnings.simplefilter(\"error\", RuntimeWarning)  # Convert warnings to errors\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def feature_similarity(node, class_instances, data):\n",
        "    \"\"\"\n",
        "    Compute feature similarity between a node and instances of each label.\n",
        "\n",
        "    Arguments:\n",
        "    - node: The node whose similarity is being computed.\n",
        "    - class_instances: A dictionary where keys are labels and values are sets of labeled node indices.\n",
        "    - data: Graph data object containing node features (data.x).\n",
        "\n",
        "    Returns:\n",
        "    - Maximum cosine similarity score between the node and labeled instances.\n",
        "    \"\"\"\n",
        "    if not class_instances:\n",
        "        return 0.0\n",
        "\n",
        "    node_feature = data.x[node].unsqueeze(0)  # Extract node feature\n",
        "    similarities = []\n",
        "\n",
        "    for lbl, instances in class_instances.items():\n",
        "        if not instances:  # Skip if no instances exist for this label\n",
        "            continue\n",
        "        instance_features = data.x[list(instances)]\n",
        "        sim = F.cosine_similarity(instance_features, node_feature).mean().item()\n",
        "        similarities.append(sim)\n",
        "\n",
        "    return max(similarities) if similarities else 0.0\n",
        "\n",
        "\n",
        "\n",
        "# Function to optimize (negate accuracy since we minimize)\n",
        "# Function to optimize (maximize train accuracy by minimizing negative accuracy)\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def random_search(model, data, num_samples=150, num_splits=5):\n",
        "    \"\"\"\n",
        "    Perform random search for hyperparameter tuning while evaluating each set\n",
        "    of hyperparameters across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function to predict classes.\n",
        "        data: Dataset object.\n",
        "        num_samples: Number of random search samples (default: 120).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best hyperparameters found based on average accuracy.\n",
        "        best_score: The highest average accuracy obtained.\n",
        "    \"\"\"\n",
        "    best_params = None\n",
        "    best_score = float('-inf')\n",
        "    indices = np.arange(data.num_nodes)\n",
        "    maxi=20\n",
        "    for _ in range(num_samples):\n",
        "        # Generate random hyperparameters\n",
        "        a1 = random.uniform(0, maxi)     # a1 must be positive\n",
        "        a2 = random.uniform(-maxi, -0.01)  # a2 must be negative\n",
        "        a3 = random.uniform(-maxi, -0.01)  # a3 must be negative\n",
        "        a5 = random.uniform(0, maxi)     # a5 must be positive\n",
        "        a4 = random.uniform(0, a5)    # a4 must be positive and a4 <= a5\n",
        "        a6 = random.uniform(0, maxi)\n",
        "        params = [a1, a2, a3, a4, a5, a6]\n",
        "\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, *params)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "\n",
        "        if avg_score > best_score:\n",
        "            best_score = avg_score\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initial guesses for a1, a2, a3, a4, a5\n",
        "#initial_params = [0.5,-5,-2,1,3]\n",
        "\n",
        "# Bounds for parameters\n",
        " # Adjust bounds as needed\n",
        "\n",
        "# Optimize using scipy\n",
        "result,best_val = random_search(predictclass,data,num_samples=20,num_splits=5)\n",
        "#print(result)\n",
        "# Get best parameters\n",
        "best_a1, best_a2, best_a3, best_a4, best_a5, best_a6 = result[0],result[1],result[2],result[3],result[4],result[5]\n",
        "\n",
        "# Evaluate on test set\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(\"best validation by random search:\", best_val)\n"
      ],
      "metadata": {
        "id": "xWZxuxXlygBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48245021-5498-42af-d146-83981aa91cb4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best validation by random search: 0.5743243243243243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from skopt.space import Real\n",
        "from skopt import gp_minimize\n",
        "def bayesian_optimization(model, data, num_calls=40, num_splits=5, initial_params=None):\n",
        "    \"\"\"\n",
        "    Bayesian Optimization to find best hyperparameters (a1, a2, a3, a4, a5, a6)\n",
        "    that maximize the validation accuracy while evaluating across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function that takes (data, train_idx, val_idx, a1, a2, a3, a4, a5, a6) and returns (loss, accuracy)\n",
        "        data: Dataset object.\n",
        "        num_calls: Number of function evaluations (default: 30).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "        initial_params: Optional initial solution from random search.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best found values for [a1, a2, a3, a4, a5, a6].\n",
        "        best_accuracy: The best validation accuracy found.\n",
        "    \"\"\"\n",
        "    search_space = [\n",
        "        Real(0, 20, name=\"a1\"),        # a1 must be positive\n",
        "        Real(-20, -0.01, name=\"a2\"),   # a2 must be negative\n",
        "        Real(-20, -0.01, name=\"a3\"),   # a3 must be negative\n",
        "        Real(0, 20, name=\"a4\"),        # a4 must be positive and a4 ≤ a5\n",
        "        Real(0, 20, name=\"a5\"),        # a5 must be positive\n",
        "        Real(0, 20, name=\"a6\")         # a6 must be positive\n",
        "    ]\n",
        "\n",
        "    indices = np.arange(data.num_nodes)\n",
        "\n",
        "    def objective(params):\n",
        "        a1, a2, a3, a4, a5, a6 = params\n",
        "        a4, a5 = min(a4, a5), max(a4, a5)  # Ensure a4 ≤ a5\n",
        "\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, a1, a2, a3, a4, a5, a6)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "        return -avg_score  # Since `gp_minimize` minimizes the function, we negate accuracy\n",
        "\n",
        "    if initial_params is not None:\n",
        "        print(\"initial_params=\",initial_params)\n",
        "        initial_params[3], initial_params[4] = min(initial_params[3], initial_params[4]), max(initial_params[3], initial_params[4])\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, x0=[initial_params], random_state=None)\n",
        "    else:\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, random_state=None)\n",
        "\n",
        "    best_a1, best_a2, best_a3, best_a4, best_a5, best_a6 = result.x\n",
        "    best_a4, best_a5 = min(best_a4, best_a5), max(best_a4, best_a5)  # Ensure a4 ≤ a5\n",
        "    best_accuracy = -result.fun\n",
        "\n",
        "    best_params = [best_a1, best_a2, best_a3, best_a4, best_a5, best_a6]\n",
        "\n",
        "    return best_params, best_accuracy\n",
        "\n",
        "# Example Usage:\n",
        "best_params, best_validation_score = bayesian_optimization(predictclass, data, num_calls=30, initial_params=result)\n",
        "\n",
        "print(\"best_validation by Bayesian=\",best_validation_score)\n",
        "if best_validation_score<best_val:\n",
        "  print(\"Bayesian made the parameters worse\")\n",
        "  best_params=result\n",
        "else:\n",
        "  best_a1, best_a2, best_a3, best_a4, best_a5,best_a6 = best_params\n",
        "print(\"best params found =\", best_params)\n",
        "\n",
        "# # # # Step 2: Test the Model Using the Best Parameters\n",
        "y_pred_test, final_test_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6)\n",
        "\n",
        "y_pred_val, final_val_accuracy = predictclass(data, train_idx, val_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6)\n",
        "\n",
        "# # # Step 3: Print the Final Accuracy on the Test Set\n",
        "print(\"\\n🎯 Final Val Set Accuracy:\", final_val_accuracy)\n",
        "\n",
        "\n",
        "print(len(y_pred_test),len(test_idx))\n",
        "\n",
        "print(\"\\n🎯 Final Test Set Accuracy:\", final_test_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqOUOkBf6ACE",
        "outputId": "422a8fc8-2a9e-400d-c6e9-0422bbf52975"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial_params= [14.87125132040347, -19.816932412884384, -2.6466517745544564, 7.596841570937167, 9.352242828135932, 15.060442745593177]\n",
            "best_validation by Bayesian= 0.6722222222222222\n",
            "best params found = [19.48553031998133, -20.0, -0.010000000000001563, 0.0, 7.431792344981696, 0.0]\n",
            "\n",
            "🎯 Final Val Set Accuracy: 0.7297297297297297\n",
            "110 110\n",
            "\n",
            "🎯 Final Test Set Accuracy: 0.5727272727272728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "FH9DxCcGSpLc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.nn import Linear, Sequential, ReLU, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class HighPassConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, amp=0.5, **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(**kwargs)\n",
        "        self.amp = amp\n",
        "        self.lin = Linear(in_channels, out_channels)\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.lin(x)\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "        out = self.amp * x - out\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "class Augmenter(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, amp=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = HighPassConv(in_dim, hidden_dim, amp=amp)\n",
        "        self.conv2 = HighPassConv(hidden_dim, hidden_dim, amp=amp)\n",
        "        self.mlp_edge_model = Sequential(\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim, hidden_dim * 2),\n",
        "            ReLU(),\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        src, dst = edge_index[0], edge_index[1]\n",
        "        edge_emb = x[src] + x[dst]\n",
        "        return torch.sigmoid(self.mlp_edge_model(edge_emb))\n",
        "\n",
        "class HeterophilicNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds=None):\n",
        "        super().__init__()\n",
        "        self.augmenter = Augmenter(in_dim, hidden_dim)\n",
        "        self.gnn_high = HighPassConv(in_dim, hidden_dim)\n",
        "        self.offset_mlp = Sequential(\n",
        "            Linear(in_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.final_mlp = Sequential(\n",
        "            Linear(hidden_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self.test_indices = test_indices  # Store test indices\n",
        "\n",
        "        # Store initial predictions but only for test indices (not trained)\n",
        "        if initial_preds is not None:\n",
        "            self.initial_preds = F.one_hot(initial_preds.long(), num_classes=num_classes).float()\n",
        "        else:\n",
        "            self.initial_preds = None\n",
        "\n",
        "    def forward(self, x, edge_index, train_indices):\n",
        "        edge_weights = self.augmenter(x, edge_index)\n",
        "        h = self.gnn_high(x, edge_index, edge_weights)\n",
        "        offset = self.offset_mlp(x)\n",
        "        logits = self.final_mlp(h + offset)\n",
        "\n",
        "        # If initial_preds exists, add it **only for test nodes**\n",
        "        if self.initial_preds is not None:\n",
        "            logits[self.test_indices] = logits[self.test_indices] + self.initial_preds\n",
        "\n",
        "        return F.log_softmax(logits, dim=1)\n",
        "\n",
        "# Training and Evaluation Code\n",
        "def train_and_evaluate(model, data, train_indices, test_indices, initial_preds, epochs=2000, lr=0.01):\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        loss = criterion(logits[train_indices], data.y[train_indices])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        predicted_classes = torch.argmax(logits, dim=1)\n",
        "        test_predictions = predicted_classes[test_indices]\n",
        "        final_accuracy = accuracy_score(data.y[test_indices].cpu().numpy(), test_predictions.cpu().numpy())\n",
        "\n",
        "    return final_accuracy, test_predictions\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c_sXm_FtUhXF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute initial test predictions\n",
        "initial_preds, initial_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5)\n",
        "\n",
        "# Ensure `initial_preds` is a tensor and on the correct device\n",
        "initial_preds = initial_preds.clone().detach()  # Ensures a proper detached copy\n",
        "\n",
        "\n",
        "print(f\"📊 Initial Classification Accuracy: {initial_accuracy:.4f}\")\n",
        "\n",
        "# Create the model\n",
        "model = HeterophilicNodeClassifier(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=len(set(data.y.tolist())),test_indices=test_indices, initial_preds=initial_preds\n",
        ").to(data.x.device)  # Ensure model is on the correct device\n",
        "\n",
        "# 🔄 Train the model before inference\n",
        "final_accuracy_before_djgnn, test_predictions_before_djgnn = train_and_evaluate(\n",
        "    model, data, train_idx, test_idx, initial_preds, epochs=100, lr=0.01\n",
        ")\n",
        "\n",
        "print(len(test_predictions_before_djgnn),len(test_idx))\n",
        "\n",
        "# ✅ Model evaluation after training\n",
        "model.eval()\n",
        "#with torch.no_grad():\n",
        " #   logits = model(data.x, data.edge_index, train_idx, test_idx, initial_test_preds=initial_preds)\n",
        " #   predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "\n",
        "print(f\"🎯  Classification Accuracy after running kdd2023: {final_accuracy_before_djgnn:.4f}\")\n",
        "#print(test_predictions)\n",
        "#print(len(initial_preds))\n",
        "#print(len(test_predictions))\n",
        "\n",
        "#print(len(val_idx))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "TtC0NBH7UhKO",
        "outputId": "2777e679-1177-4e66-b901-54c81f09175d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "predictclass() missing 1 required positional argument: 'a6'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e53f24507d00>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute initial test predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minitial_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_a5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Ensure `initial_preds` is a tensor and on the correct device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minitial_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensures a proper detached copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predictclass() missing 1 required positional argument: 'a6'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class DJGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds, n_jumps=5, dropout=0.5):\n",
        "        super(DJGNN, self).__init__()\n",
        "        self.n_jumps = n_jumps\n",
        "        self.dropout = dropout\n",
        "        self.att = nn.Parameter(torch.ones(n_jumps + 1))  # Attention weights for jumps\n",
        "        self.sm = nn.Softmax(dim=0)\n",
        "\n",
        "        # Store initial predictions (converted to one-hot)\n",
        "        self.test_indices = test_indices\n",
        "        self.initial_preds = nn.Parameter(F.one_hot(initial_preds, num_classes).float(), requires_grad=False)\n",
        "\n",
        "        # GCN layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(n_jumps):\n",
        "            self.convs.append(GCNConv(in_dim, hidden_dim))\n",
        "\n",
        "        # Extra convolution layers\n",
        "        self.conv_extra = GCNConv(in_dim, hidden_dim)\n",
        "        self.bn_extra = nn.BatchNorm1d(hidden_dim)\n",
        "        self.conv_extra2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.bn_extra_2 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        # Final classifier\n",
        "        self.classify = nn.Linear(hidden_dim * (n_jumps + 1) + num_classes, num_classes)  # Extra input for initial preds\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "      mask_attentions = self.sm(self.att)\n",
        "\n",
        "      # Extra convolutions\n",
        "      extra_conv = self.conv_extra(x, edge_index).relu()\n",
        "      print(f\"extra_conv after conv_extra: {extra_conv.shape}\")\n",
        "      extra_conv = self.bn_extra(extra_conv)\n",
        "      print(f\"extra_conv after bn_extra: {extra_conv.shape}\")\n",
        "      extra_conv = F.dropout(extra_conv, p=self.dropout, training=self.training)\n",
        "      extra_conv = self.conv_extra2(extra_conv, edge_index).relu()\n",
        "      extra_conv = self.bn_extra_2(extra_conv)\n",
        "      extra_conv = extra_conv * mask_attentions[-1]\n",
        "      print(f\"extra_conv after conv_extra2 & mask: {extra_conv.shape}\")\n",
        "\n",
        "      # Jumping knowledge mechanism: collect outputs from each conv layer\n",
        "      z_s = []\n",
        "      for i, conv in enumerate(self.convs):\n",
        "          z = conv(x, edge_index).relu() * mask_attentions[i]\n",
        "          print(f\"z from conv {i}: {z.shape}\")\n",
        "          z_s.append(z)\n",
        "\n",
        "      # Concatenate all jump outputs with extra_conv\n",
        "      final_z = torch.cat(z_s + [extra_conv], dim=1)\n",
        "      print(f\"✅ final_z shape BEFORE concatenation: {final_z.shape}\")  # Expect [num_nodes, feature_dim]\n",
        "\n",
        "      # Debug: Print test indices shape and the slice from final_z\n",
        "      print(f\"✅ self.test_indices shape: {self.test_indices.shape}\")  # Expect [num_test_samples]\n",
        "      test_slice = final_z[self.test_indices]\n",
        "      print(f\"✅ final_z[self.test_indices] shape: {test_slice.shape}\")  # Expect [num_test_samples, feature_dim]\n",
        "\n",
        "      # Ensure self.initial_preds is a LongTensor\n",
        "      num_classes = self.classify.out_features  # Get number of classes\n",
        "      initial_preds_long = self.initial_preds.long().squeeze()\n",
        "      print(f\"initial_preds_long shape after squeeze: {initial_preds_long.shape}\")\n",
        "\n",
        "      # Clamp indices to valid range\n",
        "      initial_preds_long = torch.clamp(initial_preds_long, min=0, max=num_classes - 1)\n",
        "\n",
        "      # Convert to one-hot encoding\n",
        "      one_hot_preds = F.one_hot(initial_preds_long, num_classes=num_classes).float()\n",
        "      print(f\"✅ one_hot_preds shape immediately after one_hot: {one_hot_preds.shape}\")\n",
        "\n",
        "      # If one_hot_preds still has an extra dimension, print its dimensions explicitly\n",
        "      for idx, dim in enumerate(one_hot_preds.shape):\n",
        "          print(f\"one_hot_preds dim {idx}: {dim}\")\n",
        "\n",
        "      # Attempt to remove extra dimensions by squeezing only the dims of size 1\n",
        "      one_hot_preds = one_hot_preds.squeeze()\n",
        "      print(f\"✅ one_hot_preds shape after squeeze(): {one_hot_preds.shape}\")\n",
        "\n",
        "      # Check dimensions explicitly\n",
        "      if one_hot_preds.ndim != 2:\n",
        "          print(f\"❌ one_hot_preds still has {one_hot_preds.ndim} dimensions; expected 2 dimensions!\")\n",
        "\n",
        "      # Now, try concatenation and catch errors with more prints\n",
        "      try:\n",
        "          final_z[self.test_indices] = torch.cat((final_z[self.test_indices], one_hot_preds), dim=1)\n",
        "      except RuntimeError as e:\n",
        "          print(f\"❌ ERROR: Shape mismatch at concatenation!\")\n",
        "          print(f\"🔍 final_z[self.test_indices] shape: {final_z[self.test_indices].shape}\")\n",
        "          print(f\"🔍 one_hot_preds shape: {one_hot_preds.shape}\")\n",
        "          raise e  # Re-raise after printing shapes\n",
        "\n",
        "      # Dropout and classification\n",
        "      final_z = F.dropout(final_z, p=self.dropout, training=self.training)\n",
        "      logits = self.classify(final_z).log_softmax(dim=-1)\n",
        "      return logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nZSz76h8VGIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_djgnn(model, data, train_idx, test_idx, initial_preds_djgnn, epochs=100, lr=0.01):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(data.x, data.edge_index)\n",
        "        loss_supervised = criterion(logits[train_idx], data.y[train_idx])\n",
        "\n",
        "        # 🔥 NEW: Consistency Loss to prevent drastic changes\n",
        "        confidence_threshold = 0.85  # Change only high-confidence nodes\n",
        "        high_confidence_mask = logits[test_idx].softmax(dim=1).max(dim=1).values > confidence_threshold\n",
        "\n",
        "        # Apply consistency loss only to confident predictions\n",
        "        filtered_loss = F.cross_entropy(logits[test_idx][high_confidence_mask], initial_preds_djgnn[high_confidence_mask])\n",
        "        loss = loss_supervised + 0.1 * filtered_loss\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy on test set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_logits = model(data.x, data.edge_index)\n",
        "            test_preds = test_logits[test_idx].argmax(dim=1)\n",
        "            test_correct = (test_preds == data.y[test_idx]).sum().item()\n",
        "            test_acc = test_correct / len(test_idx)\n",
        "\n",
        "    #    print(f\"🧐 Epoch {epoch+1:02d} | Loss: {loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "       # if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "       #     print(f\"🔍 Logits Before Argmax (First 5 Samples):\\n{test_logits[test_idx][:5]}\")\n",
        "\n",
        "    return test_preds, test_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "cldUM1jPk72E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Ensure `initial_preds_djgnn` is a tensor and detached\n",
        "initial_preds_djgnn = test_predictions_before_djgnn.clone().detach().long()  # Explicitly convert to LongTensor\n",
        "initial_preds = initial_preds.clone().detach().long()\n",
        "\n",
        "# Get the number of unique classes from `data.y`\n",
        "num_classes = data.y.max().item() + 1  # `max() + 1` ensures it captures all labels\n",
        "\n",
        "print(f\"📊 Number of Test Samples: {len(initial_preds_djgnn)}\")\n",
        "print(f\"🔢 Number of Unique Classes: {num_classes}\")\n",
        "\n",
        "# 🚀 Initialize DJ-GNN model with test indices & initial predictions\n",
        "djgnn_model = DJGNN(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=num_classes,  # Use the correct `num_classes`\n",
        "    test_indices=torch.tensor(test_idx, dtype=torch.long, device=data.x.device),  # Ensure `test_idx` is a tensor\n",
        "    initial_preds=initial_preds_djgnn,  # Pass initial predictions (already `LongTensor`)\n",
        "    n_jumps=5,  # Use 5 hops for diffusion\n",
        "    dropout=0.5\n",
        ").to(data.x.device)  # Ensure it's on the correct device\n",
        "\n",
        "# 🚀 Train DJ-GNN and get new predictions\n",
        "new_preds, final_accuracy_after_djgnn = train_djgnn(\n",
        "    djgnn_model, data, train_idx, test_idx, initial_preds_djgnn, epochs=500, lr=0.01\n",
        ")\n",
        "\n",
        "# 🎯 Compare accuracies before & after DJ-GNN\n",
        "print(\"\\n🔥 Final Results:\")\n",
        "print(f\"🎯 Accuracy BEFORE DJ-GNN: {final_accuracy_before_djgnn:.4f}\")\n",
        "print(f\"🚀 Accuracy AFTER DJ-GNN: {final_accuracy_after_djgnn:.4f}\")\n",
        "\n",
        "# 🔍 Sample Predictions Before & After DJ-GNN (Print first 10 for debugging)\n",
        "print(\"\\n🔍 Sample Predictions Before & After DJ-GNN:\")\n",
        "for i in range(min(10, len(test_idx))):  # Ensure we don't go out of bounds\n",
        "    print(f\"🧐 Sample {i+1} | Before: {initial_preds_djgnn[i].item()} | After: {new_preds[i].item()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "p936LZ0GlGf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}