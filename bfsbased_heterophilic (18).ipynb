{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqGs0nK9M8Kq",
        "outputId": "6886709a-1ea7-4271-946d-925a71f84372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.11/dist-packages (12.0.1)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gurobipy\n",
        "!pip install torch_geometric\n",
        "!pip install sortedcontainers\n",
        "\n",
        "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "!pip install scikit-optimize\n",
        "\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import pairwise_distances as sklearn_pairwise_distances\n",
        "import networkx as nx\n",
        " # Use \"cosine\" for cosine similarity\n",
        "import heapq\n",
        "\n",
        "\n",
        "os.environ[\"GRB_LICENSE_FILE\"] = \"gurobi (3).lic\"\n",
        "os.environ[\"GRB_WLSACCESSID\"] = \"f218200d-1f8d-4342-83f5-b7b2d9263751\"  # Replace with your actual WLSACCESSID\n",
        "os.environ[\"GRB_WLSSECRET\"] = \"528d596b-babc-4a1e-bda2-693c44f4f006\"  # Replace with your actual WLSSECRET\n",
        "os.environ[\"GRB_LICENSEID\"] = \"840285\"  # Replace with your actual LICENSEID\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from torch_geometric.datasets import WebKB, WikipediaNetwork, Actor\n",
        "\n",
        "from torch_geometric.datasets import FacebookPagePage\n",
        "\n",
        "from torch_geometric.datasets import SNAPDataset\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import networkx as nx\n",
        "from torch_geometric.datasets import WebKB\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sortedcontainers import SortedSet  # Ordered set\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "from torch_geometric.datasets import WikipediaNetwork\n",
        "from torch_geometric.datasets import Actor\n",
        "\n",
        "# Load the Film dataset (also known as Actor dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD28jxmhNmm5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZChMrfbyNoOn",
        "outputId": "db316a4c-538d-4a9e-a208-1893a1070df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/cornell/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/cornell/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_9.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Loaded  dataset with 183 nodes, 557 edges\n",
            "   - Features: 1703\n",
            "   - Number of Classes: 5\n",
            "   - Number of Components: 1\n",
            "3 -24.487818012392616\n",
            "0 -20.191604040502533\n",
            "4 -17.304636916493983\n",
            "1 -22.35129446324294\n",
            "2 -24.214443625473393\n",
            "\n",
            "🔹 Labelling Node 2 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.21600748077641\n",
            "0 -26.30684413754843\n",
            "4 -19.48409744200668\n",
            "1 -22.8873319083113\n",
            "2 -24.95406574156226\n",
            "\n",
            "🔹 Labelling Node 13 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.33685709015141\n",
            "0 -26.846091650365814\n",
            "4 -17.99798675475082\n",
            "1 -22.152377074326925\n",
            "2 -24.10720867063941\n",
            "\n",
            "🔹 Labelling Node 15 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -33.15874124542484\n",
            "0 -39.92595043027304\n",
            "4 -32.918177565908046\n",
            "1 -33.18919462498611\n",
            "2 -32.952135504745854\n",
            "\n",
            "🔹 Labelling Node 32 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.58632875458012\n",
            "0 -25.077756307958587\n",
            "4 -17.463606795644374\n",
            "1 -20.72562879857009\n",
            "2 -22.47111362364234\n",
            "\n",
            "🔹 Labelling Node 40 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.329660663759807\n",
            "0 -25.107036016820892\n",
            "4 -17.357283553456874\n",
            "1 -20.27523130711501\n",
            "2 -22.499540747665776\n",
            "\n",
            "🔹 Labelling Node 45 \n",
            "   -> Predicted Label: 3 | True Label: 1 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.23010087982426\n",
            "0 -33.19915714108847\n",
            "4 -27.907692870473475\n",
            "1 -29.689745848740987\n",
            "2 -30.68602031614722\n",
            "\n",
            "🔹 Labelling Node 51 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.64200807586918\n",
            "0 -26.826640509008392\n",
            "4 -19.22776313719711\n",
            "1 -21.735997145738057\n",
            "2 -22.76699298765601\n",
            "\n",
            "🔹 Labelling Node 60 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.832758197939494\n",
            "0 -22.7051462157955\n",
            "4 -19.115302047109218\n",
            "1 -21.68497938450759\n",
            "2 -23.82861751463355\n",
            "\n",
            "🔹 Labelling Node 77 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -33.18840051666508\n",
            "0 -38.725236318944916\n",
            "4 -33.84372611937484\n",
            "1 -34.83129972752517\n",
            "2 -35.46560138609351\n",
            "\n",
            "🔹 Labelling Node 81 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -28.35808588043461\n",
            "0 -32.07482662045859\n",
            "4 -29.101321181630702\n",
            "1 -33.539751952256616\n",
            "2 -31.27591747190894\n",
            "\n",
            "🔹 Labelling Node 84 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.026375065004924\n",
            "0 -28.956471823095306\n",
            "4 -23.47783180174789\n",
            "1 -25.576119368638448\n",
            "2 -27.422634543442143\n",
            "\n",
            "🔹 Labelling Node 89 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -19.02479196563969\n",
            "0 -20.562806509374603\n",
            "4 -19.05313583311996\n",
            "1 -22.483765547837667\n",
            "2 -30.354420126938237\n",
            "\n",
            "🔹 Labelling Node 91 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -33.49925447479496\n",
            "0 -34.49084987485312\n",
            "4 -30.249876937245936\n",
            "1 -30.40547270115798\n",
            "2 -30.611843527817143\n",
            "\n",
            "🔹 Labelling Node 105 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.722175846254924\n",
            "0 -29.822558782934173\n",
            "4 -23.099022826528163\n",
            "1 -24.653149550523214\n",
            "2 -26.645725668930424\n",
            "\n",
            "🔹 Labelling Node 106 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.717878589785197\n",
            "0 -33.36295642697714\n",
            "4 -26.447501143788905\n",
            "1 -26.805548613633565\n",
            "2 -28.661615790390385\n",
            "\n",
            "🔹 Labelling Node 123 \n",
            "   -> Predicted Label: 3 | True Label: 1 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.832226047670936\n",
            "0 -19.514954946874603\n",
            "4 -19.380272826528163\n",
            "1 -22.1480683737654\n",
            "2 -23.936912955307378\n",
            "\n",
            "🔹 Labelling Node 134 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.011591205751994\n",
            "0 -21.27868594968222\n",
            "4 -21.41131683287582\n",
            "1 -24.015738432969503\n",
            "2 -31.493381918930424\n",
            "\n",
            "🔹 Labelling Node 143 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 2: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.27351022735844\n",
            "0 -24.68275203549765\n",
            "4 -17.440768203115077\n",
            "1 -20.209385817613057\n",
            "2 -22.416429938339604\n",
            "\n",
            "🔹 Labelling Node 157 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -26.800720462954143\n",
            "0 -28.190703771947845\n",
            "4 -30.163462600087733\n",
            "1 -30.983059828843526\n",
            "2 -29.01729053404273\n",
            "\n",
            "🔹 Labelling Node 159 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.089853534853557\n",
            "0 -20.39039363706015\n",
            "4 -17.002968749379725\n",
            "1 -19.554108565415792\n",
            "2 -21.998659552597417\n",
            "\n",
            "🔹 Labelling Node 168 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.94452310577641\n",
            "0 -29.454505346654877\n",
            "4 -22.296893081044765\n",
            "1 -23.632790511216573\n",
            "2 -24.789478720688237\n",
            "\n",
            "🔹 Labelling Node 181 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -30.684932956850627\n",
            "0 -37.82001247250937\n",
            "4 -31.16941543517074\n",
            "1 -31.7386502676863\n",
            "2 -32.55084842588843\n",
            "\n",
            "🔹 Labelling Node 182 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.752174625551795\n",
            "0 -17.89108600461386\n",
            "4 -17.17287345824203\n",
            "1 -20.429638808335714\n",
            "2 -22.435425223373784\n",
            "\n",
            "🔹 Labelling Node 171 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 5 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.07901216522465\n",
            "0 -31.732711218236908\n",
            "4 -24.46768661436996\n",
            "1 -26.278695052232198\n",
            "2 -27.818096579574956\n",
            "\n",
            "🔹 Labelling Node 30 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 4 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.50376535431156\n",
            "0 -21.13268222653769\n",
            "4 -21.361382445668788\n",
            "1 -24.210259383286886\n",
            "2 -25.84292072203101\n",
            "\n",
            "🔹 Labelling Node 138 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 4 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.21111131683598\n",
            "0 -25.710688970922455\n",
            "4 -20.285256347035975\n",
            "1 -22.14776129063552\n",
            "2 -24.106081427597417\n",
            "\n",
            "🔹 Labelling Node 53 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 0: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -31.80611635223637\n",
            "0 -29.344350241064056\n",
            "4 -27.94102760252914\n",
            "1 -29.543524687852315\n",
            "2 -30.324802817367924\n",
            "\n",
            "🔹 Labelling Node 104 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -25.00054002777348\n",
            "0 -29.092187307714447\n",
            "4 -23.935078582143397\n",
            "1 -25.541632598008565\n",
            "2 -27.067919196152104\n",
            "\n",
            "🔹 Labelling Node 148 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.745397815859416\n",
            "0 -25.24061336362265\n",
            "4 -24.37103362975082\n",
            "1 -23.911124175157003\n",
            "2 -25.82583087828101\n",
            "\n",
            "🔹 Labelling Node 154 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.027927646792033\n",
            "0 -28.65142764890097\n",
            "4 -21.765698394155116\n",
            "1 -23.727023070420675\n",
            "2 -25.227383078598393\n",
            "\n",
            "🔹 Labelling Node 165 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 3 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -30.065344104921916\n",
            "0 -26.99107494199179\n",
            "4 -27.387516936635585\n",
            "1 -28.696694319810323\n",
            "2 -32.917231024765385\n",
            "\n",
            "🔹 Labelling Node 22 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 2: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.9309961892725\n",
            "0 -18.922295950292572\n",
            "4 -18.246506652211757\n",
            "1 -21.26936430272048\n",
            "2 -23.231792868637456\n",
            "\n",
            "🔹 Labelling Node 25 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 3: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.951830158388713\n",
            "0 -28.375666998266205\n",
            "4 -27.194403609609218\n",
            "1 -25.18622106846755\n",
            "2 -26.687447012924565\n",
            "\n",
            "🔹 Labelling Node 72 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.430395374453166\n",
            "0 -26.56270923459433\n",
            "4 -25.3115377038475\n",
            "1 -24.29744047459548\n",
            "2 -26.187202872299565\n",
            "\n",
            "🔹 Labelling Node 79 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -34.95137430206547\n",
            "0 -32.529401205419525\n",
            "4 -34.736706694936366\n",
            "1 -32.30843061741775\n",
            "2 -33.208708228134526\n",
            "\n",
            "🔹 Labelling Node 101 \n",
            "   -> Predicted Label: 1 | True Label: 4 ❌\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 4: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -28.6676962472559\n",
            "0 -29.582581899999603\n",
            "4 -29.682513198232265\n",
            "1 -30.270777648057393\n",
            "2 -29.119915427231206\n",
            "\n",
            "🔹 Labelling Node 8 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 1: 2 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.794748554384807\n",
            "0 -26.421397589086517\n",
            "4 -19.21538062987289\n",
            "1 -22.259112303819112\n",
            "2 -23.410841406845464\n",
            "\n",
            "🔹 Labelling Node 103 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -35.321462879335975\n",
            "0 -30.14685764157675\n",
            "4 -29.349364241933436\n",
            "1 -30.210528319444112\n",
            "2 -30.245106162094487\n",
            "\n",
            "🔹 Labelling Node 162 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 3: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -34.30226923004398\n",
            "0 -35.25079860532187\n",
            "4 -32.66989417967758\n",
            "1 -34.94665617283767\n",
            "2 -33.326498450302495\n",
            "\n",
            "🔹 Labelling Node 21 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.155897388613322\n",
            "0 -22.92139186704062\n",
            "4 -25.36186500487289\n",
            "1 -24.388506835069112\n",
            "2 -25.225979270004643\n",
            "\n",
            "🔹 Labelling Node 180 \n",
            "   -> Predicted Label: 0 | True Label: 3 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.030226001894572\n",
            "0 -23.324809454320892\n",
            "4 -21.88596626219711\n",
            "1 -26.474770491685323\n",
            "2 -24.874458731674565\n",
            "\n",
            "🔹 Labelling Node 176 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 1: 3 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.35875535980473\n",
            "0 -25.6944154723873\n",
            "4 -25.188401183461757\n",
            "1 -24.153395598496846\n",
            "2 -25.48140186216773\n",
            "\n",
            "🔹 Labelling Node 46 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -27.95984483734379\n",
            "0 -32.3107313140621\n",
            "4 -31.63722892699203\n",
            "1 -29.214943831529073\n",
            "2 -29.86093372251929\n",
            "\n",
            "🔹 Labelling Node 145 \n",
            "   -> Predicted Label: 3 | True Label: 2 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -29.100256214296916\n",
            "0 -27.78896655881308\n",
            "4 -29.589596709584804\n",
            "1 -30.802266066636495\n",
            "2 -29.880745352768315\n",
            "\n",
            "🔹 Labelling Node 6 \n",
            "   -> Predicted Label: 0 | True Label: 4 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 1: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.04454828277836\n",
            "0 -23.334012411474212\n",
            "4 -24.632361373281093\n",
            "1 -28.240740721787862\n",
            "2 -25.388578833603276\n",
            "\n",
            "🔹 Labelling Node 63 \n",
            "   -> Predicted Label: 3 | True Label: 4 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 1: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -29.897861728823283\n",
            "0 -32.48694934689902\n",
            "4 -30.894591292714686\n",
            "1 -30.83364195164626\n",
            "2 -31.473885001205815\n",
            "\n",
            "🔹 Labelling Node 158 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.732942829287147\n",
            "0 -19.00306453549765\n",
            "4 -19.50946136412582\n",
            "1 -22.28298849400466\n",
            "2 -23.47409862425269\n",
            "\n",
            "🔹 Labelling Node 62 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.589615116274455\n",
            "0 -21.588658712743744\n",
            "4 -21.581549605702968\n",
            "1 -22.700535719956807\n",
            "2 -24.058132590317143\n",
            "\n",
            "🔹 Labelling Node 149 \n",
            "   -> Predicted Label: 4 | True Label: 0 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.517181644594768\n",
            "0 -24.984572790502533\n",
            "4 -19.11370368895492\n",
            "1 -22.12075704869216\n",
            "2 -23.386095465683354\n",
            "\n",
            "🔹 Labelling Node 177 \n",
            "   -> Predicted Label: 3 | True Label: 0 ❌\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.26575113312016\n",
            "0 -24.446462057470306\n",
            "4 -19.704321822499843\n",
            "1 -22.156115477647237\n",
            "2 -23.25303501036109\n",
            "\n",
            "🔹 Labelling Node 118 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 0: 3 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -20.244228611147502\n",
            "0 -22.042977712987884\n",
            "4 -21.21767898497543\n",
            "1 -21.958653395738057\n",
            "2 -23.193468512558354\n",
            "\n",
            "🔹 Labelling Node 147 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -24.56356264129887\n",
            "0 -26.008647344945892\n",
            "4 -22.109978637075038\n",
            "1 -24.22350591954177\n",
            "2 -25.20447963621558\n",
            "\n",
            "🔹 Labelling Node 96 \n",
            "   -> Predicted Label: 4 | True Label: 2 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -39.235111484682655\n",
            "0 -33.57483043515585\n",
            "4 -33.381026229238124\n",
            "1 -33.69556898411697\n",
            "2 -34.2868141546482\n",
            "\n",
            "🔹 Labelling Node 19 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -32.22230554596195\n",
            "0 -27.22966136777304\n",
            "4 -26.735276183461757\n",
            "1 -27.58729643162673\n",
            "2 -28.090156973862065\n",
            "\n",
            "🔹 Labelling Node 54 \n",
            "   -> Predicted Label: 4 | True Label: 3 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -30.592552433168983\n",
            "0 -24.472487829565033\n",
            "4 -25.196177443837733\n",
            "1 -27.033560698594503\n",
            "2 -28.05288928892554\n",
            "\n",
            "🔹 Labelling Node 65 \n",
            "   -> Predicted Label: 0 | True Label: 0 ✅\n",
            "   - Class 3: 2 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.811390171206096\n",
            "0 -22.54678668820761\n",
            "4 -24.321803054189296\n",
            "1 -21.996302550401143\n",
            "2 -23.399118842148198\n",
            "\n",
            "🔹 Labelling Node 92 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.26652742401371\n",
            "0 -18.748834036230072\n",
            "4 -18.19123931822738\n",
            "1 -21.041722243394307\n",
            "2 -22.707683981918706\n",
            "\n",
            "🔹 Labelling Node 120 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.213876972353557\n",
            "0 -26.94862689816855\n",
            "4 -26.375826796865077\n",
            "1 -24.287062590684346\n",
            "2 -25.686781348251714\n",
            "\n",
            "🔹 Labelling Node 160 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -31.967056522524455\n",
            "0 -33.25291576230429\n",
            "4 -34.05638595519027\n",
            "1 -31.37246031102126\n",
            "2 -31.865663947128667\n",
            "\n",
            "🔹 Labelling Node 153 \n",
            "   -> Predicted Label: 1 | True Label: 2 ❌\n",
            "   - Class 4: 2 neighbors\n",
            "   - Class 0: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -23.908205280459025\n",
            "0 -22.61427821957968\n",
            "4 -24.883486708974452\n",
            "1 -23.79072660740798\n",
            "2 -24.693375052475346\n",
            "\n",
            "🔹 Labelling Node 121 \n",
            "   -> Predicted Label: 0 | True Label: 3 ❌\n",
            "   - Class 3: 1 neighbors\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -21.417253742373088\n",
            "0 -22.86911334836386\n",
            "4 -28.362790068959804\n",
            "1 -24.524102156724386\n",
            "2 -25.48843425657691\n",
            "\n",
            "🔹 Labelling Node 173 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -18.41609598175297\n",
            "0 -19.654107473730072\n",
            "4 -24.96471687254867\n",
            "1 -21.835463469590596\n",
            "2 -23.392450751327885\n",
            "\n",
            "🔹 Labelling Node 70 \n",
            "   -> Predicted Label: 3 | True Label: 1 ❌\n",
            "   - Class 4: 1 neighbors\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -22.696775684511756\n",
            "0 -18.29274501645468\n",
            "4 -17.481450042104335\n",
            "1 -20.887015288438253\n",
            "2 -22.027973593735112\n",
            "\n",
            "🔹 Labelling Node 151 \n",
            "   -> Predicted Label: 4 | True Label: 4 ✅\n",
            "   - Class 3: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3 -16.546070346987346\n",
            "0 -18.490786932348236\n",
            "4 -23.81872650084457\n",
            "1 -21.050455992783956\n",
            "2 -22.28146404173316\n",
            "\n",
            "🔹 Labelling Node 36 \n",
            "   -> Predicted Label: 3 | True Label: 3 ✅\n",
            "   - Class 4: 1 neighbors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "🎯 Label Propagation Accuracy: 0.3538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "#dataset = Actor(root='data/Film')\n",
        "data = dataset[0]\n",
        "data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "\n",
        "# ✅ Remove duplicate edges\n",
        "data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "# ✅ Convert to NetworkX Graph to Find Components\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "components = list(nx.connected_components(G))\n",
        "num_components = len(components)\n",
        "\n",
        "print(f\"\\n✅ Loaded  dataset with {data.num_nodes} nodes, {data.edge_index.shape[1]} edges\")\n",
        "print(f\"   - Features: {data.x.shape[1]}\")\n",
        "print(f\"   - Number of Classes: {len(set(data.y.numpy()))}\")\n",
        "print(f\"   - Number of Components: {num_components}\")\n",
        "\n",
        "# ✅ Set Training Percentage\n",
        "train_percentage = 0.65\n",
        "\n",
        "# ✅ Select Training Nodes\n",
        "train_indices = []\n",
        "for component in components:\n",
        "    component = list(component)\n",
        "    t = max(1, int(train_percentage * len(component)))\n",
        "    sampled_nodes = np.random.choice(component, t, replace=False)\n",
        "    train_indices.extend(sampled_nodes)\n",
        "\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "# ✅ Initialize Prediction Labels\n",
        "y_pred = np.full(data.num_nodes, -1)\n",
        "for idx in train_indices:\n",
        "    y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "# ✅ Compute Label Distribution\n",
        "total_label_counts = Counter(data.y.numpy())\n",
        "num_labels = len(set(data.y.numpy()))\n",
        "alpha = 1  # Laplace smoothing\n",
        "\n",
        "dataset_label_distribution = {\n",
        "    lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "    for lbl in total_label_counts.keys()\n",
        "}\n",
        "\n",
        "train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "train_label_distribution = {\n",
        "    lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "    for lbl in dataset_label_distribution.keys()\n",
        "}\n",
        "\n",
        "# ✅ Precompute Neighbors for Each Node\n",
        "A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "A = A.numpy()\n",
        "neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "# ✅ Track Instances Assigned to Each Label\n",
        "class_instances = defaultdict(set)\n",
        "for idx in train_indices:\n",
        "    class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "# ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "ordered_set = SortedSet()\n",
        "train_labeled_nodes = set(train_indices)\n",
        "\n",
        "for node in range(data.num_nodes):\n",
        "    if y_pred[node] == -1:  # Only process unlabeled nodes\n",
        "        labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "        num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "        total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "        if total_neighbors > 0:\n",
        "            weighted_score = (num_labeled_by_propagation + 3 * num_labeled_by_train) / total_neighbors\n",
        "        else:\n",
        "            weighted_score = 0\n",
        "\n",
        "        ordered_set.add((-weighted_score, node))\n",
        "\n",
        "# ✅ Iteratively Label the Most Constrained Nodes\n",
        "while ordered_set:\n",
        "    _, node = ordered_set.pop(0)\n",
        "\n",
        "    if y_pred[node] != -1:\n",
        "        continue\n",
        "\n",
        "    # Get labeled neighbors\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    # 🚨 If this node has 0 labeled neighbors\n",
        "    if not neighbor_labels:\n",
        "        print(f\"\\n🚨 STRANGE: Node {node} was chosen, but it has 0 labeled neighbors!\")\n",
        "        break\n",
        "\n",
        "    # Compute Neighbor Label Distribution\n",
        "    neighbor_label_counts = Counter(neighbor_labels)\n",
        "    total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "    if total_labeled_neighbors > 0:\n",
        "        neighbor_label_distribution = {\n",
        "            lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "        }\n",
        "    else:\n",
        "        neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # ✅ Compute Feature Distance to Each Class\n",
        "    # feature_diffs = {}\n",
        "    # for lbl in dataset_label_distribution.keys():\n",
        "    #   if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "    #       instance_features = data.x[list(class_instances[lbl])]\n",
        "    #       node_feature = data.x[node].unsqueeze(0)\n",
        "\n",
        "    #       # Compute distances for each instance\n",
        "    #       distances = torch.norm(instance_features - node_feature, dim=1).tolist()\n",
        "\n",
        "    #       # Apply weight based on whether the instance is from training or predicted labels\n",
        "    #       weighted_distances = [\n",
        "    #           (3 * dist) if instance in train_indices else dist  # Give 3x weight if in training set\n",
        "    #           for instance, dist in zip(class_instances[lbl], distances)\n",
        "    #       ]\n",
        "\n",
        "    #       # Compute weighted average distance\n",
        "    #       avg_distance = sum(weighted_distances) / len(weighted_distances)\n",
        "    #       feature_diffs[lbl] = avg_distance\n",
        "    #   else:\n",
        "    #       feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    feature_diffs = {}\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        if class_instances[lbl]:  # Only compute if we have instances of the label\n",
        "            instance_features = data.x[list(class_instances[lbl])]\n",
        "            node_feature = data.x[node].unsqueeze(0)\n",
        "           # print(len(instance_features),len(node_feature))\n",
        "            avg_distance = torch.mean(torch.norm(instance_features - node_feature, dim=1)).item()\n",
        "            feature_diffs[lbl] = avg_distance\n",
        "        else:\n",
        "            feature_diffs[lbl] = 0  # No penalty if no instances exist\n",
        "\n",
        "    # ✅ Select the Best Label Based on the Adjusted Score\n",
        "    best_label_candidates = []\n",
        "    max_value = float('-inf')\n",
        "    a1=0.5\n",
        "    a2=-6\n",
        "    a3=-2\n",
        "    a4=1\n",
        "    a5=3\n",
        "    for lbl in dataset_label_distribution.keys():\n",
        "        score = (\n",
        "            a1*train_label_distribution.get(lbl, 0)\n",
        "            +a2* neighbor_label_distribution.get(lbl, 0)\n",
        "            +a3*feature_diffs[lbl]  # Penalize by average feature distance\n",
        "        )\n",
        "        print(lbl,score,)\n",
        "\n",
        "        if score - max_value > 0.01:\n",
        "            best_label_candidates = [lbl]\n",
        "            max_value = score\n",
        "        elif abs(score - max_value) <= 0.01:\n",
        "            best_label_candidates.append(lbl)\n",
        "\n",
        "\n",
        "    best_label = random.choice(best_label_candidates)\n",
        "    y_pred[node] = best_label\n",
        "    class_instances[best_label].add(node)  # Track newly labeled nodes\n",
        "    neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "    label_counts = Counter(neighbor_labels)\n",
        "\n",
        "    print(f\"\\n🔹 Labelling Node {node} \")\n",
        "    # ✅ Print Prediction Outcome\n",
        "    true_label = data.y[node].item()\n",
        "    correct = \"✅\" if best_label == true_label else \"❌\"\n",
        "    print(f\"   -> Predicted Label: {best_label} | True Label: {true_label} {correct}\")\n",
        "\n",
        "   # print(f\"   - Total Neighbors: {len(neighbors_dict[node])}\")\n",
        "   # print(f\"   - Labeled Neighbors: {len(neighbor_labels)}\")\n",
        "    for lbl, count in label_counts.items():\n",
        "        print(f\"   - Class {lbl}: {count} neighbors\")\n",
        "        # ✅ Update Labeled Neighbor Score for Unlabeled Neighbors\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for n in neighbors_dict[neighbor] if y_pred[n] != -1 and n not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                new_weighted_score = (a4*num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "# ✅ Evaluate Accuracy\n",
        "test_indices = [i for i in range(data.num_nodes) if i not in train_indices]\n",
        "y_true = data.y[test_indices]\n",
        "y_pred_test = y_pred[test_indices]\n",
        "\n",
        "valid_idx = [i for i in range(len(y_pred_test)) if y_pred_test[i] != -1]\n",
        "if valid_idx:\n",
        "    final_accuracy = accuracy_score(y_true[valid_idx], y_pred_test[valid_idx])\n",
        "    print(f\"\\n🎯 Label Propagation Accuracy: {final_accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"\\n❌ No valid predictions were made!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Ru9be0GZSBHA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sortedcontainers import SortedSet\n",
        "from sklearn.metrics import accuracy_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def feature_similarity(node, class_nodes, data, train_indices, a7):\n",
        "    \"\"\"\n",
        "    Computes the similarity of a node to the average feature vector of a given class.\n",
        "\n",
        "    Parameters:\n",
        "    - node (int): The node for which similarity is being computed.\n",
        "    - class_nodes (dict): Dictionary with a single label as a key and a set of nodes in that class as values.\n",
        "    - data (torch_geometric.data.Data): Graph data containing features and labels.\n",
        "    - train_indices (list): Indices of training nodes.\n",
        "    - a7 (float): Weight coefficient for training instances.\n",
        "\n",
        "    Returns:\n",
        "    - similarity (float): A value between 0 and 1 indicating similarity.\n",
        "    \"\"\"\n",
        "    lbl, nodes = list(class_nodes.items())[0]  # Extract class label and its nodes\n",
        "    if not nodes:  # If no nodes in this class, return 0 similarity\n",
        "        return 0.0\n",
        "\n",
        "    instance_list = list(nodes)\n",
        "    instance_features = data.x[instance_list]\n",
        "\n",
        "    # Assign higher weight to training instances, lower to others\n",
        "    instance_weights = torch.tensor(\n",
        "        [(1 - a7) if inst in train_indices else a7 for inst in instance_list],\n",
        "        dtype=torch.float,\n",
        "        device=data.x.device\n",
        "    )\n",
        "\n",
        "    # Normalize weights to sum to 1\n",
        "    instance_weights /= instance_weights.sum()\n",
        "\n",
        "    # Compute weighted average feature vector\n",
        "    avg_feature = torch.sum(instance_features * instance_weights.view(-1, 1), dim=0, keepdim=True)\n",
        "\n",
        "    # Compute cosine similarity between node feature and the class's average feature\n",
        "    similarity = F.cosine_similarity(data.x[node].unsqueeze(0), avg_feature).item()\n",
        "\n",
        "    # Normalize to range [0,1]\n",
        "    similarity = (similarity + 1) / 2\n",
        "\n",
        "    return similarity\n",
        "\n",
        "\n",
        "def predictclass(data, train_indices, test_indices, a1, a2, a3, a4, a5, a6, a7):\n",
        "    data.edge_index = torch.cat([data.edge_index, data.edge_index.flip(0)], dim=1)\n",
        "    train_indices = list(train_indices)\n",
        "    test_indices = list(test_indices)\n",
        "\n",
        "    # ✅ Remove duplicate edges\n",
        "    data.edge_index = torch.unique(data.edge_index, dim=1)\n",
        "\n",
        "    # ✅ Initialize Prediction Labels\n",
        "    y_pred = np.full(data.num_nodes, -1, dtype=int)\n",
        "    for idx in train_indices:\n",
        "        y_pred[idx] = data.y[idx].item()\n",
        "\n",
        "    # ✅ Compute Label Distribution\n",
        "    total_label_counts = Counter(data.y.numpy())\n",
        "    num_labels = len(set(data.y.numpy()))\n",
        "    alpha = 1  # Laplace smoothing\n",
        "\n",
        "    dataset_label_distribution = {\n",
        "        lbl: (total_label_counts[lbl] + alpha) / (len(data.y) + alpha * num_labels)\n",
        "        for lbl in total_label_counts.keys()\n",
        "    }\n",
        "\n",
        "    train_label_counts = Counter(y_pred[train_indices])\n",
        "\n",
        "    train_label_distribution = {\n",
        "        lbl: (train_label_counts.get(lbl, 0) + alpha) / (len(train_indices) + alpha * num_labels)\n",
        "        for lbl in dataset_label_distribution.keys()\n",
        "    }\n",
        "\n",
        "    # ✅ Precompute Neighbors for Each Node\n",
        "    A = torch.zeros((data.num_nodes, data.num_nodes))\n",
        "    A[data.edge_index[0], data.edge_index[1]] = 1\n",
        "    neighbors_dict = {i: set(np.where(A[i] == 1)[0]) for i in range(data.num_nodes)}\n",
        "\n",
        "    # ✅ Track Instances Assigned to Each Label\n",
        "    class_instances = defaultdict(set)\n",
        "    for idx in train_indices:\n",
        "        class_instances[data.y[idx].item()].add(idx)\n",
        "\n",
        "    # ✅ Initialize D Table (Similarity Table)\n",
        "    D = {i: {lbl: 0.0 for lbl in dataset_label_distribution.keys()} for i in range(data.num_nodes)}\n",
        "    class_counts = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "    # ✅ Explicitly Initialize D Using Training Set\n",
        "    for i in range(data.num_nodes):\n",
        "      for lbl in dataset_label_distribution.keys():\n",
        "          if class_instances[lbl]:  # Compute similarity only if class has instances\n",
        "              D[i][lbl] = feature_similarity(i, {lbl: class_instances[lbl]}, data, train_indices, a7)\n",
        "              class_counts[lbl] = len(class_instances[lbl])  # Track number of nodes in class\n",
        "\n",
        "    # ✅ Ordered Set for Managing Unlabeled Vertices\n",
        "    ordered_set = SortedSet()\n",
        "    train_labeled_nodes = set(train_indices)\n",
        "    labeled_nodes_count = 0  # Counter for recomputing D\n",
        "\n",
        "    for node in range(data.num_nodes):\n",
        "        if y_pred[node] == -1:\n",
        "            labeled_neighbors = [n for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "            num_labeled_by_train = sum(1 for n in labeled_neighbors if n in train_labeled_nodes)\n",
        "            num_labeled_by_propagation = len(labeled_neighbors) - num_labeled_by_train\n",
        "            total_neighbors = len(neighbors_dict[node])\n",
        "\n",
        "            if total_neighbors > 0:\n",
        "                weighted_score = (a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors\n",
        "            else:\n",
        "                weighted_score = 0\n",
        "\n",
        "            similarity_score = max(D[node].values()) if D[node] else 0\n",
        "            ordered_set.add((-weighted_score - a6 * similarity_score, node))\n",
        "\n",
        "    # ✅ Iteratively Label the Most Constrained Nodes\n",
        "    while ordered_set:\n",
        "       # print(len(ordered_set))\n",
        "        _, node = ordered_set.pop(0)\n",
        "\n",
        "        if y_pred[node] != -1:\n",
        "            continue  # Skip already labeled nodes\n",
        "\n",
        "        # Get labeled neighbors\n",
        "        neighbor_labels = [y_pred[n] for n in neighbors_dict[node] if y_pred[n] != -1]\n",
        "        label_counts = Counter(neighbor_labels)\n",
        "\n",
        "        # 🚨 If this node has 0 labeled neighbors\n",
        "        if not neighbor_labels:\n",
        "            continue\n",
        "\n",
        "        # Compute Neighbor Label Distribution\n",
        "        neighbor_label_counts = Counter(neighbor_labels)\n",
        "        total_labeled_neighbors = len(neighbor_labels)\n",
        "\n",
        "        if total_labeled_neighbors > 0:\n",
        "            neighbor_label_distribution = {\n",
        "                lbl: neighbor_label_counts[lbl] / total_labeled_neighbors for lbl in neighbor_label_counts.keys()\n",
        "            }\n",
        "        else:\n",
        "            neighbor_label_distribution = {lbl: 0 for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        feature_diffs = {lbl: D[node][lbl] for lbl in dataset_label_distribution.keys()}\n",
        "\n",
        "        # ✅ Select the Best Label Based on the Adjusted Score\n",
        "        best_label_candidates = []\n",
        "        max_value = float('-inf')\n",
        "\n",
        "        for lbl in dataset_label_distribution.keys():\n",
        "            score = (\n",
        "                a1 * train_label_distribution.get(lbl, 0)\n",
        "                + a2 * neighbor_label_distribution.get(lbl, 0)\n",
        "                + a3 * feature_diffs[lbl]\n",
        "            )\n",
        "\n",
        "            if score - max_value > 0.01:\n",
        "                best_label_candidates = [lbl]\n",
        "                max_value = score\n",
        "            elif abs(score - max_value) <= 0.01:\n",
        "                best_label_candidates.append(lbl)\n",
        "\n",
        "        best_label = random.choice(best_label_candidates)\n",
        "        y_pred[node] = best_label\n",
        "        class_instances[best_label].add(node)\n",
        "        class_counts[best_label] += 1\n",
        "        labeled_nodes_count += 1  # Increment labeled count\n",
        "\n",
        "        # ✅ Update D Table for Neighbors Only\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "          for lbl in dataset_label_distribution.keys():\n",
        "              if class_instances[lbl]:  # Compute similarity only if class has instances\n",
        "                  D[neighbor][lbl] = feature_similarity(neighbor, {lbl: class_instances[lbl]}, data, train_indices, a7)\n",
        "\n",
        "\n",
        "        # ✅ Recompute Entire D Table Every 5 Nodes\n",
        "        if labeled_nodes_count % 10 == 0:\n",
        "          for i in range(data.num_nodes):\n",
        "              if y_pred[i] == -1:  # ✅ Only update unlabeled nodes\n",
        "                  for lbl in dataset_label_distribution.keys():\n",
        "                      if class_instances[lbl]:  # ✅ Ensure class has labeled instances\n",
        "                          instance_list = list(class_instances[lbl])\n",
        "                          instance_features = data.x[instance_list]\n",
        "\n",
        "                          # ✅ Assign weights: (1 - a7) for training instances, a7 for others\n",
        "                          instance_weights = torch.tensor(\n",
        "                              [(1 - a7) if inst in train_indices else a7 for inst in instance_list],\n",
        "                              dtype=torch.float,\n",
        "                              device=data.x.device\n",
        "                          )\n",
        "\n",
        "                          # ✅ Normalize weights to ensure they sum to 1\n",
        "                          instance_weights /= instance_weights.sum()\n",
        "\n",
        "                          # ✅ Compute weighted average feature vector\n",
        "                          avg_feature = torch.sum(instance_features * instance_weights.view(-1, 1), dim=0, keepdim=True)\n",
        "\n",
        "                          # ✅ Compute cosine similarity between node i and avg_feature\n",
        "                          similarity = F.cosine_similarity(data.x[i].unsqueeze(0), avg_feature).item()\n",
        "\n",
        "                          D[i][lbl] = similarity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # ✅ Update Adjacent Nodes in Ordered Set\n",
        "        for neighbor in neighbors_dict[node]:\n",
        "            if y_pred[neighbor] == -1:\n",
        "                old_entry = next((entry for entry in ordered_set if entry[1] == neighbor), None)\n",
        "                if old_entry:\n",
        "                    ordered_set.discard(old_entry)\n",
        "\n",
        "                num_labeled_by_train = sum(1 for x in neighbors_dict[neighbor] if y_pred[x] != -1 and x in train_labeled_nodes)\n",
        "                num_labeled_by_propagation = sum(1 for x in neighbors_dict[neighbor] if y_pred[x] != -1 and x not in train_labeled_nodes)\n",
        "                total_neighbors = len(neighbors_dict[neighbor])\n",
        "\n",
        "                similarity_score = max(D[neighbor].values()) if D[neighbor] else 0\n",
        "                new_weighted_score = ((a4 * num_labeled_by_propagation + a5 * num_labeled_by_train) / total_neighbors if total_neighbors > 0 else 0) + a6 * similarity_score\n",
        "\n",
        "                ordered_set.add((-new_weighted_score, neighbor))\n",
        "\n",
        "    return torch.tensor(y_pred[test_indices], dtype=torch.float), accuracy_score(data.y[test_indices], y_pred[test_indices])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqUQNrZolOwy",
        "outputId": "db818c26-5972-4af7-df82-b5e64ff880a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 33 elements\n",
            "Class 1: 1 elements\n",
            "Class 2: 18 elements\n",
            "Class 3: 101 elements\n",
            "Class 4: 30 elements\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "\n",
        "# Count occurrences of each class label\n",
        "class_counts = torch.bincount(data.y)\n",
        "\n",
        "# Print the number of elements in each class\n",
        "for class_id, count in enumerate(class_counts):\n",
        "    print(f\"Class {class_id}: {count} elements\")\n",
        "a1=0.5\n",
        "a2=-6\n",
        "a3=-2\n",
        "a4=1\n",
        "a5=3\n",
        "a6=1\n",
        "\n",
        "indices = np.arange(data.num_nodes)  # NumPy array of indices [0, 1, 2, ..., num_nodes-1]\n",
        "np.random.shuffle(indices)\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.6)\n",
        "\n",
        "# Further split train_idx into train and validation sets (e.g., 20% of train goes to validation)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.5)\n",
        "test_indices=test_idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u88m8qZfUdX-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsMOjg0RUedb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88eDCyKNUf57"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWZxuxXlygBh",
        "outputId": "4a893a7b-31c5-49da-fb5e-ee8b201af6d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "best validation by random search: 0.519069069069069\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import KFold\n",
        "import warnings\n",
        "warnings.simplefilter(\"error\", RuntimeWarning)  # Convert warnings to errors\n",
        "#dataset = WebKB(root='data', name='Cornell')\n",
        "#dataset = WebKB(root='data', name='texas')\n",
        "#dataset = WikipediaNetwork(root='data', name='chameleon')\n",
        "#dataset = WikipediaNetwork(root='data', name='squirrel')\n",
        "#dataset = WebKB(root='data', name='Wisconsin')\n",
        "\n",
        "\n",
        "\n",
        "def random_search(model, data, num_samples=50, num_splits=5):\n",
        "    \"\"\"\n",
        "    Perform random search for hyperparameter tuning while evaluating each set\n",
        "    of hyperparameters across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function to predict classes.\n",
        "        data: Dataset object.\n",
        "        num_samples: Number of random search samples (default: 120).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best hyperparameters found based on average accuracy.\n",
        "        best_score: The highest average accuracy obtained.\n",
        "    \"\"\"\n",
        "    best_params = None\n",
        "    best_score = float('-inf')\n",
        "    indices = np.arange(data.num_nodes)\n",
        "    maxi=1\n",
        "    for _ in range(num_samples):\n",
        "        print(\"step number \",_)\n",
        "        # Generate random hyperparameters\n",
        "        a1 = random.uniform(0, maxi)     # a1 must be positive\n",
        "        a2 = random.uniform(-maxi, -0.01)  # a2 must be negative\n",
        "        a3 = random.uniform(-maxi, -0.01)  # a3 must be negative\n",
        "        a5 = random.uniform(0, maxi)     # a5 must be positive\n",
        "        a4 = random.uniform(0, a5)    # a4 must be positive and a4 <= a5\n",
        "        a6 = random.uniform(0, maxi)\n",
        "        a7 = random.uniform(0, maxi/2)\n",
        "       # a8 = random.uniform(0, a7)\n",
        "        params = [a1, a2, a3, a4, a5, a6,a7]\n",
        "\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, *params)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "\n",
        "        if avg_score > best_score:\n",
        "            best_score = avg_score\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initial guesses for a1, a2, a3, a4, a5\n",
        "#initial_params = [0.5,-5,-2,1,3]\n",
        "\n",
        "# Bounds for parameters\n",
        " # Adjust bounds as needed\n",
        "\n",
        "# Optimize using scipy\n",
        "result,best_val = random_search(predictclass,data,num_samples=15,num_splits=5)\n",
        "#print(result)\n",
        "# Get best parameters\n",
        "best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7 = result[0],result[1],result[2],result[3],result[4],result[5],result[6]\n",
        "\n",
        "# Evaluate on test set\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(\"best validation by random search:\", best_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqOUOkBf6ACE",
        "outputId": "57899d0c-d182-44e0-cb99-5317264acca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial_params= [0.7133208475621263, -0.5569740369183065, -0.02245922421847779, 0.014222201548917186, 0.15781267543222743, 0.1755360384017245, 0.0650948246328577]\n",
            "best_validation by Bayesian= 0.5459459459459459\n",
            "best params found = [0.6237796879311535, -0.6475358995314613, -0.010000000000000009, 0.0, 0.33999518142331064, 1.0, 0.1959602818769689]\n",
            "\n",
            "🎯 Final Val Set Accuracy: 0.35135135135135137\n",
            "110 110\n",
            "\n",
            "🎯 Final Test Set Accuracy: 0.42727272727272725\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from skopt.space import Real\n",
        "from skopt import gp_minimize\n",
        "def bayesian_optimization(model, data, num_calls=10, num_splits=5, initial_params=None):\n",
        "    \"\"\"\n",
        "    Bayesian Optimization to find best hyperparameters (a1, a2, a3, a4, a5, a6)\n",
        "    that maximize the validation accuracy while evaluating across multiple train-test splits.\n",
        "\n",
        "    Arguments:\n",
        "        model: Function that takes (data, train_idx, val_idx, a1, a2, a3, a4, a5, a6) and returns (loss, accuracy)\n",
        "        data: Dataset object.\n",
        "        num_calls: Number of function evaluations (default: 30).\n",
        "        num_splits: Number of different train-test splits to evaluate each hyperparameter set.\n",
        "        initial_params: Optional initial solution from random search.\n",
        "\n",
        "    Returns:\n",
        "        best_params: The best found values for [a1, a2, a3, a4, a5, a6].\n",
        "        best_accuracy: The best validation accuracy found.\n",
        "    \"\"\"\n",
        "    maxi=1\n",
        "    search_space = [\n",
        "        Real(0, maxi, name=\"a1\"),        # a1 must be positive\n",
        "        Real(-maxi, -0.01, name=\"a2\"),   # a2 must be negative\n",
        "        Real(-maxi, -0.01, name=\"a3\"),   # a3 must be negative\n",
        "        Real(0, maxi, name=\"a4\"),        # a4 must be positive and a4 ≤ a5\n",
        "        Real(0, maxi, name=\"a5\"),        # a5 must be positive\n",
        "        Real(0, maxi, name=\"a6\"),\n",
        "        Real(0, maxi/2, name=\"a7\") , # a6 must be positive\n",
        "       # Real(0, maxi, name=\"a8\")\n",
        "    ]\n",
        "\n",
        "    indices = np.arange(data.num_nodes)\n",
        "\n",
        "    def objective(params):\n",
        "        a1, a2, a3, a4, a5, a6,a7 = params\n",
        "        a4, a5 = min(a4, a5), max(a4, a5)  # Ensure a4 ≤ a5\n",
        "       # a8, a7 = min(a8, a7), max(a8, a7)\n",
        "        fold_scores = []\n",
        "        kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)  # Different train-test splits\n",
        "\n",
        "        for train_idx, val_idx in kf.split(indices):\n",
        "            _, score = model(data, train_idx, val_idx, a1, a2, a3, a4, a5, a6,a7)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        avg_score = np.mean(fold_scores)\n",
        "        return -avg_score  # Since `gp_minimize` minimizes the function, we negate accuracy\n",
        "\n",
        "    if initial_params is not None:\n",
        "        print(\"initial_params=\",initial_params)\n",
        "        initial_params[3], initial_params[4] = min(initial_params[3], initial_params[4]), max(initial_params[3], initial_params[4])\n",
        "\n",
        "        #initial_params[7], initial_params[6] = min(initial_params[7], initial_params[6]), max(initial_params[7], initial_params[6])\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, x0=[initial_params], random_state=None)\n",
        "    else:\n",
        "        result = gp_minimize(objective, search_space, n_calls=num_calls, random_state=None)\n",
        "\n",
        "    best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7 = result.x\n",
        "    best_a4, best_a5 = min(best_a4, best_a5), max(best_a4, best_a5)  # Ensure a4 ≤ a5\n",
        "    #best_a8, best_a7 = min(best_a8, best_a7), max(best_a8, best_a7)\n",
        "    best_accuracy = -result.fun\n",
        "\n",
        "    best_params = [best_a1, best_a2, best_a3, best_a4, best_a5, best_a6,best_a7]\n",
        "\n",
        "    return best_params, best_accuracy\n",
        "\n",
        "# Example Usage:\n",
        "best_params, best_validation_score = bayesian_optimization(predictclass, data, num_calls=30, initial_params=result)\n",
        "\n",
        "print(\"best_validation by Bayesian=\",best_validation_score)\n",
        "if best_validation_score<best_val:\n",
        "  print(\"Bayesian made the parameters worse\")\n",
        "  best_params=result\n",
        "else:\n",
        "  best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7 = best_params\n",
        "print(\"best params found =\", best_params)\n",
        "\n",
        "# # # # Step 2: Test the Model Using the Best Parameters\n",
        "y_pred_test, final_test_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7)\n",
        "\n",
        "y_pred_val, final_val_accuracy = predictclass(data, train_idx, val_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6,best_a7)\n",
        "\n",
        "# # # Step 3: Print the Final Accuracy on the Test Set\n",
        "print(\"\\n🎯 Final Val Set Accuracy:\", final_val_accuracy)\n",
        "\n",
        "\n",
        "print(len(y_pred_test),len(test_idx))\n",
        "\n",
        "print(\"\\n🎯 Final Test Set Accuracy:\", final_test_accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH9DxCcGSpLc",
        "outputId": "6016948b-6cec-4323-8fdd-9397f444a70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Iteration 1/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.9387151304514988, -0.8243047206719621, -0.15257139211907367, 0.09170319054635429, 0.22206771121602875, 0.04463123485222331, 0.11296780837215203]\n",
            "🎯 Test Accuracy for iteration 1: 0.4324\n",
            "\n",
            "🔄 Iteration 2/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.8161772170049546, -0.8704495828489107, -0.1341486558822289, 0.7202408586619649, 0.9045876275844148, 0.10971565847844467, 0.43762394303774765]\n",
            "🎯 Test Accuracy for iteration 2: 0.5135\n",
            "\n",
            "🔄 Iteration 3/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n",
            "step number  14\n",
            "initial_params= [0.5243252261102191, -0.8733331996108448, -0.018049709001723424, 0.0709870601840635, 0.872406537832134, 0.0220289672170485, 0.4373224247576343]\n",
            "🎯 Test Accuracy for iteration 3: 0.6757\n",
            "\n",
            "🔄 Iteration 4/10\n",
            "step number  0\n",
            "step number  1\n",
            "step number  2\n",
            "step number  3\n",
            "step number  4\n",
            "step number  5\n",
            "step number  6\n",
            "step number  7\n",
            "step number  8\n",
            "step number  9\n",
            "step number  10\n",
            "step number  11\n",
            "step number  12\n",
            "step number  13\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_accuracies = []\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "for run in range(num_iterations):\n",
        "    print(f\"\\n🔄 Iteration {run + 1}/{num_iterations}\")\n",
        "\n",
        "    # Shuffle indices\n",
        "    indices = np.arange(data.num_nodes)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Step 1: Split into 80% train+validation and 20% test\n",
        "    train_val_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=run)\n",
        "\n",
        "    # Step 2: Split train+validation into 75% train and 25% validation\n",
        "    train_idx, val_idx = train_test_split(train_val_idx, test_size=0.25, random_state=run)\n",
        "    # (0.25 * 80%) = 20% of total, so remaining 60% is train\n",
        "\n",
        "    # Now we have:\n",
        "    # - train_idx (60% of total)\n",
        "    # - val_idx (20% of total)\n",
        "    # - test_idx (20% of total)\n",
        "\n",
        "    # Run hyperparameter tuning\n",
        "    best_params_random, best_val_random = random_search(predictclass, data, num_samples=15, num_splits=5)\n",
        "\n",
        "    best_params_bayes, best_val_bayes = bayesian_optimization(predictclass, data, num_calls=30, initial_params=best_params_random)\n",
        "\n",
        "    best_params = best_params_bayes if best_val_bayes >= best_val_random else best_params_random\n",
        "\n",
        "    # Extract optimized hyperparameters\n",
        "    best_a1, best_a2, best_a3, best_a4, best_a5, best_a6, best_a7 = best_params\n",
        "\n",
        "    # Run predictclass with best parameters on test set\n",
        "    _, final_test_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5, best_a6, best_a7)\n",
        "\n",
        "    # Store the result\n",
        "    test_accuracies.append(final_test_accuracy)\n",
        "\n",
        "    print(f\"🎯 Test Accuracy for iteration {run + 1}: {final_test_accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gbhUt_lv1Vh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c_sXm_FtUhXF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.nn import Linear, Sequential, ReLU, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class HighPassConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, amp=0.5, **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(**kwargs)\n",
        "        self.amp = amp\n",
        "        self.lin = Linear(in_channels, out_channels)\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.lin(x)\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "        out = self.amp * x - out\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
        "\n",
        "class Augmenter(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, amp=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = HighPassConv(in_dim, hidden_dim, amp=amp)\n",
        "        self.conv2 = HighPassConv(hidden_dim, hidden_dim, amp=amp)\n",
        "        self.mlp_edge_model = Sequential(\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim, hidden_dim * 2),\n",
        "            ReLU(),\n",
        "            Dropout(0.5),\n",
        "            Linear(hidden_dim * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        src, dst = edge_index[0], edge_index[1]\n",
        "        edge_emb = x[src] + x[dst]\n",
        "        return torch.sigmoid(self.mlp_edge_model(edge_emb))\n",
        "\n",
        "class HeterophilicNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds=None):\n",
        "        super().__init__()\n",
        "        self.augmenter = Augmenter(in_dim, hidden_dim)\n",
        "        self.gnn_high = HighPassConv(in_dim, hidden_dim)\n",
        "        self.offset_mlp = Sequential(\n",
        "            Linear(in_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.final_mlp = Sequential(\n",
        "            Linear(hidden_dim, hidden_dim),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self.test_indices = test_indices  # Store test indices\n",
        "\n",
        "        # Store initial predictions but only for test indices (not trained)\n",
        "        if initial_preds is not None:\n",
        "            self.initial_preds = F.one_hot(initial_preds.long(), num_classes=num_classes).float()\n",
        "        else:\n",
        "            self.initial_preds = None\n",
        "\n",
        "    def forward(self, x, edge_index, train_indices):\n",
        "        edge_weights = self.augmenter(x, edge_index)\n",
        "        h = self.gnn_high(x, edge_index, edge_weights)\n",
        "        offset = self.offset_mlp(x)\n",
        "        logits = self.final_mlp(h + offset)\n",
        "\n",
        "        # If initial_preds exists, add it **only for test nodes**\n",
        "        if self.initial_preds is not None:\n",
        "            logits[self.test_indices] = logits[self.test_indices] + self.initial_preds\n",
        "\n",
        "        return F.log_softmax(logits, dim=1)\n",
        "\n",
        "# Training and Evaluation Code\n",
        "def train_and_evaluate(model, data, train_indices, test_indices, initial_preds, epochs=2000, lr=0.01):\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        loss = criterion(logits[train_indices], data.y[train_indices])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, train_indices)\n",
        "        predicted_classes = torch.argmax(logits, dim=1)\n",
        "        test_predictions = predicted_classes[test_indices]\n",
        "        final_accuracy = accuracy_score(data.y[test_indices].cpu().numpy(), test_predictions.cpu().numpy())\n",
        "\n",
        "    return final_accuracy, test_predictions\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TtC0NBH7UhKO"
      },
      "outputs": [],
      "source": [
        "# Compute initial test predictions\n",
        "initial_preds, initial_accuracy = predictclass(data, train_idx, test_idx, best_a1, best_a2, best_a3, best_a4, best_a5,best_a6)\n",
        "\n",
        "# Ensure `initial_preds` is a tensor and on the correct device\n",
        "initial_preds = initial_preds.clone().detach()  # Ensures a proper detached copy\n",
        "\n",
        "\n",
        "print(f\"📊 Initial Classification Accuracy: {initial_accuracy:.4f}\")\n",
        "\n",
        "# Create the model\n",
        "model = HeterophilicNodeClassifier(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=len(set(data.y.tolist())),test_indices=test_indices, initial_preds=initial_preds\n",
        ").to(data.x.device)  # Ensure model is on the correct device\n",
        "\n",
        "# 🔄 Train the model before inference\n",
        "final_accuracy_before_djgnn, test_predictions_before_djgnn = train_and_evaluate(\n",
        "    model, data, train_idx, test_idx, initial_preds, epochs=100, lr=0.01\n",
        ")\n",
        "\n",
        "print(len(test_predictions_before_djgnn),len(test_idx))\n",
        "\n",
        "# ✅ Model evaluation after training\n",
        "model.eval()\n",
        "#with torch.no_grad():\n",
        " #   logits = model(data.x, data.edge_index, train_idx, test_idx, initial_test_preds=initial_preds)\n",
        " #   predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "\n",
        "print(f\"🎯  Classification Accuracy after running kdd2023: {final_accuracy_before_djgnn:.4f}\")\n",
        "#print(test_predictions)\n",
        "#print(len(initial_preds))\n",
        "#print(len(test_predictions))\n",
        "\n",
        "#print(len(val_idx))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nZSz76h8VGIZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class DJGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes, test_indices, initial_preds, n_jumps=5, dropout=0.5):\n",
        "        super(DJGNN, self).__init__()\n",
        "        self.n_jumps = n_jumps\n",
        "        self.dropout = dropout\n",
        "        self.att = nn.Parameter(torch.ones(n_jumps + 1))  # Attention weights for jumps\n",
        "        self.sm = nn.Softmax(dim=0)\n",
        "\n",
        "        # Store initial predictions (converted to one-hot)\n",
        "        self.test_indices = test_indices\n",
        "        self.initial_preds = nn.Parameter(F.one_hot(initial_preds, num_classes).float(), requires_grad=False)\n",
        "\n",
        "        # GCN layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(n_jumps):\n",
        "            self.convs.append(GCNConv(in_dim, hidden_dim))\n",
        "\n",
        "        # Extra convolution layers\n",
        "        self.conv_extra = GCNConv(in_dim, hidden_dim)\n",
        "        self.bn_extra = nn.BatchNorm1d(hidden_dim)\n",
        "        self.conv_extra2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.bn_extra_2 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        # Final classifier\n",
        "        self.classify = nn.Linear(hidden_dim * (n_jumps + 1) + num_classes, num_classes)  # Extra input for initial preds\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "      mask_attentions = self.sm(self.att)\n",
        "\n",
        "      # Extra convolutions\n",
        "      extra_conv = self.conv_extra(x, edge_index).relu()\n",
        "      print(f\"extra_conv after conv_extra: {extra_conv.shape}\")\n",
        "      extra_conv = self.bn_extra(extra_conv)\n",
        "      print(f\"extra_conv after bn_extra: {extra_conv.shape}\")\n",
        "      extra_conv = F.dropout(extra_conv, p=self.dropout, training=self.training)\n",
        "      extra_conv = self.conv_extra2(extra_conv, edge_index).relu()\n",
        "      extra_conv = self.bn_extra_2(extra_conv)\n",
        "      extra_conv = extra_conv * mask_attentions[-1]\n",
        "      print(f\"extra_conv after conv_extra2 & mask: {extra_conv.shape}\")\n",
        "\n",
        "      # Jumping knowledge mechanism: collect outputs from each conv layer\n",
        "      z_s = []\n",
        "      for i, conv in enumerate(self.convs):\n",
        "          z = conv(x, edge_index).relu() * mask_attentions[i]\n",
        "          print(f\"z from conv {i}: {z.shape}\")\n",
        "          z_s.append(z)\n",
        "\n",
        "      # Concatenate all jump outputs with extra_conv\n",
        "      final_z = torch.cat(z_s + [extra_conv], dim=1)\n",
        "      print(f\"✅ final_z shape BEFORE concatenation: {final_z.shape}\")  # Expect [num_nodes, feature_dim]\n",
        "\n",
        "      # Debug: Print test indices shape and the slice from final_z\n",
        "      print(f\"✅ self.test_indices shape: {self.test_indices.shape}\")  # Expect [num_test_samples]\n",
        "      test_slice = final_z[self.test_indices]\n",
        "      print(f\"✅ final_z[self.test_indices] shape: {test_slice.shape}\")  # Expect [num_test_samples, feature_dim]\n",
        "\n",
        "      # Ensure self.initial_preds is a LongTensor\n",
        "      num_classes = self.classify.out_features  # Get number of classes\n",
        "      initial_preds_long = self.initial_preds.long().squeeze()\n",
        "      print(f\"initial_preds_long shape after squeeze: {initial_preds_long.shape}\")\n",
        "\n",
        "      # Clamp indices to valid range\n",
        "      initial_preds_long = torch.clamp(initial_preds_long, min=0, max=num_classes - 1)\n",
        "\n",
        "      # Convert to one-hot encoding\n",
        "      one_hot_preds = F.one_hot(initial_preds_long, num_classes=num_classes).float()\n",
        "      print(f\"✅ one_hot_preds shape immediately after one_hot: {one_hot_preds.shape}\")\n",
        "\n",
        "      # If one_hot_preds still has an extra dimension, print its dimensions explicitly\n",
        "      for idx, dim in enumerate(one_hot_preds.shape):\n",
        "          print(f\"one_hot_preds dim {idx}: {dim}\")\n",
        "\n",
        "      # Attempt to remove extra dimensions by squeezing only the dims of size 1\n",
        "      one_hot_preds = one_hot_preds.squeeze()\n",
        "      print(f\"✅ one_hot_preds shape after squeeze(): {one_hot_preds.shape}\")\n",
        "\n",
        "      # Check dimensions explicitly\n",
        "      if one_hot_preds.ndim != 2:\n",
        "          print(f\"❌ one_hot_preds still has {one_hot_preds.ndim} dimensions; expected 2 dimensions!\")\n",
        "\n",
        "      # Now, try concatenation and catch errors with more prints\n",
        "      try:\n",
        "          final_z[self.test_indices] = torch.cat((final_z[self.test_indices], one_hot_preds), dim=1)\n",
        "      except RuntimeError as e:\n",
        "          print(f\"❌ ERROR: Shape mismatch at concatenation!\")\n",
        "          print(f\"🔍 final_z[self.test_indices] shape: {final_z[self.test_indices].shape}\")\n",
        "          print(f\"🔍 one_hot_preds shape: {one_hot_preds.shape}\")\n",
        "          raise e  # Re-raise after printing shapes\n",
        "\n",
        "      # Dropout and classification\n",
        "      final_z = F.dropout(final_z, p=self.dropout, training=self.training)\n",
        "      logits = self.classify(final_z).log_softmax(dim=-1)\n",
        "      return logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cldUM1jPk72E"
      },
      "outputs": [],
      "source": [
        "def train_djgnn(model, data, train_idx, test_idx, initial_preds_djgnn, epochs=100, lr=0.01):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(data.x, data.edge_index)\n",
        "        loss_supervised = criterion(logits[train_idx], data.y[train_idx])\n",
        "\n",
        "        # 🔥 NEW: Consistency Loss to prevent drastic changes\n",
        "        confidence_threshold = 0.85  # Change only high-confidence nodes\n",
        "        high_confidence_mask = logits[test_idx].softmax(dim=1).max(dim=1).values > confidence_threshold\n",
        "\n",
        "        # Apply consistency loss only to confident predictions\n",
        "        filtered_loss = F.cross_entropy(logits[test_idx][high_confidence_mask], initial_preds_djgnn[high_confidence_mask])\n",
        "        loss = loss_supervised + 0.1 * filtered_loss\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy on test set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_logits = model(data.x, data.edge_index)\n",
        "            test_preds = test_logits[test_idx].argmax(dim=1)\n",
        "            test_correct = (test_preds == data.y[test_idx]).sum().item()\n",
        "            test_acc = test_correct / len(test_idx)\n",
        "\n",
        "    #    print(f\"🧐 Epoch {epoch+1:02d} | Loss: {loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "       # if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "       #     print(f\"🔍 Logits Before Argmax (First 5 Samples):\\n{test_logits[test_idx][:5]}\")\n",
        "\n",
        "    return test_preds, test_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p936LZ0GlGf3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Ensure `initial_preds_djgnn` is a tensor and detached\n",
        "initial_preds_djgnn = test_predictions_before_djgnn.clone().detach().long()  # Explicitly convert to LongTensor\n",
        "initial_preds = initial_preds.clone().detach().long()\n",
        "\n",
        "# Get the number of unique classes from `data.y`\n",
        "num_classes = data.y.max().item() + 1  # `max() + 1` ensures it captures all labels\n",
        "\n",
        "print(f\"📊 Number of Test Samples: {len(initial_preds_djgnn)}\")\n",
        "print(f\"🔢 Number of Unique Classes: {num_classes}\")\n",
        "\n",
        "# 🚀 Initialize DJ-GNN model with test indices & initial predictions\n",
        "djgnn_model = DJGNN(\n",
        "    in_dim=data.x.shape[1],\n",
        "    hidden_dim=32,\n",
        "    num_classes=num_classes,  # Use the correct `num_classes`\n",
        "    test_indices=torch.tensor(test_idx, dtype=torch.long, device=data.x.device),  # Ensure `test_idx` is a tensor\n",
        "    initial_preds=initial_preds_djgnn,  # Pass initial predictions (already `LongTensor`)\n",
        "    n_jumps=5,  # Use 5 hops for diffusion\n",
        "    dropout=0.5\n",
        ").to(data.x.device)  # Ensure it's on the correct device\n",
        "\n",
        "# 🚀 Train DJ-GNN and get new predictions\n",
        "new_preds, final_accuracy_after_djgnn = train_djgnn(\n",
        "    djgnn_model, data, train_idx, test_idx, initial_preds_djgnn, epochs=500, lr=0.01\n",
        ")\n",
        "\n",
        "# 🎯 Compare accuracies before & after DJ-GNN\n",
        "print(\"\\n🔥 Final Results:\")\n",
        "print(f\"🎯 Accuracy BEFORE DJ-GNN: {final_accuracy_before_djgnn:.4f}\")\n",
        "print(f\"🚀 Accuracy AFTER DJ-GNN: {final_accuracy_after_djgnn:.4f}\")\n",
        "\n",
        "# 🔍 Sample Predictions Before & After DJ-GNN (Print first 10 for debugging)\n",
        "print(\"\\n🔍 Sample Predictions Before & After DJ-GNN:\")\n",
        "for i in range(min(10, len(test_idx))):  # Ensure we don't go out of bounds\n",
        "    print(f\"🧐 Sample {i+1} | Before: {initial_preds_djgnn[i].item()} | After: {new_preds[i].item()}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}